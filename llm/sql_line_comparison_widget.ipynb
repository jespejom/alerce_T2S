{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1dab010",
   "metadata": {},
   "source": [
    "# SQL Line-by-Line Comparison Widget\n",
    "\n",
    "This notebook implements a specialized visualization for comparing SQL queries line by line, focusing on associating similar clauses, conditions, and statements between gold (reference) and predicted SQL queries. \n",
    "\n",
    "The visualization pipeline:\n",
    "1. Parses SQL queries into meaningful \"lines\" (clauses, conditions, etc.)\n",
    "2. Calculates similarity between lines from predicted and gold queries\n",
    "3. Associates lines from both queries based on similarity thresholds\n",
    "4. Visualizes the matching with appropriate highlighting (green for matched, red for unmatched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa3db160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jespejo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jespejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import sqlparse\n",
    "import difflib\n",
    "from pygments import highlight\n",
    "from pygments.lexers import SqlLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "import json\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK resources (required for text processing)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import the utility functions for evaluation\n",
    "from utils.eval_utils import load_evaluation_results_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996695d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Qwen2.5-Coder-3B/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping gpt-4.1-mini-2025-04-14/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping prem-1B-SQL/alerce_train_direct_v8 as config.json does not exist.\n",
      "Evaluation results file not found for Qwen2.5-1.5B-Instruct/alerce_dummy_direct_v8. Skipping...\n",
      "Skipping Qwen2.5-Coder-3B/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping gpt-4.1-mini-2025-04-14/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping prem-1B-SQL/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping Qwen2.5-Coder-3B/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping gpt-4.1-mini-2025-04-14/alerce_train_direct_v8 as config.json does not exist.\n",
      "Skipping prem-1B-SQL/alerce_train_direct_v8 as config.json does not exist.\n",
      "Loaded training dataset with 58 examples\n",
      "Loaded test dataset with 52 examples\n",
      "\n",
      "Training dataset columns:\n",
      "['req_id', 'request', 'table_info', 'external_knowledge', 'domain_knowledge', 'gold_query', 'difficulty', 'type', 'nested_type', 'rephrased_request', 'rephrased_request_gpt-3.5-turbo-0125_t0.4', 'rephrased_request_gpt-4o-2024-05-13_t0.2']\n",
      "\n",
      "Test dataset columns:\n",
      "['req_id', 'request', 'table_info', 'external_knowledge', 'domain_knowledge', 'gold_query', 'difficulty', 'type', 'nested_type', 'rephrased_request', 'rephrased_request_gpt-3.5-turbo-0125_t0.4', 'rephrased_request_gpt-4o-2024-05-13_t0.2']\n",
      "\n",
      "Sample row from training dataset:\n",
      "{'req_id': 13, 'request': 'Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.', 'table_info': \"['object', 'probability']\", 'external_knowledge': '\\n-- mjd date for December = 59914.0\\n-- mjd date for September = 60217.0', 'domain_knowledge': \"\\n-- Super Nova (SNe) is a large explosion that takes place at the end of a star's life cycle\\n\", 'gold_query': \"\\nSELECT\\n    object.oid, probability.class_name, object.lastmjd, object.firstmjd\\nFROM\\n    object INNER JOIN\\n    probability\\n    ON object.oid = probability.oid\\nWHERE\\n    probability.classifier_name='lc_classifier'\\n    AND probability.class_name IN ('SNIa', 'SNIbc', 'SNII', 'SLSN')\\n    AND probability.ranking = 1\\n    AND object.firstmjd < 60217.0\\n    AND object.firstmjd > 59914.0\\n\", 'difficulty': 'simple', 'type': 'object', 'nested_type': 'none', 'rephrased_request': nan, 'rephrased_request_gpt-3.5-turbo-0125_t0.4': nan, 'rephrased_request_gpt-4o-2024-05-13_t0.2': nan}\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation results\n",
    "save_path = \"../results\"\n",
    "\n",
    "evaluation_results = load_evaluation_results_from_dir(save_path=save_path)\n",
    "evaluation_results_train = load_evaluation_results_from_dir(save_path=save_path, dataset=\"txt2sql_alerce_train_v4_0\")\n",
    "evaluation_results_test = load_evaluation_results_from_dir(save_path=save_path, dataset=\"txt2sql_alerce_test_v4_0\")\n",
    "\n",
    "# Load datasets\n",
    "try:\n",
    "    db_train = pd.read_csv('data/txt2sql_alerce_train_v4_0.csv')\n",
    "    db_test = pd.read_csv('data/txt2sql_alerce_test_v4_0.csv')\n",
    "    print(f\"Loaded training dataset with {len(db_train)} examples\")\n",
    "    print(f\"Loaded test dataset with {len(db_test)} examples\")\n",
    "    \n",
    "    # Print column names for debugging\n",
    "    print(\"\\nTraining dataset columns:\")\n",
    "    print(db_train.columns.tolist())\n",
    "    print(\"\\nTest dataset columns:\")\n",
    "    print(db_test.columns.tolist())\n",
    "    \n",
    "    # Show a sample row to understand the structure\n",
    "    if len(db_train) > 0:\n",
    "        print(\"\\nSample row from training dataset:\")\n",
    "        print(db_train.iloc[0].to_dict())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load datasets: {e}\")\n",
    "    db_train = None\n",
    "    db_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c170cbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 104 results for claude-3-5-sonnet-20241022-alerce_test_sbs_v4\n",
      "Added 104 results for claude-3-5-sonnet-20241022-alerce_test_direct_v8\n",
      "Added 104 results for claude-3-7-sonnet-20250219-alerce_test_sbs_v4\n",
      "Added 104 results for claude-3-7-sonnet-20250219-alerce_test_direct_v8\n",
      "Added 116 results for gpt-4.1-nano-2025-04-14-alerce_train_direct_v10\n",
      "Added 104 results for gpt-4.1-nano-2025-04-14-alerce_test_sbs_v4\n",
      "Added 20 results for gpt-4.1-nano-2025-04-14-alerce_train_dummy\n",
      "Added 116 results for gpt-4.1-nano-2025-04-14-alerce_train_direct_v9\n",
      "Added 20 results for gpt-4.1-nano-2025-04-14-alerce_direct_dummy_prompts\n",
      "Added 104 results for gpt-4.1-nano-2025-04-14-alerce_test_direct_v8\n",
      "Added 116 results for gpt-4.1-nano-2025-04-14-alerce_train_sbscot_v0\n",
      "Added 232 results for gpt-4.1-nano-2025-04-14-alerce_train_direct_v8\n",
      "Added 20 results for gpt-4.1-nano-2025-04-14-alerce_sbs_dummy\n",
      "Added 20 results for gpt-4.1-nano-2025-04-14-alerce_direct_dummy\n",
      "Added 20 results for gpt-4.1-nano-2025-04-14-alerce_sbs_dummy_prompts\n",
      "Added 116 results for gpt-4.1-nano-2025-04-14-alerce_train_sbs_v4\n",
      "Warning: Missing data for gpt-4o-mini-2024-07-18 - alerce_train_sbscot_v0: 'self_corrected'\n",
      "Added 116 results for gpt-4o-mini-2024-07-18-alerce_train_sbs_v4\n",
      "Added 116 results for gpt-4o-mini-2024-07-18-alerce_train_direct_dirv8\n",
      "Warning: Missing data for gpt-4.1-mini-2025-04-14 - alerce_train_sbs_v4: 'self_corrected'\n",
      "Added 104 results for gpt-4o-2024-08-06-alerce_test_sbs_v4\n",
      "Added 104 results for gpt-4o-2024-08-06-alerce_test_direct_v8\n",
      "Added 20 results for claude-3-haiku-20240307-alerce_train_dummy\n",
      "Added 116 results for claude-3-haiku-20240307-alerce_train_sbscot_v1\n",
      "Added 116 results for claude-3-haiku-20240307-alerce_train_direct_v8\n",
      "Added 116 results for claude-3-haiku-20240307-alerce_train_sbs_v4\n",
      "Added 104 results for gpt-4.1-2025-04-14-alerce_test_sbs_v4\n",
      "Added 104 results for gpt-4.1-2025-04-14-alerce_test_direct_v8\n",
      "Added 116 results for gpt-4.1-2025-04-14-alerce_train_direct_v8\n",
      "Added 116 results for gpt-4.1-2025-04-14-alerce_train_sbs_v4\n",
      "Warning: Missing data for Qwen2.5-1.5B-Instruct - alerce_dummy_direct_v8: 'self_corrected'\n",
      "Added 290 results for Qwen2.5-1.5B-Instruct-alerce_train_direct_v8\n",
      "Added 116 results for Qwen2.5-1.5B-Instruct-alerce_train_sbs_v4\n"
     ]
    }
   ],
   "source": [
    "# Process evaluation results to a format usable by the widget\n",
    "models = list(evaluation_results.keys())\n",
    "\n",
    "self_corr = True\n",
    "self_corr_key = 'self_corrected' if self_corr else 'corrected'\n",
    "\n",
    "# Initialize result dictionary for the widget\n",
    "results_dict = {}\n",
    "\n",
    "for model in models:\n",
    "    experiments = list(evaluation_results[model].keys())\n",
    "    for experiment in experiments:\n",
    "        try:\n",
    "            exp_label = f\"{model}-{experiment}\"\n",
    "            results = evaluation_results[model][experiment][self_corr_key]['detailed_results']\n",
    "            results_dict[exp_label] = results\n",
    "            print(f\"Added {len(results)} results for {exp_label}\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Missing data for {model} - {experiment}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7945189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for word embeddings\n",
    "try:\n",
    "    import sentence_transformers\n",
    "except ImportError:\n",
    "    print(\"Installing sentence-transformers...\")\n",
    "    !pip install sentence-transformers\n",
    "    import sentence_transformers\n",
    "    print(\"sentence-transformers installed successfully\")\n",
    "\n",
    "# Import necessary modules for word embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Global variable to hold the sentence transformer model\n",
    "sentence_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5b6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentence transformer model for embeddings\n",
    "# Using a lighter model for better performance\n",
    "sentence_model = None\n",
    "\n",
    "def initialize_sentence_model():\n",
    "    \"\"\"Initialize the sentence transformer model if not already loaded\"\"\"\n",
    "    global sentence_model\n",
    "    if sentence_model is None:\n",
    "        try:\n",
    "            # Using a smaller model for better performance\n",
    "            sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "            print(\"Loaded sentence-transformer model: all-MiniLM-L6-v2\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sentence-transformer model: {e}\")\n",
    "            print(\"Word embedding similarity method will not be available\")\n",
    "\n",
    "def calculate_similarity_with_method(line1, line2, method='tfidf'):\n",
    "    \"\"\"\n",
    "    Calculate similarity between two SQL query lines using the specified method\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    line1 : str\n",
    "        The first line (SQL query fragment to compare)\n",
    "    line2 : str\n",
    "        The second line (SQL query fragment to compare)\n",
    "    method : str\n",
    "        The method to use for similarity calculation:\n",
    "        - 'tfidf': Uses TF-IDF vectorization and cosine similarity (default)\n",
    "        - 'jaccard': Uses Jaccard similarity (set-based comparison)\n",
    "        - 'embedding': Uses neural word embeddings via sentence-transformers\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Similarity score between 0 and 1\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    This function handles special cases like:\n",
    "    - Table aliases (e.g., \"t.column\" vs \"column\")\n",
    "    - IN clauses with the same values but different column references\n",
    "    - Empty or null input values\n",
    "    \n",
    "    Each similarity method has different characteristics:\n",
    "    - TF-IDF: Fast, works well for keyword matching\n",
    "    - Jaccard: Good for exact token overlap, less sensitive to order\n",
    "    - Embedding: Best for semantic similarity, captures meaning even with different words\n",
    "    \"\"\"\n",
    "    # Ensure both lines are strings\n",
    "    if line1 is None:\n",
    "        line1 = \"\"\n",
    "    if line2 is None:\n",
    "        line2 = \"\"\n",
    "    \n",
    "    if not isinstance(line1, str):\n",
    "        line1 = str(line1)\n",
    "    if not isinstance(line2, str):\n",
    "        line2 = str(line2)\n",
    "    \n",
    "    # Special case: Direct equality check after alias normalization\n",
    "    # This ensures that 'column = value' and 'table.column = value' are matched with high similarity\n",
    "    normalized_line1 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', line1, flags=re.IGNORECASE)\n",
    "    normalized_line2 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', line2, flags=re.IGNORECASE)\n",
    "    \n",
    "    # If the normalized lines are identical, return a very high similarity score\n",
    "    extra_similarity = 0.0  # Extra similarity for IN clauses with identical values\n",
    "    if normalized_line1.lower() == normalized_line2.lower():\n",
    "        extra_similarity += 0.6\n",
    "    \n",
    "    # Handle table aliases and preprocessing regardless of method\n",
    "    def preprocess_text(text):\n",
    "        try:\n",
    "            # Convert to lowercase\n",
    "            text = text.lower()\n",
    "            \n",
    "            # Handle table aliases (e.g., \"t.column\" vs \"table.column\" vs \"column\")\n",
    "            # Replace patterns like \"x.column\" with just \"column\"\n",
    "            text = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', text)\n",
    "            \n",
    "            # Now tokenize\n",
    "            tokens = word_tokenize(text)\n",
    "            \n",
    "            # Remove SQL keywords, punctuation, and stopwords\n",
    "            sql_keywords = ['select', 'from', 'where', 'group', 'by', 'having', 'order', 'limit',\n",
    "                           'join', 'inner', 'outer', 'left', 'right', 'on', 'and', 'or', 'as', 'in']\n",
    "            \n",
    "            # Get stopwords or use empty list if not available\n",
    "            try:\n",
    "                stop_words = stopwords.words('english')\n",
    "            except LookupError:\n",
    "                print(\"Warning: Stopwords not available, using empty list\")\n",
    "                stop_words = []\n",
    "                \n",
    "            tokens = [token for token in tokens if token.isalnum() and token not in sql_keywords\n",
    "                     and token not in stop_words]\n",
    "            return ' '.join(tokens), tokens\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error preprocessing text: {e}\")\n",
    "            # Return a safe value\n",
    "            return text.lower(), text.lower().split()\n",
    "    \n",
    "    # Special handling for IN clauses with the same values but different table aliases\n",
    "    in_pattern = re.compile(r'(.*)\\s+in\\s+\\((.*)\\)', re.IGNORECASE)\n",
    "    match1 = in_pattern.match(line1)\n",
    "    match2 = in_pattern.match(line2)\n",
    "    \n",
    "    if match1 and match2:\n",
    "        # If both are IN clauses, compare their values\n",
    "        values1 = [v.strip().strip(\"'\\\"\") for v in match1.group(2).split(',')]\n",
    "        values2 = [v.strip().strip(\"'\\\"\") for v in match2.group(2).split(',')]\n",
    "        \n",
    "        # If the values are identical, increase the similarity\n",
    "        if sorted(values1) == sorted(values2):\n",
    "            # Extract column names (removing table aliases)\n",
    "            col1 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', match1.group(1), flags=re.IGNORECASE).strip()\n",
    "            col2 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', match2.group(1), flags=re.IGNORECASE).strip()\n",
    "            \n",
    "            # If the column names match after removing aliases, add extra similarity\n",
    "            if col1.lower() == col2.lower():\n",
    "                extra_similarity += 0.5\n",
    "\n",
    "    # Special handling for comparison operators (=, >, <, etc.) with different table aliases\n",
    "    # This handles cases like \"column = value\" vs \"table.column = value\"\n",
    "    comp_pattern = re.compile(r'(.*?)\\s*(=|<>|!=|>|<|>=|<=)\\s*(.*)', re.IGNORECASE)\n",
    "    comp_match1 = comp_pattern.match(line1)\n",
    "    comp_match2 = comp_pattern.match(line2)\n",
    "    \n",
    "    if comp_match1 and comp_match2:\n",
    "        # If both are comparison expressions with the same operator\n",
    "        if comp_match1.group(2) == comp_match2.group(2):\n",
    "            # Check if the values being compared are the same\n",
    "            val1 = comp_match1.group(3).strip().strip(\"'\\\"\")\n",
    "            val2 = comp_match2.group(3).strip().strip(\"'\\\"\")\n",
    "            \n",
    "            if val1.lower() == val2.lower():\n",
    "                # Extract column names (removing table aliases)\n",
    "                col1 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', comp_match1.group(1), flags=re.IGNORECASE).strip()\n",
    "                col2 = re.sub(r'([a-z0-9_]+)\\.([a-z0-9_]+)', r'\\2', comp_match2.group(1), flags=re.IGNORECASE).strip()\n",
    "                \n",
    "                # If the column names match after removing aliases, add extra similarity\n",
    "                if col1.lower() == col2.lower():\n",
    "                    extra_similarity += 0.5\n",
    "    \n",
    "    # Preprocess both lines\n",
    "    processed_line1, tokens1 = preprocess_text(line1)\n",
    "    processed_line2, tokens2 = preprocess_text(line2)\n",
    "    \n",
    "    # If either line is empty after preprocessing, return 0\n",
    "    if not processed_line1 or not processed_line2:\n",
    "        processed_line1 = line1.lower()\n",
    "        processed_line2 = line2.lower()            # Calculate similarity based on the chosen method\n",
    "    if method == 'tfidf':\n",
    "        # TF-IDF vectorization and cosine similarity\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(lowercase=True, analyzer='word', \n",
    "                                        token_pattern=r'[a-zA-Z0-9_\\.\\*]+',\n",
    "                                        ngram_range=(1, 2))\n",
    "            \n",
    "            tfidf_matrix = vectorizer.fit_transform([processed_line1, processed_line2])\n",
    "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            similarity = min(1.0, similarity + extra_similarity)  # Cap at 1.0\n",
    "            return similarity\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating TF-IDF similarity: {e}\")\n",
    "            return 0\n",
    "            \n",
    "    elif method == 'jaccard':\n",
    "        # Jaccard similarity (set-based)\n",
    "        try:\n",
    "            set1 = set(tokens1)\n",
    "            set2 = set(tokens2)\n",
    "            \n",
    "            if not set1 or not set2:\n",
    "                return 0\n",
    "                \n",
    "            intersection = len(set1.intersection(set2))\n",
    "            union = len(set1.union(set2))\n",
    "            \n",
    "            similarity = intersection / union if union > 0 else 0\n",
    "            similarity = min(1.0, similarity + extra_similarity)  # Cap at 1.0\n",
    "            return similarity\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating Jaccard similarity: {e}\")\n",
    "            return 0\n",
    "            \n",
    "    elif method == 'embedding':\n",
    "        # Word embedding similarity using sentence transformers\n",
    "        try:\n",
    "            # Initialize model if not already done\n",
    "            if sentence_model is None:\n",
    "                initialize_sentence_model()\n",
    "                \n",
    "            if sentence_model is None:\n",
    "                # Fall back to TF-IDF if model initialization failed\n",
    "                print(\"Warning: Falling back to TF-IDF due to missing embedding model\")\n",
    "                return calculate_similarity_with_method(line1, line2, 'tfidf')\n",
    "                \n",
    "            # Generate embeddings\n",
    "            embedding1 = sentence_model.encode([processed_line1])[0]\n",
    "            embedding2 = sentence_model.encode([processed_line2])[0]\n",
    "            \n",
    "            # Calculate cosine similarity between embeddings\n",
    "            similarity = cosine_similarity([embedding1], [embedding2])[0][0]\n",
    "            similarity = min(1.0, similarity + extra_similarity)  # Cap at 1.0\n",
    "            return similarity\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error calculating embedding similarity: {e}\")\n",
    "            # Fall back to TF-IDF\n",
    "            return calculate_similarity_with_method(line1, line2, 'tfidf')\n",
    "    \n",
    "    else:\n",
    "        print(f\"Warning: Unknown similarity method '{method}', falling back to TF-IDF\")\n",
    "        return calculate_similarity_with_method(line1, line2, 'tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04a5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sql_query(query):\n",
    "    \"\"\"\n",
    "    Format a SQL query for better readability.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query : str\n",
    "        The SQL query to format\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        The formatted SQL query\n",
    "    \"\"\"\n",
    "    if query is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # Ensure query is a string\n",
    "    if not isinstance(query, str):\n",
    "        query = str(query)\n",
    "    \n",
    "    # Clean up the query\n",
    "    query = query.strip()\n",
    "    \n",
    "    # Remove extra quotes at the beginning and end if present\n",
    "    if (query.startswith('\"') and query.endswith('\"')) or \\\n",
    "       (query.startswith(\"'\") and query.endswith(\"'\")):\n",
    "        query = query[1:-1]\n",
    "    \n",
    "    # If empty after cleanup, return empty string\n",
    "    if not query:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Format using sqlparse\n",
    "        formatted_query = sqlparse.format(\n",
    "            query,\n",
    "            reindent=True,\n",
    "            keyword_case='upper',\n",
    "            strip_comments=True\n",
    "        )\n",
    "        return formatted_query\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not format SQL query: {e}\")\n",
    "        # Return the original query if formatting fails\n",
    "        return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3256fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_sql(query):\n",
    "    \"\"\"\n",
    "    Apply syntax highlighting to SQL code.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query : str\n",
    "        The SQL query to highlight\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        HTML string with highlighted SQL\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return \"\"\n",
    "    \n",
    "    try:\n",
    "        # Use Pygments for syntax highlighting\n",
    "        highlighted = highlight(\n",
    "            query,\n",
    "            SqlLexer(),\n",
    "            HtmlFormatter(style='default', noclasses=True)\n",
    "        )\n",
    "        return highlighted\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not highlight SQL query: {e}\")\n",
    "        return f\"<pre>{query}</pre>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a41938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_where_conditions(where_content):\n",
    "    \"\"\"\n",
    "    Split WHERE clause conditions into individual conditions while respecting\n",
    "    parentheses, quotes, and subqueries.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    where_content : str\n",
    "        The WHERE clause content to split\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        A list of individual conditions\n",
    "    \"\"\"\n",
    "    from sql_line_comparison_widget_helpers import handle_complex_join_conditions\n",
    "    \n",
    "    # We can reuse the logic from handle_complex_join_conditions since the parsing is similar\n",
    "    return handle_complex_join_conditions(where_content)\n",
    "\n",
    "def parse_sql_into_lines(sql_query):\n",
    "    \"\"\"\n",
    "    Parse a SQL query into meaningful lines (clauses, conditions, etc.) with improved support for subqueries\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sql_query : str\n",
    "        The SQL query to parse\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        A list of tuples (line_type, line_content) representing the parsed lines\n",
    "    \"\"\"\n",
    "    # Import the helper functions for JOIN and ON clause handling\n",
    "    from sql_line_comparison_widget_helpers import split_join_clause, extract_on_clauses_from_joins, handle_complex_join_conditions\n",
    "    \n",
    "    # Basic validation and cleanup\n",
    "    if sql_query is None:\n",
    "        print(\"Warning: SQL query is None\")\n",
    "        return [('EMPTY', '')]\n",
    "        \n",
    "    # Strip whitespace and handle empty queries\n",
    "    sql_query = sql_query.strip() if isinstance(sql_query, str) else \"\"\n",
    "    if not sql_query:\n",
    "        print(\"Warning: SQL query is empty\")\n",
    "        return [('EMPTY', '')]\n",
    "    \n",
    "    # Format the SQL query\n",
    "    formatted_sql = format_sql_query(sql_query)\n",
    "    \n",
    "    # Initialize the result list\n",
    "    parsed_lines = []\n",
    "    \n",
    "    # Handle very simple queries or non-standard SQL\n",
    "    if not re.search(r'\\bSELECT\\b', formatted_sql, re.IGNORECASE):\n",
    "        print(\"No SELECT statement found, treating as custom SQL\")\n",
    "        # Split by semicolons for multiple statements\n",
    "        statements = formatted_sql.split(';')\n",
    "        for stmt in statements:\n",
    "            stmt = stmt.strip()\n",
    "            if stmt:\n",
    "                parsed_lines.append(('SQL Statement', stmt))\n",
    "        \n",
    "        if parsed_lines:\n",
    "            return parsed_lines\n",
    "        else:\n",
    "            return [('FULL QUERY', formatted_sql)]\n",
    "    \n",
    "    # Extract subqueries first to handle them separately\n",
    "    subqueries = extract_subqueries(formatted_sql)\n",
    "    \n",
    "    # Replace subqueries with placeholders in the main query\n",
    "    modified_sql = formatted_sql\n",
    "    subquery_placeholders = {}\n",
    "    \n",
    "    for i, (subquery_type, subquery_content) in enumerate(subqueries):\n",
    "        placeholder = f\"__SUBQUERY_{i}__\"\n",
    "        # Generate a unique signature for this subquery to ensure precise replacements\n",
    "        subquery_signature = f\"({subquery_content})\"\n",
    "        \n",
    "        # For more complex replacements, we'll use a more precise method\n",
    "        # Find the exact position of this subquery in the SQL text\n",
    "        pos = modified_sql.find(subquery_signature)\n",
    "        if pos != -1:\n",
    "            # Replace only at this specific position\n",
    "            modified_sql = modified_sql[:pos] + placeholder + modified_sql[pos + len(subquery_signature):]\n",
    "        else:\n",
    "            # Fallback to regex replacement if direct find fails\n",
    "            # Escape special characters in the subquery content for regex\n",
    "            escaped_content = re.escape(subquery_content)\n",
    "            # Match the subquery with its surrounding parentheses\n",
    "            pattern = f\"\\\\({escaped_content}\\\\)\"\n",
    "            # Replace only one occurrence at a time to avoid confusion with similar subqueries\n",
    "            modified_sql = re.sub(pattern, placeholder, modified_sql, count=1)\n",
    "        \n",
    "        subquery_placeholders[placeholder] = (subquery_type, subquery_content)\n",
    "    \n",
    "    # Use regular expressions to extract main components\n",
    "    # These patterns target specific SQL clauses and their contents\n",
    "    sql_patterns = [\n",
    "        # SELECT clause and items\n",
    "        (r'SELECT\\s+(DISTINCT\\s+)?(.+?)(?=\\s+FROM|\\s*$)', 'SELECT'),\n",
    "        \n",
    "        # FROM clause and tables\n",
    "        (r'FROM\\s+(.+?)(?=\\s+(?:WHERE|GROUP\\s+BY|HAVING|ORDER\\s+BY|LIMIT)|\\s*$)', 'FROM'),\n",
    "        \n",
    "        # JOIN clauses with separate capture groups for table and ON condition\n",
    "        (r'((?:LEFT|RIGHT|INNER|OUTER|CROSS|NATURAL)?\\s*JOIN\\s+.+?)(?:\\s+ON\\s+(.+?))?(?=\\s+(?:LEFT|RIGHT|INNER|OUTER|CROSS|NATURAL)?\\s*JOIN|\\s+(?:WHERE|GROUP\\s+BY|HAVING|ORDER\\s+BY|LIMIT)|\\s*$)', 'JOIN'),\n",
    "        \n",
    "        # WHERE clause and conditions\n",
    "        (r'WHERE\\s+(.+?)(?=\\s+(?:GROUP\\s+BY|HAVING|ORDER\\s+BY|LIMIT)|\\s*$)', 'WHERE'),\n",
    "        \n",
    "        # GROUP BY clause\n",
    "        (r'GROUP\\s+BY\\s+(.+?)(?=\\s+(?:HAVING|ORDER\\s+BY|LIMIT)|\\s*$)', 'GROUP BY'),\n",
    "        \n",
    "        # HAVING clause\n",
    "        (r'HAVING\\s+(.+?)(?=\\s+(?:ORDER\\s+BY|LIMIT)|\\s*$)', 'HAVING'),\n",
    "        \n",
    "        # ORDER BY clause\n",
    "        (r'ORDER\\s+BY\\s+(.+?)(?=\\s+LIMIT|\\s*$)', 'ORDER BY'),\n",
    "        \n",
    "        # LIMIT clause\n",
    "        (r'LIMIT\\s+(.+?)(?=\\s*$)', 'LIMIT'),\n",
    "    ]\n",
    "    \n",
    "    # Extract each component using the patterns\n",
    "    for pattern, line_type in sql_patterns:\n",
    "        try:\n",
    "            matches = re.finditer(pattern, modified_sql, re.DOTALL | re.IGNORECASE)\n",
    "            for match in matches:\n",
    "                if line_type == 'SELECT':\n",
    "                    # For SELECT, split into individual columns\n",
    "                    if match.group(2):\n",
    "                        # More robust column splitting - handles nested functions\n",
    "                        select_items = []\n",
    "                        current_item = \"\"\n",
    "                        paren_count = 0\n",
    "                        \n",
    "                        for char in match.group(2) + ',':  # Add comma to process last item\n",
    "                            if char == ',' and paren_count == 0:\n",
    "                                select_items.append(current_item.strip())\n",
    "                                current_item = \"\"\n",
    "                            else:\n",
    "                                current_item += char\n",
    "                                if char == '(':\n",
    "                                    paren_count += 1\n",
    "                                elif char == ')':\n",
    "                                    paren_count -= 1\n",
    "                        \n",
    "                        for item in select_items:\n",
    "                            item = item.strip()\n",
    "                            if item:\n",
    "                                # Check if this item contains a subquery placeholder\n",
    "                                subquery_found = False\n",
    "                                for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                                    if placeholder in item:\n",
    "                                        # Replace the placeholder with the original subquery\n",
    "                                        real_item = item.replace(placeholder, f\"({sq_content})\")\n",
    "                                        parsed_lines.append(('SELECT item with subquery', real_item))\n",
    "                                        subquery_found = True\n",
    "                                        break\n",
    "                                \n",
    "                                if not subquery_found:\n",
    "                                    parsed_lines.append(('SELECT item', item))\n",
    "                elif line_type == 'FROM':\n",
    "                    # For FROM, extract each table\n",
    "                    if match.group(1):\n",
    "                        # Split the FROM clause by commas but respect subqueries\n",
    "                        from_items = []\n",
    "                        current_item = \"\"\n",
    "                        paren_count = 0\n",
    "                        \n",
    "                        for char in match.group(1) + ',':  # Add comma to process last item\n",
    "                            if char == ',' and paren_count == 0:\n",
    "                                from_items.append(current_item.strip())\n",
    "                                current_item = \"\"\n",
    "                            else:\n",
    "                                current_item += char\n",
    "                                if char == '(':\n",
    "                                    paren_count += 1\n",
    "                                elif char == ')':\n",
    "                                    paren_count -= 1\n",
    "                        \n",
    "                        for item in from_items:\n",
    "                            item = item.strip()\n",
    "                            if item and not re.search(r'^\\s*JOIN\\s+', item, re.IGNORECASE):\n",
    "                                # Check if this item contains a subquery placeholder\n",
    "                                subquery_found = False\n",
    "                                for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                                    if placeholder in item:\n",
    "                                        # Replace the placeholder with the original subquery\n",
    "                                        real_item = item.replace(placeholder, f\"({sq_content})\")\n",
    "                                        parsed_lines.append(('FROM subquery', real_item))\n",
    "                                        subquery_found = True\n",
    "                                        break\n",
    "                                \n",
    "                                if not subquery_found:\n",
    "                                    # Check for aliased subqueries that might not have been caught\n",
    "                                    if re.search(r'\\)\\s+[a-z0-9_]+\\s*$', item, re.IGNORECASE):\n",
    "                                        parsed_lines.append(('FROM subquery', item))\n",
    "                                    else:\n",
    "                                        parsed_lines.append(('FROM table', item))\n",
    "                elif line_type == 'WHERE':\n",
    "                    # For WHERE, split conditions by AND/OR but respect parentheses\n",
    "                    if match.group(1):\n",
    "                        where_content = match.group(1).strip()\n",
    "                        \n",
    "                        # Check if there are subquery placeholders first\n",
    "                        has_placeholders = any(placeholder in where_content for placeholder in subquery_placeholders.keys())\n",
    "                        \n",
    "                        if has_placeholders:\n",
    "                            # If we have placeholders, handle them first before splitting\n",
    "                            processed_where = where_content\n",
    "                            for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                                if placeholder in processed_where:\n",
    "                                    # Replace the placeholder with the original subquery\n",
    "                                    processed_where = processed_where.replace(placeholder, f\"({sq_content})\")\n",
    "                            \n",
    "                            # Now attempt to split by AND/OR with the replaced content\n",
    "                            try:\n",
    "                                # Split the WHERE conditions safely, respecting subqueries and parentheses\n",
    "                                conditions = split_where_conditions(processed_where)\n",
    "                                \n",
    "                                # Add each condition separately\n",
    "                                for condition in conditions:\n",
    "                                    if condition.strip():\n",
    "                                        parsed_lines.append(('WHERE condition with subquery', condition.strip()))\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing WHERE with subqueries: {e}\")\n",
    "                                # Fallback to adding the whole WHERE clause\n",
    "                                parsed_lines.append(('WHERE with subquery', processed_where))\n",
    "                        else:\n",
    "                            # Split the WHERE conditions safely\n",
    "                            conditions = split_where_conditions(where_content)\n",
    "                            \n",
    "                            # Add each condition separately\n",
    "                            for condition in conditions:\n",
    "                                if condition.strip():\n",
    "                                    # Check for subquery placeholders that might have been missed\n",
    "                                    subquery_found = False\n",
    "                                    for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                                        if placeholder in condition:\n",
    "                                            # Replace the placeholder with the original subquery\n",
    "                                            real_condition = condition.replace(placeholder, f\"({sq_content})\")\n",
    "                                            parsed_lines.append(('WHERE condition with subquery', real_condition.strip()))\n",
    "                                            subquery_found = True\n",
    "                                            break\n",
    "                                    \n",
    "                                    if not subquery_found:\n",
    "                                        parsed_lines.append(('WHERE condition', condition.strip()))\n",
    "                elif line_type == 'JOIN':\n",
    "                    # For JOIN, handle the table part and ON condition separately\n",
    "                    join_clause = match.group(1).strip()\n",
    "                    on_condition = match.group(2).strip() if match.group(2) else \"\"\n",
    "                    \n",
    "                    # Use the helper function to separate JOIN table from ON condition\n",
    "                    table_part, on_part = split_join_clause(join_clause)\n",
    "                    \n",
    "                    if table_part:\n",
    "                        # Check for subquery placeholders in JOIN table part\n",
    "                        subquery_found = False\n",
    "                        for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                            if placeholder in table_part:\n",
    "                                # Replace the placeholder with the original subquery\n",
    "                                real_table = table_part.replace(placeholder, f\"({sq_content})\")\n",
    "                                parsed_lines.append(('JOIN table subquery', real_table))\n",
    "                                subquery_found = True\n",
    "                                break\n",
    "                        \n",
    "                        if not subquery_found:\n",
    "                            parsed_lines.append(('JOIN table', table_part))\n",
    "                    \n",
    "                    # Handle ON condition separately if it exists\n",
    "                    if on_part:\n",
    "                        # Check for subquery placeholders in ON conditions\n",
    "                        subquery_found = False\n",
    "                        for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                            if placeholder in on_part:\n",
    "                                # Replace the placeholder with the original subquery\n",
    "                                real_condition = on_part.replace(placeholder, f\"({sq_content})\")\n",
    "                                parsed_lines.append(('JOIN ON condition with subquery', real_condition))\n",
    "                                subquery_found = True\n",
    "                                break\n",
    "                        \n",
    "                        if not subquery_found:\n",
    "                            # Split the ON condition by AND/OR for better granularity\n",
    "                            on_conditions = handle_complex_join_conditions(on_part)\n",
    "                            for condition in on_conditions:\n",
    "                                parsed_lines.append(('JOIN ON condition', condition))\n",
    "                else:\n",
    "                    # For other clauses, add the whole match\n",
    "                    content = match.group(1).strip()\n",
    "                    if content:\n",
    "                        # Check for subquery placeholders in other clauses\n",
    "                        subquery_found = False\n",
    "                        for placeholder, (sq_type, sq_content) in subquery_placeholders.items():\n",
    "                            if placeholder in content:\n",
    "                                # Replace the placeholder with the original subquery\n",
    "                                real_content = content.replace(placeholder, f\"({sq_content})\")\n",
    "                                parsed_lines.append((f'{line_type} with subquery', real_content))\n",
    "                                subquery_found = True\n",
    "                                break\n",
    "                        \n",
    "                        if not subquery_found:\n",
    "                            parsed_lines.append((line_type, content))\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing SQL pattern {line_type}: {e}\")\n",
    "    \n",
    "    # Add any subqueries that weren't used in the main query\n",
    "    for subquery_type, subquery_content in subqueries:\n",
    "        # Check if this subquery wasn't included already\n",
    "        found = False\n",
    "        for line_type, line_content in parsed_lines:\n",
    "            if f\"({subquery_content})\" in line_content:\n",
    "                found = True\n",
    "                break\n",
    "                \n",
    "        if not found:\n",
    "            # Add as a standalone subquery\n",
    "            parsed_lines.append((f'Independent {subquery_type}', f\"({subquery_content})\"))\n",
    "    \n",
    "    # If we didn't parse anything meaningful, but we have SQL text, return the full query\n",
    "    if not parsed_lines and formatted_sql:\n",
    "        parsed_lines.append(('FULL QUERY', formatted_sql))\n",
    "    \n",
    "    # If still empty, mark as empty query\n",
    "    if not parsed_lines:\n",
    "        parsed_lines.append(('EMPTY', ''))\n",
    "    \n",
    "    # print(f\"Parsed lines: {parsed_lines}\")\n",
    "    return parsed_lines\n",
    "\n",
    "def extract_subqueries(sql_query):\n",
    "    \"\"\"\n",
    "    Extract subqueries from a SQL query with enhanced detection capabilities\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    sql_query : str\n",
    "        The SQL query to extract subqueries from\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        A list of tuples (subquery_type, subquery_content)\n",
    "    \"\"\"\n",
    "    subqueries = []\n",
    "    \n",
    "    # Helper function to scan for SELECT keyword\n",
    "    def has_select_keyword(text, start_pos, scan_length=20):\n",
    "        \"\"\"Check if text contains SELECT keyword within scan_length chars from start_pos\"\"\"\n",
    "        for j in range(start_pos, min(start_pos + scan_length, len(text))):\n",
    "            if text[j:j+6].upper() == 'SELECT':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    # Helper function to extract subquery content\n",
    "    def extract_subquery_content(text, start_pos):\n",
    "        \"\"\"\n",
    "        Extract subquery content from text starting at start_pos\n",
    "        Returns tuple: (end_position, subquery_content, is_subquery)\n",
    "        \"\"\"\n",
    "        paren_count = 1  # Already encountered the opening parenthesis\n",
    "        content = \"\"\n",
    "        i = start_pos\n",
    "        \n",
    "        # Check if this might be a subquery by looking for SELECT\n",
    "        if not has_select_keyword(text, i):\n",
    "            # Skip to matching closing parenthesis for non-subquery\n",
    "            while i < len(text) and paren_count > 0:\n",
    "                if text[i] == '(':\n",
    "                    paren_count += 1\n",
    "                elif text[i] == ')':\n",
    "                    paren_count -= 1\n",
    "                if paren_count > 0:\n",
    "                    content += text[i]\n",
    "                i += 1\n",
    "            return i, content, False\n",
    "        \n",
    "        # Extract the subquery content\n",
    "        in_quotes = False\n",
    "        quote_char = None\n",
    "        \n",
    "        while i < len(text) and paren_count > 0:\n",
    "            # Handle quoted strings to avoid misinterpreting parentheses in strings\n",
    "            if text[i] in ['\"', \"'\"]:\n",
    "                if not in_quotes:\n",
    "                    in_quotes = True\n",
    "                    quote_char = text[i]\n",
    "                elif text[i] == quote_char:\n",
    "                    in_quotes = False\n",
    "                    quote_char = None\n",
    "            \n",
    "            # Only count parentheses when not in quotes\n",
    "            if not in_quotes:\n",
    "                if text[i] == '(':\n",
    "                    paren_count += 1\n",
    "                elif text[i] == ')':\n",
    "                    paren_count -= 1\n",
    "            \n",
    "            # Only add to content if we're still inside the subquery\n",
    "            # This ensures we don't include the closing parenthesis\n",
    "            if paren_count > 0:\n",
    "                content += text[i]\n",
    "            i += 1\n",
    "        \n",
    "        # Return the exact position after the closing parenthesis\n",
    "        return i, content.strip(), True\n",
    "    \n",
    "    # Process SQL string for common escape patterns\n",
    "    # This helps avoid false positives in string literals\n",
    "    def preprocess_sql(sql):\n",
    "        # Replace string literals temporarily\n",
    "        in_single_quote = False\n",
    "        in_double_quote = False\n",
    "        escaped = False\n",
    "        processed_sql = \"\"\n",
    "        \n",
    "        for char in sql:\n",
    "            if char == \"'\" and not in_double_quote and not escaped:\n",
    "                in_single_quote = not in_single_quote\n",
    "                processed_sql += char\n",
    "            elif char == '\"' and not in_single_quote and not escaped:\n",
    "                in_double_quote = not in_double_quote\n",
    "                processed_sql += char\n",
    "            elif char == '\\\\' and not escaped:\n",
    "                escaped = True\n",
    "                processed_sql += char\n",
    "            else:\n",
    "                if escaped:\n",
    "                    escaped = False\n",
    "                processed_sql += ' ' if (in_single_quote or in_double_quote) and char == '(' else char\n",
    "        \n",
    "        return processed_sql\n",
    "    \n",
    "    # Preprocess SQL to handle string literals\n",
    "    processed_sql = preprocess_sql(sql_query)\n",
    "    \n",
    "    # Look for subqueries in SELECT clauses with enhanced SELECT pattern\n",
    "    # This pattern better handles complex SELECT structures\n",
    "    select_pattern = re.compile(r'SELECT\\s+(.*?)(?:\\s+FROM|\\s*$)', re.IGNORECASE | re.DOTALL)\n",
    "    select_matches = select_pattern.finditer(processed_sql)\n",
    "    \n",
    "    for match in select_matches:\n",
    "        select_content = match.group(1)\n",
    "        # Find opening parentheses that might indicate a subquery\n",
    "        i = 0\n",
    "        while i < len(select_content):\n",
    "            if select_content[i] == '(':\n",
    "                i += 1  # Move past the opening parenthesis\n",
    "                end_pos, subquery_content, is_subquery = extract_subquery_content(select_content, i)\n",
    "                i = end_pos\n",
    "                \n",
    "                if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                    subqueries.append(('SELECT subquery', subquery_content))\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    # Look for subqueries in FROM clauses with enhanced pattern\n",
    "    # This pattern better handles multiple FROM sources and JOINs\n",
    "    from_pattern = re.compile(r'FROM\\s+(.*?)(?:\\s+WHERE|\\s+GROUP\\s+BY|\\s+HAVING|\\s+ORDER\\s+BY|\\s+LIMIT|\\s+(?:LEFT|RIGHT|INNER|OUTER|CROSS|NATURAL)?\\s*JOIN|\\s*$)', re.IGNORECASE | re.DOTALL)\n",
    "    from_matches = from_pattern.finditer(processed_sql)\n",
    "    \n",
    "    for match in from_matches:\n",
    "        from_content = match.group(1)\n",
    "        i = 0\n",
    "        while i < len(from_content):\n",
    "            if from_content[i] == '(':\n",
    "                i += 1  # Move past the opening parenthesis\n",
    "                end_pos, subquery_content, is_subquery = extract_subquery_content(from_content, i)\n",
    "                i = end_pos\n",
    "                \n",
    "                if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                    # Check if this is an aliased subquery\n",
    "                    if i < len(from_content) and re.match(r'\\s+(?:AS\\s+)?[a-z0-9_]+', from_content[i:i+20], re.IGNORECASE):\n",
    "                        subqueries.append(('FROM aliased subquery', subquery_content))\n",
    "                    else:\n",
    "                        subqueries.append(('FROM subquery', subquery_content))\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    # Look for subqueries in WHERE clauses with enhanced pattern\n",
    "    # This pattern better handles complex WHERE conditions\n",
    "    where_pattern = re.compile(r'WHERE\\s+(.*?)(?:\\s+GROUP\\s+BY|\\s+HAVING|\\s+ORDER\\s+BY|\\s+LIMIT|\\s*$)', re.IGNORECASE | re.DOTALL)\n",
    "    where_matches = where_pattern.finditer(processed_sql)\n",
    "    \n",
    "    for match in where_matches:\n",
    "        where_content = match.group(1)\n",
    "        i = 0\n",
    "        while i < len(where_content):\n",
    "            if where_content[i] == '(':\n",
    "                # Check if this is a logical grouping or a subquery\n",
    "                # Look ahead for SELECT or common subquery markers like IN, EXISTS\n",
    "                in_subquery_context = False\n",
    "                for j in range(max(0, i-10), i):\n",
    "                    fragment = where_content[j:i].upper()\n",
    "                    if any(marker in fragment for marker in [' IN ', ' EXISTS ', ' ANY ', ' ALL ', ' SOME ']):\n",
    "                        in_subquery_context = True\n",
    "                        break\n",
    "                \n",
    "                i += 1  # Move past the opening parenthesis\n",
    "                end_pos, subquery_content, is_subquery = extract_subquery_content(where_content, i)\n",
    "                i = end_pos\n",
    "                \n",
    "                if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                    # Determine the specific type of WHERE subquery\n",
    "                    if in_subquery_context:\n",
    "                        subqueries.append(('WHERE operator subquery', subquery_content))\n",
    "                    else:\n",
    "                        subqueries.append(('WHERE subquery', subquery_content))\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    # Look for subqueries in JOIN clauses with enhanced pattern\n",
    "    # This pattern better separates table and condition parts\n",
    "    join_pattern = re.compile(r'((?:LEFT|RIGHT|INNER|OUTER|CROSS|NATURAL)?\\s*JOIN)\\s+(.+?)(?:\\s+ON\\s+(.+?))?(?=\\s+(?:LEFT|RIGHT|INNER|OUTER|CROSS|NATURAL)?\\s*JOIN|\\s+WHERE|\\s+GROUP\\s+BY|\\s+HAVING|\\s+ORDER\\s+BY|\\s+LIMIT|\\s*$)', re.IGNORECASE | re.DOTALL)\n",
    "    join_matches = join_pattern.finditer(processed_sql)\n",
    "    \n",
    "    for match in join_matches:\n",
    "        join_type = match.group(1)\n",
    "        join_table = match.group(2)\n",
    "        join_condition = match.group(3) if match.group(3) else \"\"\n",
    "        \n",
    "        # Process the table part (check for subqueries)\n",
    "        i = 0\n",
    "        while i < len(join_table):\n",
    "            if join_table[i] == '(':\n",
    "                i += 1  # Move past the opening parenthesis\n",
    "                end_pos, subquery_content, is_subquery = extract_subquery_content(join_table, i)\n",
    "                i = end_pos\n",
    "                \n",
    "                if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                    # Check if this is an aliased subquery\n",
    "                    alias_match = re.search(r'\\)\\s+(?:AS\\s+)?([a-z0-9_]+)', join_table[i-1:], re.IGNORECASE)\n",
    "                    if alias_match:\n",
    "                        subqueries.append(('JOIN aliased table subquery', subquery_content))\n",
    "                    else:\n",
    "                        subqueries.append(('JOIN table subquery', subquery_content))\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Process the ON condition separately if it exists\n",
    "        if join_condition:\n",
    "            i = 0\n",
    "            while i < len(join_condition):\n",
    "                if join_condition[i] == '(':\n",
    "                    i += 1  # Move past the opening parenthesis\n",
    "                    end_pos, subquery_content, is_subquery = extract_subquery_content(join_condition, i)\n",
    "                    i = end_pos\n",
    "                    \n",
    "                    if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                        subqueries.append(('JOIN ON condition subquery', subquery_content))\n",
    "                else:\n",
    "                    i += 1\n",
    "    \n",
    "    # Look for subqueries in HAVING clauses\n",
    "    having_pattern = re.compile(r'HAVING\\s+(.*?)(?:\\s+ORDER\\s+BY|\\s+LIMIT|\\s*$)', re.IGNORECASE | re.DOTALL)\n",
    "    for match in having_pattern.finditer(processed_sql):\n",
    "        having_content = match.group(1)\n",
    "        i = 0\n",
    "        while i < len(having_content):\n",
    "            if having_content[i] == '(':\n",
    "                i += 1  # Move past the opening parenthesis\n",
    "                end_pos, subquery_content, is_subquery = extract_subquery_content(having_content, i)\n",
    "                i = end_pos\n",
    "                \n",
    "                if is_subquery and subquery_content and 'SELECT' in subquery_content.upper():\n",
    "                    subqueries.append(('HAVING subquery', subquery_content))\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    # Additional check for nested subqueries inside already extracted subqueries\n",
    "    additional_subqueries = []\n",
    "    for _, content in subqueries:\n",
    "        # Check if this subquery contains other subqueries\n",
    "        i = 0\n",
    "        while i < len(content):\n",
    "            if content[i] == '(':\n",
    "                i += 1\n",
    "                if has_select_keyword(content, i):\n",
    "                    end_pos, nested_content, is_subquery = extract_subquery_content(content, i)\n",
    "                    i = end_pos\n",
    "                    \n",
    "                    if is_subquery and nested_content and 'SELECT' in nested_content.upper():\n",
    "                        # Check if this nested subquery is already in our list\n",
    "                        is_new = True\n",
    "                        for _, existing_content in subqueries + additional_subqueries:\n",
    "                            # Use normalized comparison to avoid false duplicates\n",
    "                            if nested_content.strip().lower() == existing_content.strip().lower():\n",
    "                                is_new = False\n",
    "                                break\n",
    "                                \n",
    "                        if is_new:\n",
    "                            additional_subqueries.append(('Nested subquery', nested_content))\n",
    "                else:\n",
    "                    # Skip non-subquery parentheses\n",
    "                    paren_count = 1\n",
    "                    while i < len(content) and paren_count > 0:\n",
    "                        if content[i] == '(':\n",
    "                            paren_count += 1\n",
    "                        elif content[i] == ')':\n",
    "                            paren_count -= 1\n",
    "                        i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "    \n",
    "    # Add any additional nested subqueries found\n",
    "    subqueries.extend(additional_subqueries)\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_subqueries = []\n",
    "    for sq_type, sq_content in subqueries:\n",
    "        if sq_content not in seen:\n",
    "            seen.add(sq_content)\n",
    "            unique_subqueries.append((sq_type, sq_content))\n",
    "    \n",
    "    return unique_subqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96841d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_line_comparison_html(associations):\n",
    "    \"\"\"\n",
    "    Generate HTML for line-by-line comparison\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    associations : list\n",
    "        List of dictionaries with matched lines and similarity scores\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        HTML string for the comparison visualization\n",
    "    \"\"\"\n",
    "    # Add debug information\n",
    "    print(f\"Generating HTML for {len(associations)} associations\")\n",
    "    \n",
    "    if not associations:\n",
    "        return '<div class=\"error-container\">No line associations to display.</div>'\n",
    "    \n",
    "    html_parts = ['<table class=\"line-comparison-table\">']    \n",
    "    html_parts.append('<tr><th>Line Type</th><th>Gold Query</th><th>Similarity</th><th>Predicted Query</th></tr>')\n",
    "    \n",
    "    for assoc in associations:\n",
    "        gold_content = assoc.get('gold_content', \"\")\n",
    "        pred_content = assoc.get('pred_content', \"\")\n",
    "        line_type = assoc.get('gold_type', assoc.get('pred_type', \"Unknown\"))\n",
    "        similarity = assoc.get('similarity', 0)\n",
    "        \n",
    "        # Format similarity for display\n",
    "        similarity_display = f\"{similarity:.2f}\" if similarity > 0 else \"-\"\n",
    "        \n",
    "        # Determine cell classes based on matching status\n",
    "        gold_class = \"matched-content\" if similarity > 0 else \"unmatched-content\" if gold_content else \"missing-content\"\n",
    "        pred_class = \"matched-content\" if similarity > 0 else \"unmatched-content\" if pred_content else \"missing-content\"\n",
    "        \n",
    "        # Row opening\n",
    "        html_parts.append(f'<tr class=\"{\"matched-line\" if similarity > 0 else \"\"}\">') \n",
    "        \n",
    "        # Line type cell\n",
    "        html_parts.append(f'<td class=\"line-type\">{line_type}</td>')\n",
    "        \n",
    "        # Gold content cell\n",
    "        if gold_content:\n",
    "            html_parts.append(f'<td class=\"gold-content {gold_class}\">{gold_content}</td>')\n",
    "        else:\n",
    "            html_parts.append(f'<td class=\"gold-content missing-line\">No matching line</td>')\n",
    "        \n",
    "        # Similarity cell\n",
    "        html_parts.append(f'<td class=\"similarity\">{similarity_display}</td>')\n",
    "        \n",
    "        # Predicted content cell\n",
    "        if pred_content:\n",
    "            html_parts.append(f'<td class=\"pred-content {pred_class}\">{pred_content}</td>')\n",
    "        else:\n",
    "            html_parts.append(f'<td class=\"pred-content missing-line\">No matching line</td>')\n",
    "        \n",
    "        # Row closing\n",
    "        html_parts.append('</tr>')\n",
    "    \n",
    "    html_parts.append('</table>')\n",
    "    return ''.join(html_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393b55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLLineComparisonWidget:\n",
    "    \"\"\"\n",
    "    An interactive widget for visualizing and comparing SQL query predictions\n",
    "    line by line with the gold queries in a Text-to-SQL task.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_dict, df_train=None, df_test=None, similarity_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the widget with a dictionary of result dictionaries.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        results_dict : dict\n",
    "            Dictionary where keys are 'model_name-experiment_name' and values are lists of result dictionaries\n",
    "        df_train : pandas.DataFrame, optional\n",
    "            DataFrame containing training data with requests and knowledge\n",
    "        df_test : pandas.DataFrame, optional\n",
    "            DataFrame containing test data with requests and knowledge\n",
    "        similarity_threshold : float\n",
    "            Threshold for similarity to consider lines as associated\n",
    "        \"\"\"\n",
    "        self.results_dict = results_dict\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        \n",
    "        # Extract model and experiment data from the keys\n",
    "        self.model_experiment_map = {}\n",
    "        for key in results_dict.keys():\n",
    "            if '-' in key:\n",
    "                model, experiment = key.split('-', 1)\n",
    "                if model not in self.model_experiment_map:\n",
    "                    self.model_experiment_map[model] = []\n",
    "                self.model_experiment_map[model].append(experiment)\n",
    "        \n",
    "        # Sort the experiments for each model\n",
    "        for model in self.model_experiment_map:\n",
    "            self.model_experiment_map[model] = sorted(self.model_experiment_map[model])\n",
    "        \n",
    "        # Flatten results for initial processing\n",
    "        self.all_results = []\n",
    "        for result_list in results_dict.values():\n",
    "            self.all_results.extend(result_list)\n",
    "        \n",
    "        # Extract unique request IDs\n",
    "        self.req_ids = sorted(list(set([r['req_id'] for r in self.all_results])))\n",
    "        \n",
    "        # Extract unique models and experiments\n",
    "        self.models = sorted(list(self.model_experiment_map.keys()))\n",
    "        if not self.models:\n",
    "            self.models = ['All']\n",
    "        \n",
    "        # Extract unique difficulties\n",
    "        self.difficulties = sorted(list(set([r.get('difficulty', 'unknown') for r in self.all_results if 'difficulty' in r])))\n",
    "        self.difficulties = ['All'] + self.difficulties\n",
    "        \n",
    "        # Set up CSS styles for the UI\n",
    "        self.setup_styles()\n",
    "        \n",
    "        # Create widgets\n",
    "        self.create_widgets()\n",
    "        \n",
    "        # Connect event handlers\n",
    "        self.setup_event_handlers()\n",
    "        \n",
    "        # Display the widget\n",
    "        self.display_widget()\n",
    "    \n",
    "    def setup_styles(self):\n",
    "        \"\"\"Define CSS styles for the UI components.\"\"\"\n",
    "        self.style_html = \"\"\"\n",
    "        <style>\n",
    "            /* Base container styles */\n",
    "            .widget-container {\n",
    "                max-width: 100%;\n",
    "                margin: 10px 0;\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "            \n",
    "            /* Control panel styles */\n",
    "            .control-panel {\n",
    "                display: flex;\n",
    "                flex-wrap: wrap;\n",
    "                gap: 10px;\n",
    "                margin-bottom: 15px;\n",
    "                background-color: #f5f5f5;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "            }\n",
    "            \n",
    "            /* Line comparison table styles */\n",
    "            .line-comparison-table {\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin: 10px 0;\n",
    "                font-family: monospace;\n",
    "                table-layout: fixed; /* Add fixed table layout for better control */\n",
    "            }\n",
    "            \n",
    "            .line-comparison-table th {\n",
    "                background-color: #f2f2f2;\n",
    "                padding: 8px;\n",
    "                text-align: left;\n",
    "                border: 1px solid #ddd;\n",
    "                position: sticky;\n",
    "                top: 0;\n",
    "                z-index: 10;\n",
    "            }\n",
    "            \n",
    "            .line-comparison-table td {\n",
    "                padding: 8px;\n",
    "                border: 1px solid #ddd;\n",
    "                vertical-align: top;\n",
    "                word-wrap: break-word; /* Enable word wrapping */\n",
    "                overflow-wrap: break-word; /* Modern browsers */\n",
    "                word-break: break-word; /* For better line breaks */\n",
    "                max-width: 0; /* Force text wrapping */\n",
    "            }\n",
    "            \n",
    "            .line-type {\n",
    "                font-weight: bold;\n",
    "                width: 15%;\n",
    "                background-color: #f8f8f8;\n",
    "            }\n",
    "            \n",
    "            .gold-content, .pred-content {\n",
    "                width: 38%; /* Slightly smaller to accommodate other columns */\n",
    "                white-space: pre-wrap;\n",
    "                overflow-x: auto; /* Add horizontal scrolling if needed */\n",
    "            }\n",
    "            \n",
    "            .similarity {\n",
    "                width: 9%; /* Fixed width for similarity column */\n",
    "                text-align: center;\n",
    "            }\n",
    "                width: 5%;\n",
    "                text-align: center;\n",
    "            }\n",
    "            \n",
    "            /* Line matching styles */\n",
    "            .matched-line {\n",
    "                background-color: #f9f9f9;\n",
    "            }\n",
    "            \n",
    "            .matched-content {\n",
    "                background-color: #e6ffed;\n",
    "                border-left: 3px solid #22863a;\n",
    "            }\n",
    "            \n",
    "            .unmatched-content {\n",
    "                background-color: #ffeef0;\n",
    "                border-left: 3px solid #cb2431;\n",
    "            }\n",
    "            \n",
    "            .missing-content {\n",
    "                background-color: #f8f8f8;\n",
    "            }\n",
    "            \n",
    "            /* Missing line indicator */\n",
    "            .missing-line {\n",
    "                color: #cb2431;\n",
    "                font-style: italic;\n",
    "            }\n",
    "            \n",
    "            /* Metadata container styles */\n",
    "            .metadata-container {\n",
    "                background-color: #e3f2fd;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "            }\n",
    "            \n",
    "            /* Request container styles */\n",
    "            .request-container {\n",
    "                background-color: #e8eaf6;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "                border-left: 4px solid #3f51b5;\n",
    "            }\n",
    "            \n",
    "            /* Knowledge container styles */\n",
    "            .knowledge-container {\n",
    "                background-color: #f3e5f5;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "                border-left: 4px solid #9c27b0;\n",
    "            }\n",
    "            \n",
    "            /* Summary container styles */\n",
    "            .summary-container {\n",
    "                background-color: #fff8e1;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "                border: 1px solid #ffe082;\n",
    "                overflow-x: auto; /* Add horizontal scrolling for wide content */\n",
    "                word-wrap: break-word; /* Enable word wrapping */\n",
    "                overflow-wrap: break-word; /* For modern browsers */\n",
    "            }\n",
    "            \n",
    "            /* Make sure pre elements in summary containers don't overflow */\n",
    "            .summary-container pre {\n",
    "                white-space: pre-wrap; /* Preserve formatting but wrap text */\n",
    "                word-break: break-word; /* Break words to prevent overflow */\n",
    "                max-width: 100%; /* Ensure content stays within container */\n",
    "            }\n",
    "            \n",
    "            /* Style for the flex layout in raw queries */\n",
    "            .summary-container .flex-container {\n",
    "                display: flex;\n",
    "                flex-wrap: wrap; /* Allow wrapping on smaller screens */\n",
    "                gap: 20px;\n",
    "            }\n",
    "            \n",
    "            .summary-container .flex-item {\n",
    "                flex: 1 1 300px; /* Grow, shrink, and minimum width */\n",
    "                min-width: 0; /* Allow flex items to shrink below content size */\n",
    "            }\n",
    "            \n",
    "            /* Error container styles */\n",
    "            .error-container {\n",
    "                background-color: #ffebee;\n",
    "                color: #c62828;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "                border-left: 4px solid #c62828;\n",
    "            }\n",
    "            \n",
    "            /* Success container styles */\n",
    "            .success-container {\n",
    "                background-color: #e8f5e9;\n",
    "                color: #2e7d32;\n",
    "                padding: 10px;\n",
    "                border-radius: 5px;\n",
    "                margin: 10px 0;\n",
    "                border-left: 4px solid #2e7d32;\n",
    "            }\n",
    "            \n",
    "            /* Similarity slider container */\n",
    "            .similarity-slider-container {\n",
    "                margin: 10px 0;\n",
    "                padding: 10px;\n",
    "                background-color: #f0f0f0;\n",
    "                border-radius: 5px;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "        display(HTML(self.style_html))\n",
    "    \n",
    "    def create_widgets(self):\n",
    "        \"\"\"Create the widgets for the UI.\"\"\"\n",
    "        # Model selector\n",
    "        self.model_dropdown = widgets.Dropdown(\n",
    "            options=self.models,\n",
    "            value=self.models[0] if self.models else None,\n",
    "            description='Model:',\n",
    "            disabled=False if self.models and self.models[0] != 'All' else True,\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Experiment selector\n",
    "        self.experiment_dropdown = widgets.Dropdown(\n",
    "            description='Experiment:',\n",
    "            disabled=False if self.model_experiment_map else True,\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Update experiment options based on model\n",
    "        if self.model_experiment_map and self.models and self.models[0] != 'All':\n",
    "            self.experiment_dropdown.options = ['All'] + self.model_experiment_map.get(self.models[0], [])\n",
    "            self.experiment_dropdown.value = 'All'\n",
    "        \n",
    "        # Difficulty selector\n",
    "        self.difficulty_dropdown = widgets.Dropdown(\n",
    "            options=self.difficulties,\n",
    "            value='All',\n",
    "            description='Difficulty:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        # Request ID selector\n",
    "        self.req_id_dropdown = widgets.Dropdown(\n",
    "            options=self.req_ids,\n",
    "            description='Request ID:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Search box\n",
    "        self.search_box = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='Search queries...',\n",
    "            description='Search:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='300px')\n",
    "        )\n",
    "        \n",
    "        # Search button\n",
    "        self.search_button = widgets.Button(\n",
    "            description='Search',\n",
    "            disabled=False,\n",
    "            button_style='info',\n",
    "            tooltip='Search for queries containing the text',\n",
    "            icon='search'\n",
    "        )\n",
    "        \n",
    "        # Similarity method selector\n",
    "        self.similarity_method_dropdown = widgets.Dropdown(\n",
    "            options=['tfidf', 'jaccard', 'embedding'],\n",
    "            value='tfidf',\n",
    "            description='Similarity Method:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        # Similarity threshold slider\n",
    "        self.similarity_slider = widgets.FloatSlider(\n",
    "            value=self.similarity_threshold,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.05,\n",
    "            description='Similarity Threshold:',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='.2f',\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "        \n",
    "        # Update button\n",
    "        self.update_button = widgets.Button(\n",
    "            description='Update Comparison',\n",
    "            disabled=False,\n",
    "            button_style='primary',\n",
    "            tooltip='Update the comparison with new threshold',\n",
    "            icon='refresh'\n",
    "        )\n",
    "        \n",
    "        # Show raw queries toggle\n",
    "        self.show_raw_queries_toggle = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Show Raw Queries',\n",
    "            disabled=False,\n",
    "            indent=False,\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        \n",
    "        # Results display\n",
    "        self.output = widgets.Output()\n",
    "    \n",
    "    def setup_event_handlers(self):\n",
    "        \"\"\"Connect the widget event handlers.\"\"\"\n",
    "        # When model changes, update experiments\n",
    "        self.model_dropdown.observe(self.on_model_change, names='value')\n",
    "        \n",
    "        # When experiment, difficulty, or request ID changes, update display\n",
    "        self.experiment_dropdown.observe(self.on_params_change, names='value')\n",
    "        self.difficulty_dropdown.observe(self.on_params_change, names='value')\n",
    "        self.req_id_dropdown.observe(self.on_req_id_change, names='value')\n",
    "        \n",
    "        # When search button is clicked, perform search\n",
    "        self.search_button.on_click(self.on_search)\n",
    "        self.search_box.on_submit(self.on_search)\n",
    "        \n",
    "        # When update button is clicked, refresh the comparison\n",
    "        self.update_button.on_click(self.on_update)\n",
    "        \n",
    "        # When similarity method changes, update the display\n",
    "        self.similarity_method_dropdown.observe(self.on_similarity_method_change, names='value')\n",
    "        \n",
    "        # When show raw queries toggle changes, update the display\n",
    "        self.show_raw_queries_toggle.observe(self.on_toggle_raw_queries, names='value')\n",
    "    \n",
    "    def on_model_change(self, change):\n",
    "        \"\"\"Handle model selection change.\"\"\"\n",
    "        model = change['new']\n",
    "        if model and model != 'All' and model in self.model_experiment_map:\n",
    "            self.experiment_dropdown.options = ['All'] + self.model_experiment_map[model]\n",
    "            self.experiment_dropdown.value = 'All'\n",
    "        else:\n",
    "            self.experiment_dropdown.options = ['All']\n",
    "            self.experiment_dropdown.value = 'All'\n",
    "    \n",
    "    def on_params_change(self, change):\n",
    "        \"\"\"Handle parameter changes (model, experiment, difficulty).\"\"\"\n",
    "        self.filter_req_ids()\n",
    "    \n",
    "    def on_req_id_change(self, change):\n",
    "        \"\"\"Handle request ID selection change.\"\"\"\n",
    "        self.update_display()\n",
    "    \n",
    "    def on_search(self, button=None):\n",
    "        \"\"\"Handle search action.\"\"\"\n",
    "        search_text = self.search_box.value.lower()\n",
    "        if not search_text:\n",
    "            self.filter_req_ids()\n",
    "            return\n",
    "        \n",
    "        filtered_req_ids = []\n",
    "        for result_list in self.results_dict.values():\n",
    "            for result in result_list:\n",
    "                req_id = result['req_id']\n",
    "                \n",
    "                # Get gold and predicted queries\n",
    "                if 'comparison' in result and isinstance(result['comparison'], dict):\n",
    "                    comparison = result['comparison']\n",
    "                    gold_query = comparison.get('gold_query', '')\n",
    "                    pred_query = comparison.get('pred_query', '')\n",
    "                    \n",
    "                    # Check if search text is in either query\n",
    "                    if (search_text in gold_query.lower() or \n",
    "                        search_text in pred_query.lower()):\n",
    "                        filtered_req_ids.append(req_id)\n",
    "        \n",
    "        # Update the request ID dropdown\n",
    "        filtered_req_ids = sorted(list(set(filtered_req_ids)))\n",
    "        if filtered_req_ids:\n",
    "            self.req_id_dropdown.options = filtered_req_ids\n",
    "            self.req_id_dropdown.value = filtered_req_ids[0]\n",
    "        else:\n",
    "            self.req_id_dropdown.options = ['No results']\n",
    "            self.req_id_dropdown.value = 'No results'\n",
    "    \n",
    "    def on_update(self, button=None):\n",
    "        \"\"\"Handle update button click.\"\"\"\n",
    "        self.similarity_threshold = self.similarity_slider.value\n",
    "        self.update_display()\n",
    "    \n",
    "    def on_similarity_method_change(self, change):\n",
    "        \"\"\"Handle change in similarity method.\"\"\"\n",
    "        if change['new'] == 'embedding':\n",
    "            # Ensure the embedding model is initialized\n",
    "            initialize_sentence_model()\n",
    "        self.update_display()\n",
    "    \n",
    "    def on_toggle_raw_queries(self, change):\n",
    "        \"\"\"Handle toggle for showing raw queries.\"\"\"\n",
    "        self.update_display()\n",
    "    \n",
    "    def filter_req_ids(self):\n",
    "        \"\"\"Filter request IDs based on selected model, experiment, and difficulty.\"\"\"\n",
    "        model = self.model_dropdown.value\n",
    "        experiment = self.experiment_dropdown.value\n",
    "        difficulty = self.difficulty_dropdown.value\n",
    "        \n",
    "        filtered_req_ids = []\n",
    "        \n",
    "        for key, result_list in self.results_dict.items():\n",
    "            # Check if this result matches the selected model and experiment\n",
    "            if model != 'All' and not key.startswith(f\"{model}-\"):\n",
    "                continue\n",
    "            if experiment != 'All' and not key.endswith(f\"-{experiment}\"):\n",
    "                continue\n",
    "            \n",
    "            # Add matching request IDs\n",
    "            for result in result_list:\n",
    "                if difficulty != 'All' and result.get('difficulty') != difficulty:\n",
    "                    continue\n",
    "                filtered_req_ids.append(result['req_id'])\n",
    "        \n",
    "        # Update the request ID dropdown\n",
    "        filtered_req_ids = sorted(list(set(filtered_req_ids)))\n",
    "        if filtered_req_ids:\n",
    "            self.req_id_dropdown.options = filtered_req_ids\n",
    "            if self.req_id_dropdown.value not in filtered_req_ids:\n",
    "                self.req_id_dropdown.value = filtered_req_ids[0]\n",
    "        else:\n",
    "            self.req_id_dropdown.options = ['No results']\n",
    "            self.req_id_dropdown.value = 'No results'\n",
    "    \n",
    "    def update_display(self):\n",
    "        \"\"\"Update the display with the selected request ID, model, and experiment.\"\"\"\n",
    "        req_id = self.req_id_dropdown.value\n",
    "        model = self.model_dropdown.value\n",
    "        experiment = self.experiment_dropdown.value\n",
    "\n",
    "        if req_id == 'No results':\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                display(HTML('<div class=\"error-container\">No results found.</div>'))\n",
    "            return\n",
    "        \n",
    "        # Find result(s) matching the request ID\n",
    "        matching_results = []\n",
    "        for key, result_list in self.results_dict.items():\n",
    "            for result in result_list:\n",
    "                if result['req_id'] == req_id and key == f\"{model}-{experiment}\":\n",
    "                    result['model_experiment'] = key\n",
    "                    matching_results.append(result)\n",
    "        \n",
    "        if not matching_results:\n",
    "            with self.output:\n",
    "                clear_output()\n",
    "                display(HTML('<div class=\"error-container\">No matching result found.</div>'))\n",
    "            return\n",
    "        \n",
    "        # Sort results by model and experiment\n",
    "        matching_results.sort(key=lambda r: r['model_experiment'])\n",
    "        \n",
    "        # Display the results\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            \n",
    "            # If multiple results, allow selection\n",
    "            # if len(matching_results) > 1:\n",
    "            #     result_dropdown = widgets.Dropdown(\n",
    "            #         options=[(f\"{r['model_experiment']}\", i) for i, r in enumerate(matching_results)],\n",
    "            #         description='Result:',\n",
    "            #         layout=widgets.Layout(width='400px')\n",
    "            #     )\n",
    "                \n",
    "            #     def on_result_change(change):\n",
    "            #         self.display_single_result(matching_results[change['new']])\n",
    "                \n",
    "            #     result_dropdown.observe(on_result_change, names='value')\n",
    "            #     display(result_dropdown)\n",
    "            #     self.display_single_result(matching_results[0])\n",
    "            # else:\n",
    "            print(matching_results)\n",
    "            self.display_single_result(matching_results[0])\n",
    "    \n",
    "    def display_single_result(self, result):\n",
    "        \"\"\"Display a single result with line-by-line comparison.\"\"\"\n",
    "        if 'comparison' not in result or not isinstance(result['comparison'], dict):\n",
    "            display(HTML('<div class=\"error-container\">No comparison data found.</div>'))\n",
    "            return\n",
    "        \n",
    "        comparison = result['comparison']\n",
    "        gold_query = comparison.get('sql_gold', '')\n",
    "        pred_query = comparison.get('sql_pred', '')\n",
    "        \n",
    "        # Debug info about the queries\n",
    "        print(f\"Gold query type: {type(gold_query)}, length: {len(str(gold_query)) if gold_query else 0}\")\n",
    "        print(f\"Predicted query type: {type(pred_query)}, length: {len(str(pred_query)) if pred_query else 0}\")\n",
    "        \n",
    "        # Ensure queries are strings and clean them up\n",
    "        if gold_query is None:\n",
    "            gold_query = \"\"\n",
    "        elif not isinstance(gold_query, str):\n",
    "            gold_query = str(gold_query)\n",
    "            \n",
    "        if pred_query is None:\n",
    "            pred_query = \"\"\n",
    "        elif not isinstance(pred_query, str):\n",
    "            pred_query = str(pred_query)\n",
    "        \n",
    "        # Remove extra quotes that might be present in the queries\n",
    "        gold_query = gold_query.strip().strip('\"\\'')\n",
    "        pred_query = pred_query.strip().strip('\"\\'')\n",
    "        \n",
    "        # Extract subqueries and nested queries from the gold and predicted queries\n",
    "        gold_subqueries = extract_subqueries(gold_query)\n",
    "        pred_subqueries = extract_subqueries(pred_query)\n",
    "\n",
    "        # Parse queries into lines\n",
    "        gold_lines = parse_sql_into_lines(gold_query)\n",
    "        pred_lines = parse_sql_into_lines(pred_query)\n",
    "\n",
    "        # Debug info about parsed lines\n",
    "        print(f\"Gold lines: {gold_lines}\")\n",
    "        print(f\"Predicted lines: {pred_lines}\")\n",
    "        \n",
    "        # Get the selected similarity method\n",
    "        similarity_method = self.similarity_method_dropdown.value\n",
    "        print(f\"Using similarity method: {similarity_method}\")\n",
    "        \n",
    "        # If using embedding method, initialize the model\n",
    "        if similarity_method == 'embedding' and sentence_model is None:\n",
    "            initialize_sentence_model()\n",
    "        \n",
    "        # Associate lines with the selected method\n",
    "        associations = []\n",
    "        \n",
    "        # Keep track of which lines have been matched\n",
    "        gold_matched = [False] * len(gold_lines)\n",
    "        pred_matched = [False] * len(pred_lines)\n",
    "        \n",
    "        # Calculate similarity matrix\n",
    "        similarity_matrix = np.zeros((len(gold_lines), len(pred_lines)))\n",
    "        \n",
    "        for i, (g_type, g_content) in enumerate(gold_lines):\n",
    "            for j, (p_type, p_content) in enumerate(pred_lines):\n",
    "                # First, try to match lines of the same type\n",
    "                if g_type == p_type:\n",
    "                    similarity = calculate_similarity_with_method(g_content, p_content, similarity_method)\n",
    "                    similarity_matrix[i, j] = similarity\n",
    "                else:\n",
    "                    # If types don't match but both are WHERE conditions or similar, still try to match\n",
    "                    if ('WHERE' in g_type and 'WHERE' in p_type) or \\\n",
    "                       ('SELECT' in g_type and 'SELECT' in p_type) or \\\n",
    "                       ('FROM' in g_type and 'FROM' in p_type) or \\\n",
    "                       ('JOIN' in g_type and 'JOIN' in p_type):\n",
    "                        # Reduce similarity slightly for different subtypes\n",
    "                        similarity = calculate_similarity_with_method(g_content, p_content, similarity_method) * 0.9\n",
    "                        similarity_matrix[i, j] = similarity\n",
    "                    else:\n",
    "                        # similarity_matrix[i, j] = 0\n",
    "                        similarity = calculate_similarity_with_method(g_content, p_content, similarity_method) * 0.75\n",
    "                        similarity_matrix[i, j] = similarity\n",
    "        \n",
    "        # Associate lines greedily from highest to lowest similarity\n",
    "        while np.max(similarity_matrix) > self.similarity_threshold:\n",
    "            # Find the highest similarity\n",
    "            max_i, max_j = np.unravel_index(np.argmax(similarity_matrix), similarity_matrix.shape)\n",
    "            max_sim = similarity_matrix[max_i, max_j]\n",
    "            \n",
    "            # Add the association\n",
    "            associations.append({\n",
    "                'gold_index': max_i,\n",
    "                'gold_type': gold_lines[max_i][0],\n",
    "                'gold_content': gold_lines[max_i][1],\n",
    "                'pred_index': max_j,\n",
    "                'pred_type': pred_lines[max_j][0],\n",
    "                'pred_content': pred_lines[max_j][1],\n",
    "                'similarity': max_sim\n",
    "            })\n",
    "            \n",
    "            # Mark as matched\n",
    "            gold_matched[max_i] = True\n",
    "            pred_matched[max_j] = True\n",
    "            \n",
    "            # Remove these lines from consideration\n",
    "            similarity_matrix[max_i, :] = 0\n",
    "            similarity_matrix[:, max_j] = 0\n",
    "        \n",
    "        # Add unmatched gold lines\n",
    "        for i, (g_type, g_content) in enumerate(gold_lines):\n",
    "            if not gold_matched[i]:\n",
    "                associations.append({\n",
    "                    'gold_index': i,\n",
    "                    'gold_type': g_type,\n",
    "                    'gold_content': g_content,\n",
    "                    'pred_index': None,\n",
    "                    'pred_type': None,\n",
    "                    'pred_content': None,\n",
    "                    'similarity': 0\n",
    "                })\n",
    "        \n",
    "        # Add unmatched predicted lines\n",
    "        for j, (p_type, p_content) in enumerate(pred_lines):\n",
    "            if not pred_matched[j]:\n",
    "                associations.append({\n",
    "                    'gold_index': None,\n",
    "                    'gold_type': None,\n",
    "                    'gold_content': None,\n",
    "                    'pred_index': j,\n",
    "                    'pred_type': p_type,\n",
    "                    'pred_content': p_content,\n",
    "                    'similarity': 0\n",
    "                })\n",
    "        \n",
    "        # Sort by gold index, then pred index\n",
    "        associations.sort(key=lambda x: (\n",
    "            float('inf') if x['gold_index'] is None else x['gold_index'], \n",
    "            float('inf') if x['pred_index'] is None else x['pred_index']\n",
    "        ))\n",
    "        \n",
    "        # Generate HTML\n",
    "        line_comparison_html = generate_line_comparison_html(associations)\n",
    "        \n",
    "        # Get request and knowledge information\n",
    "        req_id = result['req_id']\n",
    "        request_text = ''\n",
    "        knowledge_text = ''\n",
    "        \n",
    "        # Look up in train and test data\n",
    "        for df in [self.df_train, self.df_test]:\n",
    "            if df is not None:\n",
    "                try:\n",
    "                    # Try different ways of matching the ID\n",
    "                    # First, print column names for debugging\n",
    "                    print(f\"DataFrame columns: {df.columns.tolist()}\")\n",
    "                    \n",
    "                    # Check if 'id' or 'req_id' column exists\n",
    "                    id_col = None\n",
    "                    for possible_id_col in ['id', 'req_id', 'ID', 'Id']:\n",
    "                        if possible_id_col in df.columns:\n",
    "                            id_col = possible_id_col\n",
    "                            break\n",
    "                    \n",
    "                    if id_col is not None:\n",
    "                        # Convert req_id to appropriate type for comparison\n",
    "                        try:\n",
    "                            req_id_value = int(req_id)\n",
    "                        except (ValueError, TypeError):\n",
    "                            req_id_value = req_id\n",
    "                            \n",
    "                        # Try to find matching rows\n",
    "                        matching_rows = df[df[id_col] == req_id_value]\n",
    "                        \n",
    "                        # If no match with numerical comparison, try string comparison\n",
    "                        if matching_rows.empty and isinstance(req_id_value, int):\n",
    "                            matching_rows = df[df[id_col] == str(req_id_value)]\n",
    "                        \n",
    "                        if not matching_rows.empty:\n",
    "                            row = matching_rows.iloc[0]\n",
    "                            print(f\"Found matching row with ID {req_id_value}\")\n",
    "                            \n",
    "                            # Check for request column with different possible names\n",
    "                            for req_col in ['request', 'question', 'query', 'text']:\n",
    "                                if req_col in row:\n",
    "                                    request_text = row[req_col]\n",
    "                                    break\n",
    "                            \n",
    "                            # Check for knowledge column with different possible names\n",
    "                            for know_col in ['external_knowledge', 'knowledge', 'schema', 'context']:\n",
    "                                if know_col in row:\n",
    "                                    knowledge_text = row[know_col]\n",
    "                                    break\n",
    "                            for dom_know_col in ['domain_knowledge', 'knowledge', 'schema', 'context']:\n",
    "                                if dom_know_col in row:\n",
    "                                    knowledge_text += f\"\\n {row[dom_know_col]}\"\n",
    "                                    break\n",
    "                            \n",
    "                            break  # Break out of the df loop if we found a match\n",
    "                except Exception as e:\n",
    "                    print(f\"Error looking up request info: {e}\")\n",
    "        \n",
    "        # Display metadata\n",
    "        metadata_html = f\"\"\"\n",
    "        <div class=\"metadata-container\">\n",
    "            <h3>Metadata</h3>\n",
    "            <p><strong>Request ID:</strong> {req_id}</p>\n",
    "            <p><strong>Model:</strong> {result['model_experiment'].split('-')[0]}</p>\n",
    "            <p><strong>Experiment:</strong> {'-'.join(result['model_experiment'].split('-')[1:])}</p>\n",
    "            <p><strong>Difficulty:</strong> {result.get('difficulty', 'Unknown')}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Display request and knowledge\n",
    "        request_html = f\"\"\"\n",
    "        <div class=\"request-container\">\n",
    "            <h3>Request</h3>\n",
    "            <p>{request_text}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        knowledge_html = f\"\"\"\n",
    "        <div class=\"knowledge-container\">\n",
    "            <h3>External Knowledge</h3>\n",
    "            <p>{knowledge_text}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Display raw queries for comparison/debugging\n",
    "        raw_queries_html = f\"\"\"\n",
    "        <div class=\"summary-container\">\n",
    "            <h3>Raw Queries</h3>\n",
    "            <div class=\"flex-container\">\n",
    "                <div class=\"flex-item\">\n",
    "                    <h4>Gold Query</h4>\n",
    "                    <pre style=\"background-color: #f5f5f5; padding: 10px; overflow-x: auto;\">{gold_query}</pre>\n",
    "                </div>\n",
    "                <div class=\"flex-item\">\n",
    "                    <h4>Predicted Query</h4>\n",
    "                    <pre style=\"background-color: #f5f5f5; padding: 10px; overflow-x: auto;\">{pred_query}</pre>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Display summary statistics\n",
    "        matched_count = sum(1 for a in associations if a['similarity'] > 0)\n",
    "        total_gold = sum(1 for a in associations if a['gold_index'] is not None)\n",
    "        total_pred = sum(1 for a in associations if a['pred_index'] is not None)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        gold_coverage = matched_count/max(total_gold, 1) if total_gold > 0 else 0\n",
    "        pred_coverage = matched_count/max(total_pred, 1) if total_pred > 0 else 0\n",
    "        \n",
    "        summary_html = f\"\"\"\n",
    "        <div class=\"summary-container\">\n",
    "            <h3>Comparison Summary</h3>\n",
    "            <p><strong>Matched Lines:</strong> {matched_count}</p>\n",
    "            <p><strong>Gold Lines:</strong> {total_gold}</p>\n",
    "            <p><strong>Predicted Lines:</strong> {total_pred}</p>\n",
    "            <p><strong>Gold Lines:</strong> {gold_lines}</p>\n",
    "            <p><strong>Predicted Lines:</strong> {pred_lines}</p>        \n",
    "            <p><strong>Gold Coverage:</strong> {gold_coverage:.2f} ({matched_count}/{total_gold})</p>\n",
    "            <p><strong>Prediction Coverage:</strong> {pred_coverage:.2f} ({matched_count}/{total_pred})</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Display similarity threshold slider in the results area\n",
    "        similarity_slider_html = f\"\"\"\n",
    "        <div class=\"similarity-slider-container\">\n",
    "            <h3>Adjust Similarity Threshold</h3>\n",
    "            <p>Current threshold: {self.similarity_threshold:.2f}</p>\n",
    "            <p>Higher values require more similarity for lines to match. Lower values are more lenient in matching.</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Display execution information if available\n",
    "        execution_html = \"\"\n",
    "        if 'execution_time' in comparison or 'execution_error' in comparison:\n",
    "            execution_status = \"Failed\" if comparison.get('execution_error') else \"Succeeded\"\n",
    "            execution_time = comparison.get('execution_time', 'N/A')\n",
    "            execution_error = comparison.get('execution_error', 'None')\n",
    "            \n",
    "            execution_html = f\"\"\"\n",
    "            <div class=\"{'error-container' if execution_status == 'Failed' else 'success-container'}\">\n",
    "                <h3>Execution Status: {execution_status}</h3>\n",
    "                <p><strong>Execution Time:</strong> {execution_time}</p>\n",
    "                {f'<p><strong>Error:</strong> {execution_error}</p>' if execution_status == 'Failed' else ''}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Combine all HTML\n",
    "        final_html = f\"\"\"\n",
    "        <div class=\"widget-container\">\n",
    "            {metadata_html}\n",
    "            {request_html}\n",
    "            {knowledge_html}\n",
    "            {raw_queries_html if self.show_raw_queries_toggle.value else ''}\n",
    "            {summary_html}\n",
    "            {similarity_slider_html}\n",
    "            {execution_html}\n",
    "            <h3>Line-by-Line Comparison</h3>\n",
    "            {line_comparison_html}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        display(HTML(final_html))\n",
    "    \n",
    "    def display_widget(self):\n",
    "        \"\"\"Display the complete widget.\"\"\"\n",
    "        # Create the control panel\n",
    "        control_panel = widgets.VBox([\n",
    "            widgets.HBox([\n",
    "                self.model_dropdown,\n",
    "                self.experiment_dropdown,\n",
    "                self.difficulty_dropdown\n",
    "            ]),\n",
    "            widgets.HBox([\n",
    "                self.req_id_dropdown,\n",
    "                self.search_box,\n",
    "                self.search_button\n",
    "            ]),\n",
    "            widgets.HBox([\n",
    "                self.similarity_method_dropdown,\n",
    "                self.similarity_slider,\n",
    "                self.update_button\n",
    "            ]),\n",
    "            widgets.HBox([\n",
    "                self.show_raw_queries_toggle\n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "        # Display the control panel and output\n",
    "        display(HTML('<h2>SQL Line-by-Line Comparison Widget</h2>'))\n",
    "        display(HTML('<div class=\"control-panel\">'))\n",
    "        display(control_panel)\n",
    "        display(HTML('</div>'))\n",
    "        display(self.output)\n",
    "        \n",
    "        # Initialize the display\n",
    "        self.filter_req_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abcd4937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Base container styles */\n",
       "            .widget-container {\n",
       "                max-width: 100%;\n",
       "                margin: 10px 0;\n",
       "                font-family: Arial, sans-serif;\n",
       "            }\n",
       "            \n",
       "            /* Control panel styles */\n",
       "            .control-panel {\n",
       "                display: flex;\n",
       "                flex-wrap: wrap;\n",
       "                gap: 10px;\n",
       "                margin-bottom: 15px;\n",
       "                background-color: #f5f5f5;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "            }\n",
       "            \n",
       "            /* Line comparison table styles */\n",
       "            .line-comparison-table {\n",
       "                width: 100%;\n",
       "                border-collapse: collapse;\n",
       "                margin: 10px 0;\n",
       "                font-family: monospace;\n",
       "                table-layout: fixed; /* Add fixed table layout for better control */\n",
       "            }\n",
       "            \n",
       "            .line-comparison-table th {\n",
       "                background-color: #f2f2f2;\n",
       "                padding: 8px;\n",
       "                text-align: left;\n",
       "                border: 1px solid #ddd;\n",
       "                position: sticky;\n",
       "                top: 0;\n",
       "                z-index: 10;\n",
       "            }\n",
       "            \n",
       "            .line-comparison-table td {\n",
       "                padding: 8px;\n",
       "                border: 1px solid #ddd;\n",
       "                vertical-align: top;\n",
       "                word-wrap: break-word; /* Enable word wrapping */\n",
       "                overflow-wrap: break-word; /* Modern browsers */\n",
       "                word-break: break-word; /* For better line breaks */\n",
       "                max-width: 0; /* Force text wrapping */\n",
       "            }\n",
       "            \n",
       "            .line-type {\n",
       "                font-weight: bold;\n",
       "                width: 15%;\n",
       "                background-color: #f8f8f8;\n",
       "            }\n",
       "            \n",
       "            .gold-content, .pred-content {\n",
       "                width: 38%; /* Slightly smaller to accommodate other columns */\n",
       "                white-space: pre-wrap;\n",
       "                overflow-x: auto; /* Add horizontal scrolling if needed */\n",
       "            }\n",
       "            \n",
       "            .similarity {\n",
       "                width: 9%; /* Fixed width for similarity column */\n",
       "                text-align: center;\n",
       "            }\n",
       "                width: 5%;\n",
       "                text-align: center;\n",
       "            }\n",
       "            \n",
       "            /* Line matching styles */\n",
       "            .matched-line {\n",
       "                background-color: #f9f9f9;\n",
       "            }\n",
       "            \n",
       "            .matched-content {\n",
       "                background-color: #e6ffed;\n",
       "                border-left: 3px solid #22863a;\n",
       "            }\n",
       "            \n",
       "            .unmatched-content {\n",
       "                background-color: #ffeef0;\n",
       "                border-left: 3px solid #cb2431;\n",
       "            }\n",
       "            \n",
       "            .missing-content {\n",
       "                background-color: #f8f8f8;\n",
       "            }\n",
       "            \n",
       "            /* Missing line indicator */\n",
       "            .missing-line {\n",
       "                color: #cb2431;\n",
       "                font-style: italic;\n",
       "            }\n",
       "            \n",
       "            /* Metadata container styles */\n",
       "            .metadata-container {\n",
       "                background-color: #e3f2fd;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "            }\n",
       "            \n",
       "            /* Request container styles */\n",
       "            .request-container {\n",
       "                background-color: #e8eaf6;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "                border-left: 4px solid #3f51b5;\n",
       "            }\n",
       "            \n",
       "            /* Knowledge container styles */\n",
       "            .knowledge-container {\n",
       "                background-color: #f3e5f5;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "                border-left: 4px solid #9c27b0;\n",
       "            }\n",
       "            \n",
       "            /* Summary container styles */\n",
       "            .summary-container {\n",
       "                background-color: #fff8e1;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "                border: 1px solid #ffe082;\n",
       "                overflow-x: auto; /* Add horizontal scrolling for wide content */\n",
       "                word-wrap: break-word; /* Enable word wrapping */\n",
       "                overflow-wrap: break-word; /* For modern browsers */\n",
       "            }\n",
       "            \n",
       "            /* Make sure pre elements in summary containers don't overflow */\n",
       "            .summary-container pre {\n",
       "                white-space: pre-wrap; /* Preserve formatting but wrap text */\n",
       "                word-break: break-word; /* Break words to prevent overflow */\n",
       "                max-width: 100%; /* Ensure content stays within container */\n",
       "            }\n",
       "            \n",
       "            /* Style for the flex layout in raw queries */\n",
       "            .summary-container .flex-container {\n",
       "                display: flex;\n",
       "                flex-wrap: wrap; /* Allow wrapping on smaller screens */\n",
       "                gap: 20px;\n",
       "            }\n",
       "            \n",
       "            .summary-container .flex-item {\n",
       "                flex: 1 1 300px; /* Grow, shrink, and minimum width */\n",
       "                min-width: 0; /* Allow flex items to shrink below content size */\n",
       "            }\n",
       "            \n",
       "            /* Error container styles */\n",
       "            .error-container {\n",
       "                background-color: #ffebee;\n",
       "                color: #c62828;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "                border-left: 4px solid #c62828;\n",
       "            }\n",
       "            \n",
       "            /* Success container styles */\n",
       "            .success-container {\n",
       "                background-color: #e8f5e9;\n",
       "                color: #2e7d32;\n",
       "                padding: 10px;\n",
       "                border-radius: 5px;\n",
       "                margin: 10px 0;\n",
       "                border-left: 4px solid #2e7d32;\n",
       "            }\n",
       "            \n",
       "            /* Similarity slider container */\n",
       "            .similarity-slider-container {\n",
       "                margin: 10px 0;\n",
       "                padding: 10px;\n",
       "                background-color: #f0f0f0;\n",
       "                border-radius: 5px;\n",
       "            }\n",
       "        </style>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>SQL Line-by-Line Comparison Widget</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"control-panel\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386692766b2746b6bffc26ca40126da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Model:', layout=Layout(width='300px'), options=('Qwen2.5',"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8958227cdd4201b73c8785931960a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and display the widget\n",
    "widget = SQLLineComparisonWidget(results_dict, db_train, db_test, similarity_threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efd4d4",
   "metadata": {},
   "source": [
    "## About the SQL Line-by-Line Comparison Widget\n",
    "\n",
    "This widget provides a specialized visualization for comparing SQL queries line by line, focusing on associating similar clauses, conditions, and statements between gold (reference) and predicted SQL queries.\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Line Parsing**: Breaks down SQL queries into meaningful \"lines\" (clauses, conditions, statements) that can be compared individually.\n",
    "\n",
    "2. **Similarity Calculation**: Uses multiple similarity methods to determine how similar each line from the gold query is to each line from the predicted query:\n",
    "   - TF-IDF vectorization and cosine similarity (default)\n",
    "   - Jaccard similarity (set-based comparison)\n",
    "   - Word embeddings (neural semantic similarity)\n",
    "   \n",
    "   See `similarity_methods_documentation.md` for detailed information on each method.\n",
    "\n",
    "3. **Line Association**: Associates lines from both queries based on a configurable similarity threshold.\n",
    "\n",
    "4. **Visual Highlighting**: \n",
    "   - Lines that match (above the similarity threshold) are highlighted in green\n",
    "   - Lines that don't have a match in the other query are highlighted in red\n",
    "\n",
    "5. **Adjustable Threshold**: The similarity threshold can be adjusted to control how strict the matching should be.\n",
    "\n",
    "6. **Summary Statistics**: Provides metrics on how many lines matched, total lines in each query, and coverage percentages.\n",
    "\n",
    "7. **Filtering Options**: Filter by model, experiment, difficulty level, or search for specific SQL content.\n",
    "\n",
    "### Benefits\n",
    "\n",
    "- Provides a more granular comparison than simple query-level matching\n",
    "- Helps identify which specific parts of queries match or differ\n",
    "- Allows for understanding partial correctness in predicted queries\n",
    "- Supports detailed error analysis and model comparison\n",
    "\n",
    "## Enhanced Subquery Handling\n",
    "\n",
    "The SQL Line Comparison Widget now includes improved handling for subqueries and nested queries with the following enhancements:\n",
    "\n",
    "### Dedicated Subquery Extraction\n",
    "- A new `extract_subqueries` function identifies and extracts subqueries from different parts of the SQL statement:\n",
    "  - SELECT clause subqueries (scalar subqueries)\n",
    "  - FROM clause subqueries (derived tables)\n",
    "  - WHERE clause subqueries (IN, EXISTS, comparison)\n",
    "  - JOIN condition subqueries\n",
    "\n",
    "### Subquery-Aware Parsing Process\n",
    "1. Subqueries are first extracted from the original SQL\n",
    "2. Placeholder text replaces subqueries in the main query\n",
    "3. The modified query is parsed normally\n",
    "4. Placeholders are replaced with the original subqueries when building the line items\n",
    "5. Special line types are used to distinguish items containing subqueries\n",
    "\n",
    "### New Line Types for Subqueries\n",
    "- `SELECT item with subquery` - For columns that use subqueries\n",
    "- `FROM subquery` - For derived tables and table expressions\n",
    "- `WHERE condition with subquery` - For WHERE conditions that use subqueries\n",
    "- `JOIN subquery` - For JOIN clauses that use subqueries\n",
    "- `Independent [type] subquery` - For subqueries that weren't matched to a specific clause\n",
    "\n",
    "### Benefits\n",
    "- Preserves the structure of complex queries\n",
    "- Keeps subqueries intact for better comparison\n",
    "- Properly identifies and matches similar subqueries between gold and predicted SQL\n",
    "- Handles nested levels of subqueries\n",
    "- Improves similarity matching for queries with complex structures\n",
    "\n",
    "This enhancement significantly improves the widget's ability to handle complex SQL queries with nested structures, making the line-by-line comparison more accurate and useful for advanced SQL evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alerce_t2s",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
