{"custom_id": "15-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the Query:**\n\n1. **Identify the Main Object Set:**\n   - Start from the `object` table, as it contains the main object identifiers (`oid`) and the time of first detection (`firstmjd`).\n   - Filter objects whose `firstmjd` is between 60188.0 and 60190.0 (to include both September 1 and 2, as MJD is a continuous variable and the end is exclusive).\n\n2. **Determine Fast Riser Objects:**\n   - Use the `magstat` table to estimate the initial rise rate for each object in each filter.\n   - The initial rise rate is defined as `dm_first / dt_first` (where `dm_first` is the change in magnitude at first detection, and `dt_first` is the time between the last non-detection and the first detection, both in the same filter).\n   - Filter for objects where this rate is at least 0.25 magnitudes/day (i.e., `dm_first / dt_first >= 0.25`).\n   - Ensure that `dt_first > 0` to avoid division by zero.\n   - For each object, keep the filter ID (`fid`) from `magstat` as `magstat_fid` and the computed initial rise estimate.\n\n3. **Select Objects with Highest Stamp Classifier Probability for Class 'SN':**\n   - From the `probability` table, select entries where:\n     - `classifier_name = 'stamp_classifier'`\n     - `class_name = 'SN'`\n     - `ranking = 1` (highest probability for this classifier)\n   - Retrieve the probability value for this class and classifier.\n\n4. **Retrieve Light Curve Detections:**\n   - From the `detection` table, select all detections (`candid`, `fid`, and other columns as needed) for the objects identified in the previous steps.\n   - Only include rows where the `oid` matches the filtered set of objects.\n\n5. **Retrieve Light Curve Classifier Probabilities:**\n   - From the `probability` table, select entries where:\n     - `classifier_name = 'lc_classifier'`\n     - `ranking = 1` (highest probability for this classifier)\n   - Retrieve the probability value for this classifier.\n\n6. **Combine All Information:**\n   - For each object that meets the above criteria:\n     - Return the `oid`\n     - The probability for class 'SN' from the stamp classifier\n     - The probability for the most likely class from the light curve classifier\n     - All detection rows for that object (with `candid` and `fid`)\n     - The `magstat_fid` (filter ID from `magstat`)\n     - The initial rise estimate (`dm_first / dt_first`)\n   - Ensure that the returned detections are only for the objects and filters that qualify as fast risers.\n\n7. **Order the Results:**\n   - Order the final results by `oid`.\n\n**Summary of Steps/Subqueries:**\n- Subquery 1: Filter `object` by `firstmjd` in the specified range.\n- Subquery 2: Join with `magstat` to compute and filter by initial rise rate (fast riser definition), keeping `magstat_fid` and initial rise estimate.\n- Subquery 3: Join with `probability` to select objects with highest probability for class 'SN' in the stamp classifier.\n- Subquery 4: Join with `detection` to get all detections for the selected objects.\n- Subquery 5: Join with `probability` to get the highest probability from the light curve classifier.\n- Final Selection: Select and return the required columns, ensuring all conditions are met, and order by `oid`.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the Query:**\n\n1. **Identify the Main Output Columns:**\n   - Object identifiers (`oid`)\n   - Probabilities in the stamp classifier (for class 'SN', highest probability)\n   - Light curve detections (from `detection` table)\n   - Filter ID and candid of detections (`detection.fid`, `detection.candid`)\n   - Filter ID from `magstat` as `magstat_fid`\n   - Initial rise estimate (rate of magnitude change at detection, `magstat.dmdt_first`)\n\n2. **Filter Objects by First Detection Date:**\n   - Use the `object` table to select objects whose `firstmjd` is between 60188.0 and 60190.0 (i.e., first two days of September).\n\n3. **Identify Fast Risers:**\n   - Use the `magstat` table to select objects where `dmdt_first >= 0.25` in any filter (since the rate is defined as positive for a fast rise).\n   - Ensure that the `magstat.oid` matches the `object.oid`.\n   - Retain the filter ID from `magstat` as `magstat_fid`.\n\n4. **Select Objects with Highest Probability for 'SN' in the Stamp Classifier:**\n   - Use the `probability` table to select entries where:\n     - `classifier_name = 'stamp_classifier'`\n     - `class_name = 'SN'`\n     - `ranking = 1` (highest probability for this classifier)\n   - Retrieve the probability value for these entries.\n   - Ensure that the `probability.oid` matches the `object.oid`.\n\n5. **Retrieve Detections for the Selected Objects:**\n   - Use the `detection` table to get all detections (`detection.oid` matches the selected `object.oid`).\n   - Retrieve `detection.fid` (filter ID) and `detection.candid` (candidate ID).\n\n6. **Combine All Filters:**\n   - The selected objects must satisfy all of the following:\n     - First detection in the first two days of September (`object.firstmjd` in range).\n     - Qualify as fast risers (`magstat.dmdt_first >= 0.25`).\n     - Highest probability in the stamp classifier for class 'SN' (`probability.class_name = 'SN'`, `probability.classifier_name = 'stamp_classifier'`, `probability.ranking = 1`).\n\n7. **Join the Tables Appropriately:**\n   - Join `object` to `magstat` on `oid`.\n   - Join `object` to `probability` on `oid`.\n   - Join `object` to `detection` on `oid`.\n   - Ensure that the filter ID in `magstat` matches the filter ID of the first detection if needed for the initial rise estimate.\n\n8. **Select and Alias the Required Columns:**\n   - Select `object.oid`\n   - Select `probability.probability` (as the probability in the stamp classifier)\n   - Select all columns from `detection` (or at least `detection.fid`, `detection.candid`)\n   - Select `magstat.fid` as `magstat_fid`\n   - Select `magstat.dmdt_first` as the initial rise estimate\n\n9. **Order the Results:**\n   - Order the final results by `object.oid`.\n\n10. **Summary of Steps:**\n    - Filter objects by first detection date.\n    - Filter by fast riser criterion in `magstat`.\n    - Filter by highest probability for 'SN' in the stamp classifier in `probability`.\n    - Join with `detection` to get all detections for these objects.\n    - Select and alias the required columns.\n    - Order by `oid`.\n\n**Note:** Ensure that all joins are INNER JOINs to enforce that only objects meeting all criteria are included. If multiple filters are present in `magstat` or `detection`, ensure the correct association for the initial rise estimate and detection filter.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are:\n     - `object`: for object-level statistics (e.g., number of detections, coordinates, etc.).\n     - `probability`: for classification information and probabilities.\n     - `detection`: for time-resolved photometry (magnitudes, errors, candidate IDs, band IDs, time).\n     - `magstat`: for initial rise rate (dmdt_first) per band.\n   - Required columns:\n     - Object identifier: `object.oid`\n     - Candidate identifier: `detection.candid`\n     - Magnitudes: `detection.magpsf`, `detection.magap`, `detection.magpsf_corr`, `detection.magapbig`\n     - Magnitude errors: `detection.sigmapsf`, `detection.sigmagap`, `detection.sigmapsf_corr`, `detection.sigmapsf_corr_ext`, `detection.sigmagapbig`\n     - Initial rise estimate: `magstat.dmdt_first`\n     - Band identifier: `detection.fid`\n     - Time: `detection.mjd`\n\n2. **Filter Objects by Classification:**\n   - Use the `probability` table to select objects classified as 'SNII' with:\n     - `probability.class_name = 'SNII'`\n     - `probability.classifier_name = 'lc_classifier'` (default condition)\n     - `probability.ranking = 1` (default condition)\n     - `probability.probability > 0.6` (user-specified)\n   - Join `probability` to `object` on `oid`.\n\n3. **Filter by Number of Detections:**\n   - In the `object` table, require `object.ndet > 50`.\n\n4. **Filter by Initial Rise Rate in g and r Bands:**\n   - Use the `magstat` table to get `dmdt_first` for each object in both g-band (`fid=1`) and r-band (`fid=2`).\n   - Require `magstat.dmdt_first > 0.5` for both bands.\n   - Ensure that both conditions are met for the same object (i.e., the object must have a qualifying `magstat` row for both `fid=1` and `fid=2`).\n\n5. **Filter by Detection Time Range:**\n   - The user requests detections in the years 2019-2022.\n   - Convert these years to Modified Julian Date (MJD) range:\n     - 2019-01-01 \u2248 58484\n     - 2022-12-31 \u2248 59948\n   - Filter `detection.mjd` to be between these MJD values.\n\n6. **Join Detections for Selected Objects:**\n   - For objects passing the above filters, join to the `detection` table on `oid`.\n   - Select all detections within the specified MJD range.\n\n7. **Select Required Columns:**\n   - From `object`: `oid`\n   - From `detection`: `candid`, `magpsf`, `sigmapsf`, `magap`, `sigmagap`, `magpsf_corr`, `sigmapsf_corr`, `sigmapsf_corr_ext`, `magapbig`, `sigmagapbig`, `fid`, `mjd`\n   - From `magstat`: `dmdt_first` (for both g and r bands; can be included as subquery or joined columns)\n\n8. **Ensure Only Objects Meeting All Criteria Are Included:**\n   - Use appropriate joins and subqueries to ensure that only objects meeting all the above criteria (classification, probability, ndet, initial rise in both bands) are included in the final result.\n\n9. **(Optional) Order Results:**\n   - Optionally, order the results by `object.oid` and `detection.mjd` to present the light curve as a function of time.\n\n10. **Summary of Steps:**\n    - Filter `probability` for SNII, ranking=1, classifier_name='lc_classifier', probability>0.6.\n    - Join to `object` and filter for ndet>50.\n    - Ensure object has `magstat.dmdt_first>0.5` for both fid=1 and fid=2.\n    - Join to `detection` for those objects, filter for detection.mjd in 2019-2022.\n    - Select required columns from all relevant tables.\n\n**Note:** The query will require at least one subquery or a double join to `magstat` to ensure both g and r band initial rise rates are above threshold.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are:\n     - `object`: for object-level statistics (including `oid`, `ndet`, etc.).\n     - `probability`: for classification and probability information.\n     - `detection`: for time-resolved photometry (including `candid`, `mjd`, `magpsf`, `sigmapsf`, `fid`, etc.).\n     - `magstat`: for band-specific statistics, including the initial rise rate (`dmdt_first`) and band identifier (`fid`).\n\n2. **Set Up Classification and Probability Filters:**\n   - From the `probability` table, select only rows where:\n     - `class_name = 'SNII'`\n     - `classifier_name = 'lc_classifier'` (default condition)\n     - `ranking = 1` (default condition)\n     - `probability > 0.6` (user-specified)\n   - Join this filtered set to the `object` table using `oid`.\n\n3. **Apply Object-Level Filters:**\n   - From the `object` table, select only objects where:\n     - `ndet > 50` (user-specified)\n     - The time of first and last detection (`firstmjd` and `lastmjd`) falls within the years 2019-2022.\n       - Convert the calendar years to Modified Julian Date (MJD) ranges:\n         - 2019-01-01 \u2248 58484\n         - 2022-12-31 \u2248 59948\n       - Ensure that at least part of the object's activity falls within this range (e.g., `lastmjd >= 58484` AND `firstmjd <= 59948`).\n\n4. **Filter for Initial Rise Rate in g and r Bands:**\n   - From the `magstat` table, select only rows where:\n     - `fid IN (1, 2)` (1 = g-band, 2 = r-band)\n     - `dmdt_first > 0.5` (user-specified)\n   - Ensure that for each object, both g and r bands satisfy this condition. This may require grouping or checking that both bands exist per object.\n\n5. **Combine Filters Across Tables:**\n   - Join the filtered `probability` and `object` tables on `oid`.\n   - Join the filtered `magstat` table on `oid` to ensure the initial rise rate condition is met in both g and r bands.\n   - Only include objects that meet all the above criteria.\n\n6. **Retrieve Time-Resolved Photometry:**\n   - From the `detection` table, select all detections for the filtered objects (`oid`).\n   - Retrieve the following columns for each detection:\n     - `oid` (object identifier)\n     - `candid` (candidate identifier)\n     - `mjd` (time of detection)\n     - `magpsf` (magnitude)\n     - `sigmapsf` (magnitude error)\n     - `fid` (band identifier)\n\n7. **Assemble the Final Output:**\n   - For each detection of the selected objects, output:\n     - `oid`\n     - `candid`\n     - `mjd`\n     - `magpsf`\n     - `sigmapsf`\n     - `fid`\n   - Optionally, include the initial rise rate (`dmdt_first`) from `magstat` for each band if required.\n\n8. **Order the Results:**\n   - Sort the results by `oid` and `mjd` to present the light curve as a function of time for each object.\n\n9. **Summary of Steps:**\n   - Filter `probability` for SN II, ranking 1, classifier 'lc_classifier', and probability > 0.6.\n   - Filter `object` for ndet > 50 and time range 2019-2022.\n   - Filter `magstat` for g and r bands with dmdt_first > 0.5, ensuring both bands are present per object.\n   - Join these filters to get the list of qualifying `oid`s.\n   - Retrieve all detections from `detection` for these `oid`s, selecting the required columns.\n   - Order the results by `oid` and `mjd`.\n\n**Note:**  \n- Ensure that the filtering for both g and r bands with dmdt_first > 0.5 is enforced for each object, not just for one band.\n- Use INNER JOINs or subqueries as appropriate to ensure only objects meeting all criteria are included.\n- No SQL code is provided, only the step-by-step plan as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Define the List of Source Positions:**\n   - Create a temporary table (using a WITH clause) named `catalog` containing the source IDs and their (ra, dec) coordinates:\n     - ('source_1', 160.18301441363647, 33.0164673528409)\n     - ('source_2', 174.21524897555543, 44.83789535222221)\n\n2. **Identify the Main Table for Object Information:**\n   - Use the `object` table as the main source for object statistics, including coordinates (`meanra`, `meandec`) and first detection time (`firstmjd`).\n\n3. **Spatial Filtering (Within 10 Degrees of Each Source):**\n   - For each row in the `catalog` table, select objects from the `object` table whose (`meanra`, `meandec`) are within 10 degrees of the catalog position.\n   - Use the Q3C function `q3c_radial_query(object.meanra, object.meandec, catalog.ra, catalog.dec, 10.0)` to perform this cone search.\n\n4. **Temporal Filtering (First Detection in First 7 Days of February):**\n   - Filter objects where `object.firstmjd` is between 59976.0 (February 1) and 59982.0 (February 7), inclusive.\n\n5. **Classification Filtering (Stamp Classifier, SN Class, Probability > 0.4, Ranking=1):**\n   - Use the `probability` table to filter for objects classified as SN by the stamp classifier:\n     - `probability.classifier_name = 'stamp_classifier'`\n     - `probability.class_name = 'SN'`\n     - `probability.probability > 0.4`\n     - `probability.ranking = 1`\n   - Join the `object` and `probability` tables on `oid`.\n\n6. **Combine All Conditions:**\n   - For each source in the `catalog`, select all columns from both `object` and `probability` tables for objects that:\n     - Are within 10 degrees of the source position,\n     - Have `firstmjd` in the specified range,\n     - Have a stamp classifier SN probability > 0.4 and ranking=1.\n\n7. **Output Columns:**\n   - Since the user did not specify particular columns, select all columns from the involved tables (`object` and `probability`).\n\n8. **Result Structure:**\n   - Include the `source_id` from the `catalog` table in the output to indicate which source each object is associated with.\n\n**Summary of Steps:**\n- Step 1: Define the `catalog` table with the two source positions.\n- Step 2: Join `catalog` to `object` using Q3C cone search (10 degrees).\n- Step 3: Filter `object` by `firstmjd` between 59976.0 and 59982.0.\n- Step 4: Join to `probability` on `oid`.\n- Step 5: Filter `probability` for `classifier_name='stamp_classifier'`, `class_name='SN'`, `probability > 0.4`, and `ranking=1`.\n- Step 6: Select all columns from `object` and `probability`, and include `source_id` from `catalog` in the output.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Define the Input Catalog of Positions:**\n   - Create a temporary table (using a WITH clause) named `catalog` with columns: `source_id`, `ra`, and `dec`.\n   - Populate it with the provided sources and their coordinates:\n     - ('source_1', 160.18301441363647, 33.0164673528409)\n     - ('source_2', 174.21524897555543, 44.83789535222221)\n\n2. **Spatial Filtering Using Q3C:**\n   - For each object in the `object` table, check if its mean right ascension (`meanra`) and mean declination (`meandec`) are within 10 degrees of any of the positions in the `catalog` table.\n   - Use the Q3C function `q3c_join(object.meanra, object.meandec, catalog.ra, catalog.dec, 10.0)` to perform this spatial match.\n\n3. **Temporal Filtering on First Detection:**\n   - Filter objects to include only those with `firstmjd` between 59976.0 (February 1) and 59982.0 (February 7), inclusive.\n\n4. **Classification Filtering on SN Probability:**\n   - Join the `object` table with the `probability` table on `oid`.\n   - Filter for rows where:\n     - `probability.classifier_name = 'stamp_classifier'`\n     - `probability.class_name = 'SN'`\n     - `probability.ranking = 1`\n     - `probability.probability > 0.4`\n\n5. **Select Output Columns:**\n   - Since the user did not specify particular columns, select all columns from the `object` and `probability` tables, as well as the `source_id` from the `catalog` table to indicate which input position each object matched.\n\n6. **Combine All Conditions:**\n   - Ensure the query only returns objects that satisfy all of the above:\n     - Are within 10 degrees of at least one input position,\n     - Have a first detection in the specified MJD range,\n     - Have a SN probability > 0.4 and ranking=1 in the stamp classifier.\n\n7. **(Optional) Output Organization:**\n   - If needed, order the results by `source_id`, `probability.probability` (descending), or `object.firstmjd` for clarity.\n\n**Summary of Steps:**\n- Define the input positions as a temporary table.\n- Join `object` with `catalog` using Q3C for spatial filtering.\n- Filter `object` by `firstmjd` for the temporal window.\n- Join with `probability` for SN classification, probability, and ranking filters.\n- Select all relevant columns, including the matched `source_id`.\n- Apply all filters in the WHERE clause.\n- (Optional) Order the results for readability.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the PostgreSQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are `object` (for source properties) and `probability` (for classification results).\n   - Required columns to return: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `g_r_mean_corr`, `classifier_name`, `class_name`, `ranking`, `probability`.\n\n2. **Define the Filtering Criteria:**\n   - Only consider sources classified as either 'AGN', 'QSO', or 'Blazar' by the light curve classifier (`probability.classifier_name = 'lc_classifier'`).\n   - Only consider the most likely class for each object (`probability.ranking = 1`).\n   - Minimum number of detections: `object.ndet >= 40`.\n   - Minimum time span between first and last detection: `object.deltajd >= 200`.\n   - Probability thresholds:\n     - For 'Blazar': `probability.probability <= 0.8`.\n     - For 'AGN' and 'QSO': `probability.probability <= 0.95`.\n\n3. **Design Sub-Queries for Each Class:**\n   - Create three sub-queries, one for each class ('AGN', 'QSO', 'Blazar'), each with its specific probability threshold.\n   - Each sub-query should:\n     - Join `object` and `probability` on `oid`.\n     - Filter by the respective `class_name` and probability threshold.\n     - Apply the general filters for `classifier_name`, `ranking`, `ndet`, and `deltajd`.\n     - Select the required columns.\n\n4. **Combine Results Using UNION:**\n   - Use the `UNION` statement to combine the results of the three sub-queries, ensuring similar numbers for each class.\n   - Ensure that the column order and types are consistent across all sub-queries.\n\n5. **Order and Output:**\n   - Optionally, order the final result set by `class_name` or another relevant column if needed for clarity.\n   - Ensure the output includes all specified columns: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `g_r_mean_corr`, `classifier_name`, `class_name`, `ranking`, `probability`.\n\n6. **Summary of Steps:**\n   - For each class ('AGN', 'QSO', 'Blazar'):\n     - Join `object` and `probability` on `oid`.\n     - Filter by `probability.class_name` for the specific class.\n     - Filter by `probability.classifier_name = 'lc_classifier'`.\n     - Filter by `probability.ranking = 1`.\n     - Filter by `object.ndet >= 40`.\n     - Filter by `object.deltajd >= 200`.\n     - Filter by the class-specific probability threshold.\n     - Select the required columns.\n   - Combine the three sub-queries using `UNION`.\n   - Return the combined result set with the specified columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the PostgreSQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are `object` (for source properties) and `probability` (for classification results).\n   - Required columns to return: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `g_r_mean_corr`, `classifier_name`, `class_name`, `ranking`, `probability`.\n\n2. **Define the Filtering Criteria:**\n   - Only consider sources classified as either 'AGN', 'QSO', or 'Blazar' by the light curve classifier (`probability.classifier_name = 'lc_classifier'`).\n   - Only consider the most likely class for each source (`probability.ranking = 1`).\n   - Minimum number of detections: `object.ndet >= 40`.\n   - Minimum time span between first and last detection: `object.deltajd >= 200`.\n   - Probability thresholds:\n     - For 'Blazar': `probability.probability <= 0.8`.\n     - For 'AGN' and 'QSO': `probability.probability <= 0.95`.\n\n3. **Construct Sub-Queries for Each Class:**\n   - For each class ('AGN', 'QSO', 'Blazar'), define a sub-query that:\n     - Joins `object` and `probability` on `oid`.\n     - Applies the class-specific probability threshold.\n     - Applies the general filters (classifier, ranking, ndet, deltajd).\n     - Selects the required columns.\n\n4. **Combine Sub-Queries Using UNION:**\n   - Use the `UNION` statement to combine the results of the three sub-queries, ensuring similar numbers for each class.\n   - Ensure that the column order and types are consistent across all sub-queries.\n\n5. **Final Output:**\n   - The final result should include all sources meeting the criteria for any of the three classes, with the specified columns.\n\n6. **Order and Presentation (Optional):**\n   - Optionally, order the final results by class or another relevant column if needed for clarity.\n\n**Summary of Steps:**\n- For each class ('AGN', 'QSO', 'Blazar'):\n  - Join `object` and `probability` on `oid`.\n  - Filter by `probability.classifier_name = 'lc_classifier'` and `probability.ranking = 1`.\n  - Filter by `object.ndet >= 40` and `object.deltajd >= 200`.\n  - Filter by `probability.class_name` for the specific class.\n  - Apply the class-specific probability threshold.\n  - Select the required columns.\n- Combine the three sub-queries using `UNION`.\n- Return the combined result set with the specified columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Main Object Type and Classification:**\n   - The user requests \"Type Ia SNe,\" which corresponds to class_name = 'SNIa' in the 'probability' table.\n   - Use the 'probability' table to filter for objects classified as 'SNIa'.\n   - Apply the default conditions: probability.ranking = 1 and probability.classifier_name = 'lc_classifier'.\n\n2. **Filter by First Detection Date in September:**\n   - The first detection date is stored in the 'object' table as 'firstmjd'.\n   - The required range is from 60188.0 (start of September) to 60217.0 (end of September), inclusive.\n   - Filter objects where object.firstmjd >= 60188.0 and object.firstmjd <= 60217.0.\n\n3. **Filter by Peak Magnitude Above 19:**\n   - \"Peak magnitude\" refers to the maximum magnitude, which is stored in the 'magstat' table as 'magmax'.\n   - The user wants objects with magmax > 19.\n   - Since magnitude is filter-dependent, retrieve this information from the 'magstat' table for all filters (fid).\n\n4. **Filter by g-r Color at Maximum Below 1:**\n   - The 'object' table contains 'g_r_max', which is the g-r color at maximum.\n   - Filter for objects where object.g_r_max < 1.\n\n5. **Determine the Required Output Columns:**\n   - The user wants: object identifier (object.oid), maximum g-r difference (object.g_r_max), maximum magnitude (magstat.magmax), and filter id (magstat.fid).\n\n6. **Join the Relevant Tables:**\n   - Join 'probability' and 'object' on oid to get classification and object properties.\n   - Join the result with 'magstat' on oid to get magnitude statistics per filter.\n\n7. **Select and Return the Required Columns:**\n   - Select object.oid, object.g_r_max, magstat.magmax, and magstat.fid for the final output.\n\n8. **Summary of Steps:**\n   - From 'probability', select oids classified as 'SNIa' with ranking = 1 and classifier_name = 'lc_classifier'.\n   - Join with 'object' to filter by firstmjd (September) and g_r_max (<1).\n   - Join with 'magstat' to filter by magmax (>19) and to retrieve magmax and fid.\n   - Select the required columns for output.\n\n**Note:** No SQL code is provided, only the step-by-step decomposition as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Main Object Type and Classification:**\n   - The user requests Type Ia SNe, which corresponds to class_name = 'SNIa' in the 'probability' table.\n   - Use the default classifier conditions: classifier_name = 'lc_classifier' and ranking = 1.\n\n2. **Filter by First Detection Date in September:**\n   - The first detection date is stored in the 'object' table as firstmjd.\n   - September is defined as MJD between 60188.0 (inclusive) and 60217.0 (exclusive or inclusive, clarify with user if needed; assume inclusive for now).\n   - Add a condition: object.firstmjd >= 60188.0 AND object.firstmjd <= 60217.0.\n\n3. **Filter by Peak Magnitude Above 19:**\n   - Peak magnitude is interpreted as the maximum magnitude (magmax) in the 'magstat' table.\n   - The user wants \"above 19\", which for astronomical magnitudes means fainter than 19 (since higher magnitude = fainter). Confirm with user if \"above\" means fainter or brighter, but typically \"above\" means fainter.\n   - Add a condition: magstat.magmax > 19.\n\n4. **Filter by g-r Color at Maximum Below 1:**\n   - The g-r color at maximum is stored in object.g_r_max.\n   - Add a condition: object.g_r_max < 1.\n\n5. **Determine the Required Output Columns:**\n   - The user wants: object identifier (object.oid), maximum g-r difference (object.g_r_max), maximum magnitude (magstat.magmax), and filter id (magstat.fid).\n\n6. **Determine Table Joins and Relationships:**\n   - The main tables involved are: object, probability, and magstat.\n   - Join 'object' and 'probability' on oid.\n   - Join 'object' and 'magstat' on oid.\n\n7. **Select All Relevant Columns:**\n   - As per instructions, select only the columns explicitly requested by the user: object.oid, object.g_r_max, magstat.magmax, magstat.fid.\n\n8. **Assemble the Query Logic:**\n   - Start from the 'object' table.\n   - INNER JOIN with 'probability' on oid, applying the classification filters.\n   - INNER JOIN with 'magstat' on oid, applying the magnitude filter.\n   - Apply all WHERE conditions for date, color, and magnitude.\n\n9. **Return the Results:**\n   - Output the selected columns for all objects meeting the criteria.\n\n**Summary of Steps:**\n1. Filter 'probability' for class_name = 'SNIa', classifier_name = 'lc_classifier', and ranking = 1.\n2. Filter 'object' for firstmjd between 60188.0 and 60217.0 (September).\n3. Filter 'object' for g_r_max < 1.\n4. Filter 'magstat' for magmax > 19.\n5. Join 'object', 'probability', and 'magstat' on oid.\n6. Select object.oid, object.g_r_max, magstat.magmax, magstat.fid.\n7. Return the results.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query, step by step, with all necessary details and logic:\n\n---\n\n### 1. **Define the Spatial Search Region**\n   - The search is centered at RA=39.97, Dec=-1.5768 (Abell 370).\n   - The search radius is 1000 arcmin, which is 16.16667 degrees.\n   - Use the Q3C function `q3c_radial_query(meanra, meandec, 39.97, -1.5768, 16.16667)` to filter objects within this region.\n\n---\n\n### 2. **Filter Objects by First Detection Date**\n   - The first detection must be in July 2023.\n   - Use the MJD range: `firstmjd >= 60126.0 AND firstmjd < 60156.0` on the `object` table.\n\n---\n\n### 3. **Filter by sgscore1 Feature**\n   - The feature `sgscore1` must be less than 0.3.\n   - The `feature` table is transposed, so for each object, filter for `name='sgscore1' AND value < 0.3`.\n   - Only include objects that meet this feature condition.\n\n---\n\n### 4. **Filter by Stamp Classifier Probability**\n   - For each object, retrieve the highest probability (ranking=1) from the `probability` table where `classifier_name='stamp_classifier'`.\n   - Exclude objects where the highest probability class is 'asteroid' or 'bogus' (i.e., `class_name NOT IN ('asteroid', 'bogus')`).\n   - Use the default condition: `ranking=1` and `classifier_name='stamp_classifier'`.\n\n---\n\n### 5. **Select Required Columns**\n   - From the `object` table: `oid`, `meanra`, `meandec`.\n   - From the `feature` table: `value` (for `sgscore1`), `name` (should be 'sgscore1'), and `version` (feature version).\n   - From the `probability` table: the source identifier (which is `oid`), and the classifier version (as `version`).\n   - Compute the distance from the Abell 370 center using `q3c_dist(meanra, meandec, 39.97, -1.5768)` and label it as `dist`.\n\n---\n\n### 6. **Join the Tables Appropriately**\n   - Start with the `object` table as the main table.\n   - INNER JOIN with the `feature` table on `oid` to get the `sgscore1` value, filtering for `name='sgscore1' AND value < 0.3`.\n   - INNER JOIN with the `probability` table on `oid` to get the highest probability for the `stamp_classifier`, filtering for `ranking=1`, `classifier_name='stamp_classifier'`, and `class_name NOT IN ('asteroid', 'bogus')`.\n\n---\n\n### 7. **Apply All Filters in the WHERE Clause**\n   - `object.firstmjd >= 60126.0 AND object.firstmjd < 60156.0`\n   - `q3c_radial_query(object.meanra, object.meandec, 39.97, -1.5768, 16.16667)`\n   - `feature.name = 'sgscore1' AND feature.value < 0.3`\n   - `probability.classifier_name = 'stamp_classifier' AND probability.ranking = 1 AND probability.class_name NOT IN ('asteroid', 'bogus')`\n\n---\n\n### 8. **Select and Alias the Output Columns**\n   - `object.oid`\n   - `feature.value` (sgscore1 value)\n   - `feature.name` (should be 'sgscore1')\n   - `feature.version` (feature version)\n   - `object.meanra`\n   - `object.meandec`\n   - `probability.oid` (source identifier, same as object.oid)\n   - `q3c_dist(object.meanra, object.meandec, 39.97, -1.5768)` as `dist`\n\n---\n\n### 9. **Summary of Subqueries and Joins**\n   - No need for UNION or INTERSECT since all conditions are conjunctive and can be handled with INNER JOINs and WHERE clauses.\n   - The main query will be a SELECT from `object`, INNER JOIN `feature` (for sgscore1), INNER JOIN `probability` (for stamp_classifier, ranking=1, not asteroid/bogus), with all filters applied.\n\n---\n\n### 10. **Order or Limit (Optional)**\n   - If the user wants the results ordered by distance, add an ORDER BY on `dist`.\n   - If a limit is needed, add a LIMIT clause.\n\n---\n\n**In summary:**  \n- Start from the `object` table, filter by MJD and spatial region.\n- INNER JOIN with `feature` for `sgscore1 < 0.3`.\n- INNER JOIN with `probability` for `stamp_classifier`, `ranking=1`, and not 'asteroid'/'bogus'.\n- Select the required columns, including the computed distance.\n- Apply all filters in the WHERE clause.  \n- No need for UNION/INTERSECT as all conditions are conjunctive and can be handled with JOINs.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query, step by step, using the ALeRCE database schema and all the context and constraints provided:\n\n---\n\n### 1. **Define the Spatial Region and Time Window**\n\n- **Spatial Region:**  \n  - Center: RA = 39.97, Dec = -1.5768 (Abell 370)\n  - Search radius: 1000 arcmin = 16.16667 degrees\n  - Use the Q3C function `q3c_radial_query(object.meanra, object.meandec, 39.97, -1.5768, 16.16667)` to filter objects within this region.\n  - Also, calculate the distance for each object using `q3c_dist(object.meanra, object.meandec, 39.97, -1.5768)` and return it as 'dist'.\n\n- **Time Window:**  \n  - First detection in July 2023:  \n    - `object.firstmjd >= 60126.0`  \n    - `object.firstmjd < 60156.0`\n\n---\n\n### 2. **Filter on sgscore1 Feature**\n\n- The 'sgscore1' feature is not in the 'object' or 'probability' tables, so it must be in a 'feature' table (not shown in the schema, but implied by the context).\n- For each object, require that `feature.name = 'sgscore1'` and `feature.value < 0.3`.\n- The 'feature' table must be joined to the filtered set of objects.\n\n---\n\n### 3. **Filter on Stamp Classifier Probability**\n\n- Use the 'probability' table:\n  - Only consider rows where `probability.classifier_name = 'stamp_classifier'`.\n  - Only consider the highest probability per object: `probability.ranking = 1`.\n  - Exclude objects where `probability.class_name IN ('asteroid', 'bogus')`.\n- Join this filtered probability set to the objects.\n\n---\n\n### 4. **Select Required Columns**\n\n- From the 'object' table:  \n  - `oid`, `meanra`, `meandec`\n- From the 'feature' table:  \n  - `value` (sgscore1 value), `name` (should be 'sgscore1')\n- From the 'probability' table:  \n  - `version` (classifier version)\n- The source identifier is `oid` (as per the schema).\n- The distance from the cluster center, as calculated above, should be returned as 'dist'.\n\n---\n\n### 5. **Join Logic and Query Structure**\n\n- **Step 1:**  \n  - Start with the 'object' table, filtering by spatial region and time window.\n- **Step 2:**  \n  - INNER JOIN to the 'feature' table on `object.oid = feature.oid`, with `feature.name = 'sgscore1'` and `feature.value < 0.3`.\n- **Step 3:**  \n  - INNER JOIN to the 'probability' table on `object.oid = probability.oid`, with:\n    - `probability.classifier_name = 'stamp_classifier'`\n    - `probability.ranking = 1`\n    - `probability.class_name NOT IN ('asteroid', 'bogus')`\n- **Step 4:**  \n  - In the SELECT clause, include all required columns and the calculated distance.\n\n---\n\n### 6. **Final Output Columns**\n\n- `object.oid` (object identifier)\n- `feature.value` (sgscore1 value)\n- `feature.name` (should be 'sgscore1')\n- `probability.version` (classifier version)\n- `object.meanra`\n- `object.meandec`\n- `object.oid` (as source identifier)\n- `q3c_dist(object.meanra, object.meandec, 39.97, -1.5768)` as 'dist'\n\n---\n\n### 7. **Ordering and Uniqueness**\n\n- If required, add `ORDER BY dist ASC` to sort by proximity to the cluster center.\n- Use `SELECT DISTINCT` if there is a possibility of duplicate rows due to joins.\n\n---\n\n### 8. **Summary of Steps/Subqueries**\n\n1. **Subquery 1:**  \n   - Filter 'object' table for objects with `firstmjd` in July 2023 and within the spatial region using Q3C.\n2. **Subquery 2:**  \n   - Filter 'feature' table for `name = 'sgscore1'` and `value < 0.3`, joining to the objects from Subquery 1.\n3. **Subquery 3:**  \n   - Filter 'probability' table for `classifier_name = 'stamp_classifier'`, `ranking = 1`, and `class_name NOT IN ('asteroid', 'bogus')`, joining to the objects from Subquery 1.\n4. **Final Join:**  \n   - INNER JOIN the results of Subqueries 2 and 3 on `oid` to the filtered objects from Subquery 1.\n5. **Select and Calculate:**  \n   - Select the required columns and calculate the distance using Q3C.\n\n---\n\nThis plan ensures all conditions are met, all required columns are selected, and the query is both accurate and optimal for the ALeRCE schema and context.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query, following the database schema, context, and advanced query requirements:\n\n---\n\n### 1. **Identify the Main Selection Criteria and Output Columns**\n\n- **Output Columns Required:**\n  - object identifier (`object.oid`)\n  - candidate identifier of the detections (`detection.candid`)\n  - feature name (`feature.name`)\n  - feature value (`feature.value`)\n  - psf magnitude (`detection.magpsf`)\n  - psf magnitude error (`detection.sigmapsf`)\n  - band identifier from feature table, renamed as `feature_fid` (`feature.fid AS feature_fid`)\n  - time of detection (`detection.mjd`)\n\n- **Selection Criteria:**\n  - Objects classified as SN II (`probability.class_name = 'SNII'`)\n  - Probability > 0.6 (`probability.probability > 0.6`)\n  - Only most likely class per object (`probability.ranking = 1`)\n  - Classifier is 'lc_classifier' (`probability.classifier_name = 'lc_classifier'`)\n  - Number of detections > 50 (`object.ndet > 50`)\n  - Difference between minimum and maximum magnitudes in ZTF g-band > 2 mag (feature: `delta_mag_fid` with `fid=1` and `value > 2`)\n\n---\n\n### 2. **Subquery for SN II Classification with Probability and Ranking Conditions**\n\n- Create a subquery on the `probability` table to select `oid` where:\n  - `class_name = 'SNII'`\n  - `probability > 0.6`\n  - `ranking = 1`\n  - `classifier_name = 'lc_classifier'`\n\n---\n\n### 3. **Subquery for Objects with Sufficient Detections**\n\n- Join the above subquery with the `object` table to filter for:\n  - `object.ndet > 50`\n\n---\n\n### 4. **Subquery for Objects with Sufficient g-band Magnitude Range**\n\n- Create a subquery on the `feature` table to select `oid` where:\n  - `name = 'delta_mag_fid'`\n  - `fid = 1` (ZTF g-band)\n  - `value > 2`\n- This subquery should be INNER JOINed with the filtered oids from step 3 to ensure only relevant objects are considered.\n\n---\n\n### 5. **Combine All Filters to Get Final List of oids**\n\n- INTERSECT the oids from:\n  - The SN II classification/probability/ndet subquery (steps 2 and 3)\n  - The g-band magnitude range subquery (step 4)\n- This ensures only objects meeting all criteria are selected.\n\n---\n\n### 6. **Retrieve Detection and Feature Information for Selected oids**\n\n- For each oid in the final list:\n  - Join with the `detection` table to get:\n    - `candid`, `magpsf`, `sigmapsf`, `fid`, `mjd`\n  - Join with the `feature` table to get:\n    - `name`, `value`, `fid` (renamed as `feature_fid`)\n- The join between `detection` and `feature` should be on `oid`.\n\n---\n\n### 7. **Assemble the Final Output**\n\n- Select the following columns:\n  - `object.oid`\n  - `detection.candid`\n  - `feature.name`\n  - `feature.value`\n  - `detection.magpsf`\n  - `detection.sigmapsf`\n  - `feature.fid AS feature_fid`\n  - `detection.mjd`\n- Ensure that the output is ordered by `object.oid`.\n\n---\n\n### 8. **Order the Results**\n\n- Add an `ORDER BY object.oid` clause to the final query.\n\n---\n\n### 9. **Summary of Query Structure**\n\n- The query will involve:\n  - A subquery for SN II classification with probability and ranking filters.\n  - An INNER JOIN with the `object` table for ndet filtering.\n  - A subquery on the `feature` table for the g-band magnitude range.\n  - An INTERSECT to ensure all criteria are met.\n  - INNER JOINs with `detection` and `feature` tables to retrieve the required columns.\n  - Renaming of the `feature.fid` column as `feature_fid`.\n  - Ordering by `object.oid`.\n\n---\n\n### 10. **Notes on Efficiency and Schema Usage**\n\n- Use indexes on `probability.oid`, `object.oid`, and `feature.oid` for efficient joins.\n- Use the exact column and table names as specified.\n- Ensure that the `feature` table is joined correctly, as it is transposed (one row per feature per object).\n- Only include detections and features for the filtered set of oids.\n\n---\n\nThis step-by-step plan ensures that all user requirements are met, the query is optimal, and the database schema is used correctly.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query, following the database schema, context, and advanced query requirements:\n\n---\n\n### 1. **Identify the Main Selection Criteria and Output Columns**\n\n- **Output Columns Required:**\n  - object identifier (`object.oid`)\n  - candidate identifier of the detections (`detection.candid`)\n  - feature name (`feature.name`)\n  - feature value (`feature.value`)\n  - psf magnitude (`detection.magpsf`)\n  - psf magnitude error (`detection.sigmapsf`)\n  - band identifier from feature table, renamed as `feature_fid` (`feature.fid AS feature_fid`)\n  - time of detection (`detection.mjd`)\n\n- **Selection Criteria:**\n  - Objects classified as SN II (`probability.class_name = 'SNII'`)\n  - Probability > 0.6 (`probability.probability > 0.6`)\n  - Only most likely class (`probability.ranking = 1`)\n  - Classifier is 'lc_classifier' (`probability.classifier_name = 'lc_classifier'`)\n  - Number of detections > 50 (`object.ndet > 50`)\n  - Difference between minimum and maximum magnitudes in ZTF g-band > 2 mag (feature: `delta_mag_fid` with `fid=1` and `value > 2`)\n\n---\n\n### 2. **Subquery: Filter Objects by Classification and Detection Count**\n\n- Create a subquery on the `probability` table:\n  - Filter for `class_name = 'SNII'`, `probability > 0.6`, `ranking = 1`, `classifier_name = 'lc_classifier'`.\n- Join this subquery with the `object` table to filter for `ndet > 50`.\n\n---\n\n### 3. **Subquery: Filter Objects by g-band Magnitude Range**\n\n- Create a subquery on the `feature` table:\n  - Filter for `name = 'delta_mag_fid'`, `fid = 1` (ZTF g-band), and `value > 2`.\n- Join this subquery with the result of step 2 to ensure only objects meeting all criteria are selected.\n\n---\n\n### 4. **Combine Filters Using INTERSECT**\n\n- Since the `feature` table is transposed (one row per feature per object), use the following approach:\n  - The subquery from step 2 gives oids matching the classification and detection count.\n  - The subquery from step 3 gives oids matching the g-band magnitude range.\n  - Use an INTERSECT to get oids present in both subqueries.\n\n---\n\n### 5. **Retrieve All Required Features for Selected Objects**\n\n- For the oids resulting from the INTERSECT, select all features (`feature.name`, `feature.value`, `feature.fid AS feature_fid`) for those objects.\n- This allows for flexibility if the user wants all features, or you can restrict to specific features if needed.\n\n---\n\n### 6. **Join with Detection Table for Light Curve Information**\n\n- For each selected oid, join with the `detection` table to retrieve:\n  - `detection.candid`\n  - `detection.mjd`\n  - `detection.magpsf`\n  - `detection.sigmapsf`\n  - `detection.fid` (if needed for band information)\n- Ensure the join is on `oid`.\n\n---\n\n### 7. **Assemble the Final Output**\n\n- Select the following columns:\n  - `object.oid`\n  - `detection.candid`\n  - `feature.name`\n  - `feature.value`\n  - `feature.fid AS feature_fid`\n  - `detection.mjd`\n  - `detection.magpsf`\n  - `detection.sigmapsf`\n- Ensure that the join between `feature` and `detection` is on `oid`, and that only oids from the INTERSECT are included.\n\n---\n\n### 8. **Order the Results**\n\n- Add an `ORDER BY object.oid` clause to the final query to sort the results by object identifier.\n\n---\n\n### 9. **Summary of Query Structure**\n\n- The query will involve:\n  - A subquery on `probability` joined with `object` for classification and detection count.\n  - A subquery on `feature` for g-band magnitude range.\n  - An INTERSECT to get oids meeting all criteria.\n  - A join with `feature` and `detection` tables to retrieve all required columns.\n  - An ORDER BY clause for sorting.\n\n---\n\n### 10. **Notes and Optimization**\n\n- Use INNER JOINs for all joins to ensure only matching records are included.\n- Use the appropriate indexes (e.g., on `probability.oid`, `object.oid`, `feature.oid`, `detection.oid`) for performance.\n- If the user wants only specific features, add a filter on `feature.name` as needed.\n- If the user wants the band identifier from the detection table as well, include `detection.fid` in the output.\n\n---\n\nThis step-by-step plan ensures all user requirements are met, using advanced SQL constructs (JOINs, INTERSECT, subqueries), and leverages the database schema and context for optimal and accurate results.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nDecomposition Plan for the Query:\n\n1. **Identify YSO Candidates with High Probability**\n   - Start by querying the `probability` table to select objects (`oid`) classified as 'YSO' by the 'lc_classifier' classifier, with `probability` greater than 0.7 and `ranking` = 1 (default condition).\n   - Retrieve the following columns: `oid`, `probability`, `class_name`, `classifier_name`, and `classifier_version`.\n\n2. **Filter for Periodicities: Photometric Period Between 3 and 10 Days**\n   - For the objects identified in step 1, query the `feature` table for the feature named 'Period_band' (photometric period), with `value` between 3 and 10 (inclusive).\n   - Ensure that only the oids from step 1 are considered by performing an INNER JOIN between the filtered `probability` subquery and the `feature` table on `oid`.\n   - Retrieve: `oid`, `name` (should be 'Period_band'), `value` (period), `fid`, and `version`.\n\n3. **Filter for Variation Amplitude Greater Than 0.5 mag**\n   - Similarly, for the same set of oids from step 1, query the `feature` table for the feature named 'Amplitude', with `value` greater than 0.5.\n   - Again, use an INNER JOIN between the filtered `probability` subquery and the `feature` table on `oid`.\n   - Retrieve: `oid`, `name` (should be 'Amplitude'), `value` (amplitude), `fid`, and `version`.\n\n4. **Combine Feature Filters (Periodicity and Amplitude)**\n   - Since the `feature` table is transposed (each feature is a separate row), you need to ensure that only objects that satisfy both the period and amplitude conditions are selected.\n   - For this, create two subqueries: one for 'Period_band' and one for 'Amplitude', each joined with the filtered `probability` subquery from step 1.\n   - Use an INTERSECT operation on the oids from both subqueries to get the set of objects that satisfy both feature conditions.\n\n5. **Retrieve All Relevant Feature Information for Selected Objects**\n   - For the oids resulting from the INTERSECT in step 4, retrieve both the 'Period_band' and 'Amplitude' feature rows from the `feature` table, including: `oid`, `name`, `value`, `fid`, and `version`.\n   - This can be done by a UNION of the two feature subqueries, filtered to only include oids from the INTERSECT set.\n\n6. **Combine with Probability Information**\n   - For each object in the final set, join the feature information (from step 5) with the corresponding probability information (from step 1) on `oid`.\n   - Retrieve: `oid`, `probability`, `name` (feature name), `value` (feature value), `fid`, and `version`.\n\n7. **Sort the Results**\n   - Sort the final result set by `probability` in descending order.\n\n8. **Return the Required Columns**\n   - Ensure the output includes: `oid` (object identifier), `probability`, `name` (feature name), `value` (feature value), `fid` (filter id), and `version` (feature version).\n\nSummary of Steps:\n- Step 1: Filter `probability` for YSO, probability > 0.7, ranking = 1, classifier_name = 'lc_classifier'.\n- Step 2: Filter `feature` for 'Period_band', value between 3 and 10, INNER JOIN with step 1 oids.\n- Step 3: Filter `feature` for 'Amplitude', value > 0.5, INNER JOIN with step 1 oids.\n- Step 4: INTERSECT oids from steps 2 and 3 to get objects satisfying both feature conditions.\n- Step 5: UNION the feature rows for 'Period_band' and 'Amplitude' for the INTERSECT oids.\n- Step 6: INNER JOIN the feature rows with the probability information from step 1.\n- Step 7: Sort by `probability` descending.\n- Step 8: Return `oid`, `probability`, `name`, `value`, `fid`, and `version`.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the Query:**\n\n1. **Identify the Target Class and Classifier:**\n   - The user wants objects classified as likely Young Stellar Objects (YSOs).\n   - In the `probability` table, filter for:\n     - `class_name = 'YSO'`\n     - `classifier_name = 'lc_classifier'` (default for object classes)\n     - `ranking = 1` (default: only most likely class per object)\n     - `probability > 0.7` (as specified by the user)\n\n2. **Define the Periodicity and Amplitude Feature Constraints:**\n   - The user wants objects with:\n     - Photometric period between 3 and 10 days.\n       - This corresponds to the feature `Period_band` in the `feature` table.\n       - So, filter for `name = 'Period_band'` and `value BETWEEN 3 AND 10`.\n     - Variation amplitude greater than 0.5 mag.\n       - This corresponds to the feature `Amplitude` in the `feature` table.\n       - So, filter for `name = 'Amplitude'` and `value > 0.5`.\n\n3. **Handle the Transposed Feature Table:**\n   - Since each feature is a separate row in the `feature` table, and the user wants objects that satisfy both feature constraints, follow the prescribed steps:\n     - I. Create a sub-query using the `probability` table with the above filters to get the relevant `oid`s.\n     - II. For each feature (`Period_band` and `Amplitude`), create a sub-query that:\n       - Joins with the filtered `probability` sub-query on `oid`.\n       - Applies the respective feature name and value condition.\n     - III. UNION the two feature sub-queries to get all relevant feature rows for the selected objects.\n     - IV. INTERSECT the two feature sub-queries to get the `oid`s that satisfy both feature conditions.\n     - V. Filter the UNION result to only include rows with `oid`s present in the INTERSECT result.\n\n4. **Select the Required Columns:**\n   - The user wants:\n     - Object identifier (`oid`)\n     - Probability (from `probability.probability`)\n     - Feature value (`feature.value`)\n     - Feature name (`feature.name`)\n     - Filter id (`feature.fid`)\n     - Feature version (`feature.version`)\n\n5. **Join the Feature and Probability Information:**\n   - For the final result, join the filtered feature rows (from step 3) with the corresponding probability information (from step 1) on `oid` to retrieve the probability value.\n\n6. **Sort the Results:**\n   - Order the final result by `probability.probability` in descending order, as requested.\n\n7. **Summary of Steps/Subqueries:**\n   - a. Sub-query: Filter `probability` for YSO, ranking=1, classifier_name='lc_classifier', probability>0.7.\n   - b. Sub-query: For `Period_band`, join with (a), filter for value between 3 and 10.\n   - c. Sub-query: For `Amplitude`, join with (a), filter for value > 0.5.\n   - d. UNION (b) and (c) to get all relevant feature rows.\n   - e. INTERSECT (b) and (c) to get oids that satisfy both feature conditions.\n   - f. Filter the UNION result to only include oids from the INTERSECT.\n   - g. Join the filtered feature rows with the probability sub-query to get the probability value.\n   - h. Select the required columns: oid, probability, feature.value, feature.name, feature.fid, feature.version.\n   - i. Order by probability in descending order.\n\n**Note:** All table and column names must be used exactly as in the schema. The query must follow the prescribed method for handling multiple features in the transposed `feature` table.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "38-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are `probability` (for classification and probability) and `object` (for detection counts).\n   - Relevant columns from `probability`: `oid`, `class_name`, `classifier_name`, `probability`, `ranking`.\n   - Relevant columns from `object`: `oid`, `ndet`.\n\n2. **Set Default and User-Specified Conditions:**\n   - For both AGN and QSO, use only rows where `probability.classifier_name = 'lc_classifier'` and `probability.ranking = 1` (default conditions).\n   - For AGN: `probability.class_name = 'AGN'` and `probability > 0.6`.\n   - For QSO: `probability.class_name = 'QSO'` and `probability > 0.5`.\n\n3. **Order and Limit Results for Each Class:**\n   - For AGN: Order by `probability` in descending order and limit to the top 1000 results.\n   - For QSO: Order by `probability` in descending order and limit to the top 1000 results.\n\n4. **Combine the Two Sets of Candidates:**\n   - Combine the top 1000 AGN and top 1000 QSO candidates into a single set. This can be done using a `UNION ALL` or by creating two subqueries and combining their results.\n\n5. **Join with the Object Table for Detection Counts:**\n   - For each candidate in the combined set, join with the `object` table on `oid` to access the `ndet` (number of detections) column.\n\n6. **Apply Detection Count Filter:**\n   - Filter the joined results to include only those objects where `object.ndet` is between 30 and 200 (inclusive).\n\n7. **Select Desired Columns:**\n   - Since the user did not specify particular columns, select all columns from both `probability` and `object` tables for the filtered set.\n\n8. **Return the Final Result:**\n   - The final result should be the set of objects (from the top 1000 AGN and top 1000 QSO candidates, as defined above) that have between 30 and 200 detections, with all available columns from the involved tables.\n\n**Summary of Steps:**\n1. Filter `probability` for AGN with `probability > 0.6`, `classifier_name = 'lc_classifier'`, `ranking = 1`, order by `probability` descending, limit 1000.\n2. Filter `probability` for QSO with `probability > 0.5`, `classifier_name = 'lc_classifier'`, `ranking = 1`, order by `probability` descending, limit 1000.\n3. Combine the two sets of oids (AGN and QSO).\n4. Join the combined set with `object` on `oid`.\n5. Filter for `object.ndet` between 30 and 200 (inclusive).\n6. Select all columns from both tables for the final output.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query the top 1000 active galactic nuclei and top 1000 quasi\u2013stellar objects candidates ordered by probability in descending order, that have a probability > 0.6 and 0.5 respectively according to the light curve classifier. From those objects obtain the ones that have between 30 and 200 detections both.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Required Output Columns:**\n   - Galactic coordinates: These are features named 'gal_l' (galactic longitude) and 'gal_b' (galactic latitude) in the 'feature' table.\n   - Feature columns: The user wants \"feature columns\" in general, so all available features for each object should be included.\n   - Class name: This is found in the 'class_name' column of the 'probability' table.\n   - Object identifiers: This is the 'oid' column from the 'object' table.\n\n2. **Determine the Main Table for Filtering:**\n   - The main table for object detection dates is 'object', specifically the 'firstmjd' column, which records the time of first detection.\n\n3. **Apply the Date Filter:**\n   - Filter objects where 'firstmjd' is between 59976.0 (February 1, 2023) and 59978.0 (February 3, 2023), but only include those first detected between February 1 and 2, so the range should be 59976.0 <= firstmjd < 59978.0.\n\n4. **Identify the Classification Table and Conditions:**\n   - Use the 'probability' table to get the class name for each object.\n   - Apply the default conditions:\n     - 'probability.classifier_name' = 'lc_classifier'\n     - 'probability.ranking' = 1 (only the most likely class per object)\n\n5. **Join the Tables:**\n   - Join 'object' and 'probability' on 'oid' to associate each object with its most likely class as determined by the light curve classifier.\n   - Join the 'feature' table to retrieve all features for each object. This join is also on 'oid'.\n\n6. **Select the Galactic Coordinates:**\n   - From the 'feature' table, select the rows where 'name' = 'gal_l' and 'name' = 'gal_b' to get galactic longitude and latitude, respectively.\n   - Also, select all other features for each object as requested.\n\n7. **Assemble the Output:**\n   - For each object that meets the date and classification criteria, output:\n     - The object identifier ('oid')\n     - The class name from 'probability'\n     - The galactic coordinates ('gal_l' and 'gal_b' from 'feature')\n     - All other feature columns (from 'feature')\n\n8. **Handle Multiple Features per Object:**\n   - Since each object can have multiple features (one per row in 'feature'), ensure the output includes all features for each object, possibly as separate rows per feature, or as columns if pivoting is desired (the user did not specify).\n\n9. **Summary of Steps:**\n   - Filter 'object' table for firstmjd between 59976.0 and 59978.0 (excluding 59978.0).\n   - Join with 'probability' table on 'oid', with classifier_name = 'lc_classifier' and ranking = 1.\n   - Join with 'feature' table on 'oid' to get all features, including 'gal_l' and 'gal_b'.\n   - Select 'oid', 'class_name', all feature columns (including 'gal_l' and 'gal_b').\n\n10. **Order or Grouping (if needed):**\n    - If the user wants the results grouped by object or ordered by detection date, add appropriate ordering or grouping (not explicitly requested, so can be omitted unless specified).\n\n**End of Decomposition Plan.**\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Main Table for Object Detection Dates:**\n   - The `object` table contains the `firstmjd` column, which records the Modified Julian Date (MJD) of the first detection for each object.\n   - This table also contains the object identifier (`oid`).\n\n2. **Filter Objects by First Detection Date:**\n   - Apply a filter on `object.firstmjd` to select only those objects first detected between February 1, 2023 (MJD 59976.0) and February 2, 2023 (MJD 59977.999...).\n   - The condition should be: `object.firstmjd >= 59976.0 AND object.firstmjd < 59978.0`.\n\n3. **Obtain the Identifiers of the Selected Objects:**\n   - Select the `oid` column from the filtered `object` table.\n\n4. **Retrieve Galactic Coordinates from Features:**\n   - The galactic coordinates are stored as features in the `feature` table, with `name` values 'gal_l' (galactic longitude) and 'gal_b' (galactic latitude).\n   - For each selected `oid`, retrieve the corresponding `value` from the `feature` table where `name` is 'gal_l' or 'gal_b'.\n\n5. **Retrieve All Feature Columns for Each Object:**\n   - For each selected `oid`, retrieve all available features from the `feature` table (i.e., all rows with the matching `oid`).\n   - This includes the columns: `name`, `value`, `fid`, and `version`.\n\n6. **Retrieve the Class Name from the Light Curve Classifier:**\n   - Use the `probability` table to get the classification for each object.\n   - Apply the default conditions: `probability.classifier_name = 'lc_classifier'` and `probability.ranking = 1`.\n   - Retrieve the `class_name` column for each `oid`.\n\n7. **Combine the Information:**\n   - Join the filtered `object` table (step 2) with the `probability` table (step 6) on `oid` to get the class name for each object.\n   - Join the result with the `feature` table (step 5) on `oid` to get all feature columns, including galactic coordinates.\n\n8. **Select the Required Columns:**\n   - For each object, select:\n     - The object identifier (`oid`)\n     - The galactic longitude (`gal_l`) and latitude (`gal_b`) values\n     - All feature columns from the `feature` table\n     - The class name from the `probability` table\n\n9. **Ensure Output Structure:**\n   - If the user expects one row per object with all features as columns, consider pivoting the features (if required by the user).\n   - Otherwise, return one row per feature per object, including the galactic coordinates, class name, and object identifier.\n\n10. **Summary of Steps:**\n    - Filter objects by detection date in the `object` table.\n    - Join with `probability` table for class name, using default classifier and ranking.\n    - Join with `feature` table for all features, including galactic coordinates.\n    - Select and output the required columns for each object.\n\n**Note:** No SQL code is provided, only the step-by-step plan for constructing the query.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Main Selection Criteria:**\n   - Objects classified as 'SNII' (Supernova Type II) by the light curve classifier ('lc_classifier'), with ranking = 1 and probability > 0.6.\n   - The classification must be valid for the object (join 'probability' and 'object' tables).\n   - The time window is from MJD 58484.0 (start of 2019) to 59944.0 (end of 2022).\n   - Initial rise rate (dmdt_first) > 0.5 mag/day in both ZTF g-band (fid=1) and r-band (fid=2).\n   - At least 100 days of observations in r-band (magstat.lastmjd - magstat.firstmjd >= 100 for fid=2).\n   - Number of detections (object.ndet) > 30.\n\n2. **Determine the Required Output Columns:**\n   - Object identifier (object.oid)\n   - Candidate identifier (detection.candid)\n   - Magnitude (detection.magpsf)\n   - Magnitude error (detection.sigmapsf)\n   - Band identifier (detection.fid), but rename as f_id\n   - Time of detection (detection.mjd)\n\n3. **Filter Objects by Classification:**\n   - From the 'probability' table, select rows where:\n     - class_name = 'SNII'\n     - classifier_name = 'lc_classifier'\n     - ranking = 1\n     - probability > 0.6\n\n4. **Filter Objects by Number of Detections:**\n   - From the 'object' table, select objects with ndet > 30.\n\n5. **Filter Objects by Initial Rise Rate in g and r Bands:**\n   - From the 'magstat' table, select objects where:\n     - dmdt_first > 0.5 for fid=1 (g-band)\n     - dmdt_first > 0.5 for fid=2 (r-band)\n   - Ensure both conditions are met for the same object (requires two subqueries or a GROUP BY/HAVING approach).\n\n6. **Filter Objects by Duration of Observations in r-band:**\n   - From the 'magstat' table, for fid=2 (r-band), select objects where (lastmjd - firstmjd) >= 100.\n\n7. **Filter Detections by Time Window:**\n   - From the 'detection' table, select detections where mjd >= 58484.0 and mjd <= 59944.0.\n\n8. **Join Tables to Gather All Required Information:**\n   - Join 'probability' and 'object' on oid to apply classification and ndet filters.\n   - Join with 'magstat' (twice or via aggregation) to apply rise rate and duration filters.\n   - Join with 'detection' on oid to get detection-level data, and apply the time window filter.\n\n9. **Select and Rename Columns:**\n   - In the final SELECT, include:\n     - object.oid\n     - detection.candid\n     - detection.magpsf\n     - detection.sigmapsf\n     - detection.fid as f_id\n     - detection.mjd\n\n10. **Ensure Uniqueness and Efficiency:**\n    - Use appropriate WHERE clauses and JOINs to avoid duplicate rows and ensure only objects meeting all criteria are included.\n    - Use indexes on oid, class_name, ranking, probability, fid, and mjd for performance.\n\n11. **Order the Results (Optional):**\n    - Optionally, order the results by object.oid and detection.mjd to show the time evolution per object.\n\n**Summary of Steps:**\n- Filter objects by classification, probability, and number of detections.\n- Ensure initial rise rate > 0.5 mag/day in both g and r bands.\n- Ensure at least 100 days of r-band observations.\n- Select detections within the 2019-2022 MJD range.\n- Join all relevant tables and select the required columns, renaming fid as f_id.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify the Main Output Columns and Their Sources:**\n   - Object identifier: `object.oid`\n   - Candidate identifier: `detection.candid`\n   - Magnitudes: `detection.magpsf`, `detection.magap`, `detection.magapbig`, `detection.magpsf_corr`\n   - Magnitude errors: `detection.sigmapsf`, `detection.sigmagap`, `detection.sigmagapbig`, `detection.sigmapsf_corr`, `detection.sigmapsf_corr_ext`\n   - Band identifier: `detection.fid` (to be renamed as `f_id`)\n   - Time: `detection.mjd`\n\n2. **Filter Objects Classified as SN II with Required Probability:**\n   - Use the `probability` table to select objects where:\n     - `probability.class_name = 'SNII'`\n     - `probability.classifier_name = 'lc_classifier'` (default condition)\n     - `probability.ranking = 1` (default condition)\n     - `probability.probability > 0.6`\n\n3. **Restrict to Objects Detected in 2019-2022:**\n   - Use the `object` table to ensure:\n     - `object.firstmjd >= 58484.0`\n     - `object.lastmjd <= 59944.0`\n\n4. **Initial Rise Rate Condition in g and r Bands:**\n   - Use the `magstat` table to select objects where:\n     - `magstat.fid IN (1, 2)` (1 = g, 2 = r)\n     - `magstat.dmdt_first > 0.5`\n   - Ensure that both g and r bands satisfy this condition for each object:\n     - This requires checking that for each `oid`, there is a `magstat` row with `fid=1` and `dmdt_first > 0.5` AND a row with `fid=2` and `dmdt_first > 0.5`.\n\n5. **At Least 100 Days of Observations in r-band:**\n   - In the `magstat` table, for `fid=2` (r-band), require:\n     - `magstat.lastmjd - magstat.firstmjd >= 100`\n\n6. **Number of Detections Greater Than 30:**\n   - In the `magstat` table, for `fid=2` (r-band), require:\n     - `magstat.ndet > 30`\n\n7. **Join Tables to Gather All Required Information:**\n   - Join `object` and `probability` on `oid`\n   - Join `object` and `magstat` on `oid`\n   - Join `object` and `detection` on `oid`\n   - Ensure that the detection rows returned are for the selected objects only\n\n8. **Select and Rename Columns as Needed:**\n   - Select the required columns from the `detection` table, renaming `fid` as `f_id`\n   - Include the time column (`detection.mjd`)\n\n9. **Return Results as a Function of Time:**\n   - Ensure the results are ordered by `detection.mjd` (time)\n\n10. **Summary of Filtering and Joins:**\n    - Only include objects that:\n      - Are classified as SN II with probability > 0.6 (and default classifier/ranking)\n      - Have first and last detection within 2019-2022\n      - Have initial rise rate > 0.5 mag/day in both g and r bands\n      - Have at least 100 days of observations in r-band\n      - Have more than 30 detections in r-band\n    - For these objects, return all detections (all bands) with the required columns, renaming `fid` as `f_id`, and order by time.\n\n**Note:**  \n- The filtering on `magstat` for both g and r bands requires a subquery or a join that ensures both conditions are met for each object.\n- The main selection of detection rows is for all detections of the selected objects, not just those in g or r band, unless the user wants only g and r band detections (clarify if needed).\n- All joins should be INNER JOINs to ensure only objects meeting all criteria are included.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The `object` table contains ZTF object information, including:\n     - `oid` (ZTF identifier)\n     - `ndet` (number of detections)\n     - `deltajd` (difference between last and first detection date)\n   - The `feature` table contains features for each object, including:\n     - `oid` (object identifier)\n     - `name` (feature name, e.g., 'LinearTrend')\n     - `value` (feature value)\n     - `fid` (filter identifier)\n   - The `probability` table contains classification results, including:\n     - `oid` (object identifier)\n     - `classifier_name` (should be 'lc_classifier')\n     - `ranking` (should be 1)\n     - `classifier_version` (classifier version)\n     - `class_name` (class)\n     - `probability` (probability)\n\n2. **Define Filtering Criteria:**\n   - In the `feature` table, select rows where:\n     - `name` = 'LinearTrend'\n     - `value` > 5\n   - In the `object` table, select rows where:\n     - `deltajd` > 1\n   - In the `probability` table, select rows where:\n     - `classifier_name` = 'lc_classifier'\n     - `ranking` = 1\n\n3. **Determine Required Output Columns:**\n   - From `object`: `oid` (ZTF identifier), `ndet` (number of detections)\n   - From `probability`: `classifier_version`, `class_name`, `probability`\n   - From `feature`: `value` (of 'LinearTrend'), `fid` (filter identifier)\n\n4. **Establish Table Relationships and Joins:**\n   - Join `feature` and `object` on `oid` to associate feature values with object properties.\n   - Join the result with `probability` on `oid` to get classification data.\n\n5. **Apply Filtering Conditions:**\n   - Ensure that only rows meeting all the above criteria are included:\n     - `feature.name` = 'LinearTrend' and `feature.value` > 5\n     - `object.deltajd` > 1\n     - `probability.classifier_name` = 'lc_classifier' and `probability.ranking` = 1\n\n6. **Limit the Number of Results:**\n   - Restrict the output to at most 10 rows.\n\n7. **Select and Return the Required Columns:**\n   - For each qualifying object, return:\n     - `object.oid` (ZTF identifier)\n     - `object.ndet` (number of detections)\n     - `probability.classifier_version`\n     - `probability.class_name`\n     - `probability.probability`\n     - `feature.value` (LinearTrend value)\n     - `feature.fid` (filter identifier)\n\n8. **Order of Operations:**\n   - Apply all filters before limiting the results to 10.\n   - Ensure that the joins are performed efficiently, using indexed columns (`oid`).\n\n9. **Final Output:**\n   - The query should return up to 10 rows, each containing the specified columns for objects with a 'LinearTrend' feature value greater than 5 and a detection date difference greater than 1 day, along with their top-ranked light curve classifier data.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The `feature` table contains the 'LinearTrend' feature, its value, and the filter identifier (`fid`).\n   - The `object` table contains the ZTF object identifier (`oid`), and the number of detections (`ndet`), as well as the difference between last and first detection date (`deltajd`).\n   - The `probability` table contains the light curve classifier data: classifier version (`classifier_version`), class (`class_name`), and probability (`probability`).\n\n2. **Set Filtering Conditions:**\n   - In the `feature` table, select rows where `name = 'LinearTrend'` and `value > 5`.\n   - In the `object` table, select rows where `deltajd > 1`.\n   - In the `probability` table, select rows where:\n     - `ranking = 1` (most likely class, as per default condition).\n     - `classifier_name = 'lc_classifier'` (light curve classifier, as per default condition).\n\n3. **Determine Required Columns for Output:**\n   - From `object`: `oid` (ZTF identifier), `ndet` (number of detections).\n   - From `probability`: `classifier_version`, `class_name`, `probability`.\n   - From `feature`: `value` (of 'LinearTrend'), `fid` (filter identifier).\n\n4. **Establish Table Relationships and Joins:**\n   - Join `feature` and `object` on `oid` (since `feature.oid` references `object.oid`).\n   - Join the result with `probability` on `oid` (since `probability.oid` references `object.oid`).\n\n5. **Apply All Filtering Conditions:**\n   - Ensure that only rows where the feature is 'LinearTrend' and its value is greater than 5 are included.\n   - Ensure that only objects with `deltajd > 1` are included.\n   - Ensure that only the most likely light curve classifier result is included (`ranking = 1` and `classifier_name = 'lc_classifier'`).\n\n6. **Limit the Number of Results:**\n   - Limit the output to at most 10 cases.\n\n7. **Select and Order Columns Appropriately:**\n   - Select the columns in the order requested: ZTF identifier (`oid`), number of detections (`ndet`), classifier version (`classifier_version`), class (`class_name`), probability (`probability`), 'LinearTrend' value (`value`), and filter identifier (`fid`).\n\n8. **Summary of Steps:**\n   - Filter the `feature` table for 'LinearTrend' > 5.\n   - Join with `object` table for `deltajd > 1` and to get `ndet`.\n   - Join with `probability` table for classifier data at ranking 1 and classifier_name 'lc_classifier'.\n   - Select the required columns.\n   - Limit the result to 10 rows.\n\nThis step-by-step plan ensures all user requirements and default database conditions are met for an optimal and accurate query.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query, step by step:\n\n---\n\n### 1. **Define the Set of ZTF Identifiers of Interest**\n- Create a temporary table or CTE (WITH clause) listing the two ZTF object identifiers: 'ZTF19aazhdoy' and 'ZTF17aaaqqtd'.\n- This will be used to filter both the 'xmatch' and 'feature' tables.\n\n---\n\n### 2. **Retrieve All Matches from the 'xmatch' Table**\n- Query the 'xmatch' table for all rows where 'oid' is in the set of the two ZTF identifiers.\n- Select the following columns from 'xmatch':\n  - 'oid' (ZTF identifier)\n  - 'oid_catalog' (identifier in the external catalog)\n  - 'dist' (distance between counterparts)\n- This will provide all catalog matches for the two ZTF objects.\n\n---\n\n### 3. **Retrieve the Desired Features from the 'feature' Table**\n- For each of the two ZTF identifiers, query the 'feature' table for rows where:\n  - 'oid' is in the set of the two ZTF identifiers,\n  - 'name' is one of 'W1-W2', 'g-W2', or 'r-W2',\n  - 'version' is 'lc_classifier_1.2.1-P'.\n- Select the following columns from 'feature':\n  - 'oid' (ZTF identifier)\n  - 'name' (feature name)\n  - 'value' (feature value)\n- This will provide the required features for the two objects.\n\n---\n\n### 4. **Join the Results from 'xmatch' and 'feature'**\n- Perform an INNER JOIN between the results from step 2 ('xmatch') and step 3 ('feature') on the 'oid' column (ZTF identifier).\n- This will associate each catalog match with each feature for the same ZTF object.\n- The join will result in a table where, for each ZTF object and each of its catalog matches, all three features (if present) are listed.\n\n---\n\n### 5. **Select and Rename the Required Output Columns**\n- From the joined table, select and, if necessary, alias the following columns:\n  - 'oid' as the ZTF identifier,\n  - 'oid_catalog' as the catalog object identifier,\n  - 'dist' as the distance between counterparts,\n  - 'name' as the feature name,\n  - 'value' as the feature value.\n\n---\n\n### 6. **Sort the Results**\n- Order the final results by:\n  - 'oid_catalog' (catalog object identifier),\n  - 'name' (feature name).\n\n---\n\n### 7. **Return the Final Table**\n- The final output should be a table with columns:\n  - ZTF identifier,\n  - Catalog object identifier,\n  - Distance between counterparts,\n  - Feature name,\n  - Feature value,\n- Sorted as specified.\n\n---\n\n**Summary of Steps:**\n1. Define the two ZTF identifiers as a CTE or filter.\n2. Query 'xmatch' for all catalog matches for these objects.\n3. Query 'feature' for the three specified features and version for these objects.\n4. INNER JOIN the two result sets on the ZTF identifier.\n5. Select and alias the required columns.\n6. Sort by catalog object identifier and feature name.\n7. Return the final result.\n\n---\n\n**Note:**  \n- No probability or classifier tables are needed, as the request is only for 'xmatch' and 'feature' tables.\n- The join is on 'oid' (ZTF identifier).\n- The query must ensure that only the specified features and version are included.\n- If a feature is missing for a given object, it will not appear in the result (INNER JOIN behavior). If all features should be shown even if missing, a LEFT JOIN could be considered, but the request does not specify this.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify the ZTF Object Identifiers of Interest**\n   - The user is interested in two specific ZTF objects: 'ZTF19aazhdoy' and 'ZTF17aaaqqtd'.\n   - These correspond to the 'oid' column in the relevant tables.\n\n2. **Retrieve All Matches from the 'xmatch' Table for These Objects**\n   - Filter the 'xmatch' table for rows where 'oid' is either 'ZTF19aazhdoy' or 'ZTF17aaaqqtd'.\n   - For each match, extract:\n     - 'oid' (ZTF identifier)\n     - 'oid_catalog' (identifier in the external catalog)\n     - 'dist' (distance between ZTF and catalog object)\n   - Optionally, also keep 'catid' if needed for context, but the user did not request it.\n\n3. **Retrieve the Requested Features from the 'feature' Table**\n   - Filter the 'feature' table for:\n     - 'oid' in ('ZTF19aazhdoy', 'ZTF17aaaqqtd')\n     - 'name' in ('W1-W2', 'g-W2', 'r-W2')\n     - 'version' = 'lc_classifier_1.2.1-P'\n   - For each feature, extract:\n     - 'oid' (ZTF identifier)\n     - 'name' (feature name)\n     - 'value' (feature value)\n\n4. **Join the Results from 'xmatch' and 'feature'**\n   - Join the filtered 'xmatch' and 'feature' tables on 'oid' (ZTF identifier).\n   - This will associate each catalog match with the requested features for the same ZTF object.\n   - For each combination, include:\n     - 'oid' (ZTF identifier)\n     - 'oid_catalog' (catalog object identifier)\n     - 'dist' (distance between counterparts)\n     - 'name' (feature name)\n     - 'value' (feature value)\n\n5. **Select and Order the Output Columns**\n   - Select the following columns for the final output:\n     - ZTF identifier ('oid')\n     - Catalog object identifier ('oid_catalog')\n     - Distance between counterparts ('dist')\n     - Feature name ('name')\n     - Feature value ('value')\n   - Sort the results by 'oid_catalog' (catalog object identifier) and 'name' (feature name), as requested.\n\n6. **Summary of Steps**\n   - Filter 'xmatch' for the two ZTF oids.\n   - Filter 'feature' for the same oids, the three requested feature names, and the specified version.\n   - Join the two filtered tables on 'oid'.\n   - Select the required columns.\n   - Sort by catalog object identifier and feature name.\n\n**Note:** No SQL code is provided, only the step-by-step plan as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify the Object of Interest**\n   - The user wants detections for the ZTF object with oid = 'ZTF20actqnhg'.\n   - This means all relevant detections must have detection.oid = 'ZTF20actqnhg'.\n\n2. **Determine the Required Columns**\n   - From the detection table, the user requests:\n     - detection date (detection.mjd)\n     - isdiffpos flag (detection.isdiffpos)\n     - difference magnitude (detection.magpsf)\n     - difference magnitude uncertainty (detection.sigmapsf)\n   - From the dataquality table, the user wants all columns for the corresponding epochs (i.e., for the same detection).\n\n3. **Establish the Relationship Between Tables**\n   - The detection and dataquality tables are related via the candid (detection.candid = dataquality.candid).\n   - Both tables also have the oid column, but candid is the unique identifier for each detection and is the primary key for both tables.\n\n4. **Filter the Detections**\n   - Apply a filter to select only those rows from detection where oid = 'ZTF20actqnhg'.\n\n5. **Join Detection and Dataquality Tables**\n   - For each detection of the specified object, join with the dataquality table on candid (and optionally oid for extra safety).\n   - This ensures that for each detection, the corresponding dataquality information is retrieved for the same epoch.\n\n6. **Select the Required Columns**\n   - From detection: mjd, isdiffpos, magpsf, sigmapsf.\n   - From dataquality: all columns (i.e., dataquality.*).\n\n7. **Sort the Results**\n   - Order the results by detection date, i.e., detection.mjd in ascending order.\n\n8. **Summary of Steps**\n   - Filter detection table for oid = 'ZTF20actqnhg'.\n   - Join with dataquality on candid (and optionally oid).\n   - Select detection.mjd, detection.isdiffpos, detection.magpsf, detection.sigmapsf, and all columns from dataquality.\n   - Order the results by detection.mjd ascending.\n\n**No SQL code is provided, only the step-by-step plan as requested.**\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify the Object of Interest**\n   - The user is interested in the ZTF object with the identifier 'ZTF20actqnhg'.\n   - This identifier corresponds to the 'oid' column in the relevant tables.\n\n2. **Determine the Main Table for Detections**\n   - The 'detection' table contains all detections for objects, with each detection linked to an 'oid'.\n   - Filter the 'detection' table to only include rows where 'oid' = 'ZTF20actqnhg'.\n\n3. **Select Required Columns from the Detection Table**\n   - The user requests the following columns from the 'detection' table:\n     - Detection date: This is the 'mjd' column.\n     - isdiffpos flag: This is the 'isdiffpos' column.\n     - Difference magnitude: This is the 'magpsf' column.\n     - Uncertainty of the difference magnitude: This is the 'sigmapsf' column.\n\n4. **Join with the Dataquality Table**\n   - The user wants all columns from the 'dataquality' table for the corresponding epochs (detections) of this object.\n   - The 'dataquality' table is linked to the 'detection' table via the 'candid' and 'oid' columns.\n   - Perform an INNER JOIN between 'detection' and 'dataquality' on both 'candid' and 'oid' to ensure only matching detections are included.\n\n5. **Select All Columns from Dataquality**\n   - Include all columns from the 'dataquality' table in the output, as requested.\n\n6. **Sort the Results by Detection Date**\n   - The user wants the results sorted by detection date, which corresponds to the 'mjd' column from the 'detection' table.\n   - Apply an ORDER BY clause on 'detection.mjd' in ascending order.\n\n7. **Assemble the Final Output**\n   - The final output should include:\n     - 'detection.mjd' (detection date)\n     - 'detection.isdiffpos'\n     - 'detection.magpsf'\n     - 'detection.sigmapsf'\n     - All columns from 'dataquality' for the matching 'candid' and 'oid'\n\n**Summary of Steps:**\n1. Filter the 'detection' table for rows where 'oid' = 'ZTF20actqnhg'.\n2. Select the required columns from 'detection': 'mjd', 'isdiffpos', 'magpsf', 'sigmapsf'.\n3. Perform an INNER JOIN with the 'dataquality' table on both 'candid' and 'oid'.\n4. Select all columns from 'dataquality'.\n5. Sort the results by 'detection.mjd' in ascending order.\n6. Return the combined results as specified.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are:\n     - `probability`: to filter objects classified as 'QSO' by the light curve classifier with high probability.\n     - `xmatch`: to retrieve cross-match information for the selected objects.\n     - `allwise`: to retrieve ALLWISE catalog information for the matched objects.\n   - The relevant columns are:\n     - All columns from `xmatch` and `allwise` tables.\n\n2. **Set Filtering Criteria on the 'probability' Table:**\n   - Filter for rows where:\n     - `probability.class_name = 'QSO'`\n     - `probability.classifier_name = 'lc_classifier'` (default condition)\n     - `probability.ranking = 1` (default condition)\n     - `probability.probability > 0.7`\n   - This will select ZTF objects (using `oid`) that are most likely QSOs according to the light curve classifier with a probability greater than 0.7.\n\n3. **Select Distinct ZTF Object Identifiers:**\n   - From the filtered `probability` table, select up to 200 distinct `oid` values.\n   - This ensures the result is limited to at most 200 unique ZTF objects.\n\n4. **Join with the 'xmatch' Table:**\n   - For each selected `oid`, retrieve all columns from the `xmatch` table.\n   - The join should be performed on `xmatch.oid = probability.oid`.\n\n5. **Join with the 'allwise' Table:**\n   - For each row in the `xmatch` table, join with the `allwise` table using `xmatch.oid_catalog = allwise.oid_catalog`.\n   - Retrieve all columns from the `allwise` table.\n\n6. **Select All Columns from 'xmatch' and 'allwise':**\n   - The final output should include all columns from both the `xmatch` and `allwise` tables for each matched object.\n\n7. **Limit the Output:**\n   - Ensure that the total number of distinct ZTF objects (`oid`) in the result does not exceed 200.\n\n8. **Summary of Steps:**\n   - Filter the `probability` table for QSOs with probability > 0.7, classifier 'lc_classifier', and ranking 1.\n   - Select up to 200 distinct `oid` values.\n   - Join these `oid` values with the `xmatch` table to get cross-match information.\n   - Join the resulting rows with the `allwise` table using `oid_catalog`.\n   - Return all columns from both `xmatch` and `allwise` tables for the selected objects.\n\n**Note:** No SQL code is provided, only the step-by-step plan as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nDecomposition Plan:\n\n1. **Identify Relevant Tables and Columns**\n   - The main tables involved are:\n     - `probability`: to filter objects classified as 'QSO' by the light curve classifier with high probability.\n     - `xmatch`: to retrieve cross-match information for the selected objects.\n     - `allwise`: to retrieve ALLWISE catalog information for the cross-matched objects.\n   - All columns from `xmatch` and `allwise` are to be returned.\n\n2. **Set Filtering Criteria in the 'probability' Table**\n   - Filter for rows where:\n     - `probability.class_name = 'QSO'`\n     - `probability.classifier_name = 'lc_classifier'` (default condition)\n     - `probability.ranking = 1` (default condition)\n     - `probability.probability > 0.7`\n   - Select the `oid` values of objects meeting these criteria.\n\n3. **Join with the 'xmatch' Table**\n   - Use the filtered `oid` values to select corresponding rows from the `xmatch` table.\n   - The join should be on `xmatch.oid = probability.oid`.\n   - Retrieve all columns from the `xmatch` table for these objects.\n\n4. **Join with the 'allwise' Table**\n   - For each row in `xmatch`, join with the `allwise` table using `xmatch.oid_catalog = allwise.oid_catalog`.\n   - Retrieve all columns from the `allwise` table for these cross-matched objects.\n\n5. **Select Distinct ZTF Objects**\n   - Ensure that the result contains at most 200 distinct ZTF objects (`oid`).\n   - If multiple cross-matches exist for a single `oid`, ensure that the limit applies to the number of unique `oid` values, not the total number of rows.\n\n6. **Return All Columns from 'xmatch' and 'allwise'**\n   - The final output should include all columns from both the `xmatch` and `allwise` tables for the selected objects.\n\n7. **Limit the Output**\n   - Limit the result to at most 200 distinct ZTF objects as per the user request.\n\nSummary of Steps:\n- Filter `probability` for 'QSO', 'lc_classifier', ranking=1, probability>0.7.\n- Join filtered `oid` values with `xmatch` on `oid`.\n- Join resulting `xmatch.oid_catalog` with `allwise.oid_catalog`.\n- Select all columns from `xmatch` and `allwise`.\n- Limit to 200 distinct ZTF objects (`oid`).\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The query requires information from the `probability` and `gaia_ztf` tables.\n   - All columns from both tables should be returned.\n   - The `probability` table provides classification probabilities and class names.\n   - The `gaia_ztf` table provides information about the Gaia cross-match, including whether the closest Gaia object has changed (`unique1`).\n\n2. **Set Default and User-Specified Conditions for the `probability` Table:**\n   - Only consider rows where `probability.ranking = 1` (default condition).\n   - Only consider rows where `probability.classifier_name = 'lc_classifier'` (default condition).\n   - Only consider rows where `probability.classifier_version = 'hierarchical_rf_1.1.0'` (user-specified).\n   - Only consider rows where `probability.class_name` is either 'LPV' (Long Period Variable) or 'E' (Eclipsing Binary) (user-specified).\n   - Only consider rows where `probability.probability > 0.7` (user-specified).\n\n3. **Set User-Specified Condition for the `gaia_ztf` Table:**\n   - Only consider rows where `gaia_ztf.unique1 = TRUE`, meaning the closest Gaia object has not changed compared to the first alert.\n\n4. **Join the Tables:**\n   - Join `probability` and `gaia_ztf` on the `oid` column, which is the unique object identifier present in both tables.\n\n5. **Select All Columns:**\n   - Select all columns from both `probability` and `gaia_ztf` tables.\n\n6. **Limit the Number of Results:**\n   - Limit the output to at most 50 rows.\n\n7. **Summary of Steps:**\n   - Filter `probability` for ranking 1, classifier 'lc_classifier', version 'hierarchical_rf_1.1.0', class_name in ('LPV', 'E'), and probability > 0.7.\n   - Filter `gaia_ztf` for unique1 = TRUE.\n   - Join the filtered results on `oid`.\n   - Select all columns from both tables.\n   - Limit the result to 50 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nDecomposition Plan:\n\n1. **Identify Relevant Tables and Columns**\n   - The query requires information from the `probability` and `gaia_ztf` tables.\n   - All columns from both tables should be returned.\n   - The `probability` table provides classification probabilities and rankings for each object.\n   - The `gaia_ztf` table provides information about the closest Gaia object and whether it has changed (`unique1`).\n\n2. **Set Required Joins**\n   - Both tables have the `oid` column, which is the unique object identifier and can be used to join them.\n   - Use an INNER JOIN between `probability` and `gaia_ztf` on `oid` to ensure only objects present in both tables are returned.\n\n3. **Apply Conditions on the `probability` Table**\n   - Only consider rows where:\n     - `probability.class_name` is either 'LPV' (Long Period Variable) or 'E' (Eclipsing Binary).\n     - `probability.classifier_name` is 'lc_classifier' (as per default and user request).\n     - `probability.classifier_version` is 'hierarchical_rf_1.1.0'.\n     - `probability.probability` is greater than 0.7.\n     - `probability.ranking` is 1 (default condition for most likely class).\n\n4. **Apply Conditions on the `gaia_ztf` Table**\n   - Only include objects where `gaia_ztf.unique1` is TRUE, meaning the closest Gaia object has not changed compared to the first alert.\n\n5. **Select Required Columns**\n   - Select all columns from both `probability` and `gaia_ztf` tables.\n\n6. **Limit the Number of Results**\n   - Restrict the output to at most 50 rows.\n\n7. **Summary of Steps**\n   - Start from the `probability` table, applying all specified filters.\n   - Join with the `gaia_ztf` table on `oid`.\n   - Apply the `unique1` condition.\n   - Select all columns from both tables.\n   - Limit the result to 50 rows.\n\n8. **Order of Operations**\n   - Filtering on `probability` table (class, classifier, version, probability, ranking).\n   - Join with `gaia_ztf` on `oid`.\n   - Filter on `gaia_ztf.unique1`.\n   - Select all columns.\n   - Apply row limit.\n\nThis step-by-step plan ensures the query is accurate, efficient, and meets all user requirements.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "101-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify the Main Selection Criteria:**\n   - ZTF objects (from the ALeRCE database) must have:\n     - A probability > 0.5 of being a long period variable (class_name = 'LPV') according to the light curve classifier (classifier_name = 'lc_classifier').\n     - A WISE W1 magnitude (w1mpro) between 7 and 8 (inclusive or exclusive, but unless specified, assume inclusive).\n   - The result should include all columns from the 'probability', 'xmatch', and 'allwise' tables.\n   - Limit the output to at most 100 rows.\n\n2. **Determine the Required Tables and Their Relationships:**\n   - The 'probability' table contains the classification probabilities for each object.\n   - The 'xmatch' table links ZTF objects (oid) to external catalogs, including ALLWISE, via the 'oid_catalog' field.\n   - The 'allwise' table contains WISE photometric data, with 'oid_catalog' as the unique identifier.\n   - The 'probability' table is linked to 'xmatch' via 'oid'.\n   - The 'xmatch' table is linked to 'allwise' via 'oid_catalog'.\n\n3. **Define the Filtering Conditions:**\n   - In the 'probability' table:\n     - class_name = 'LPV'\n     - classifier_name = 'lc_classifier'\n     - ranking = 1 (default condition for 'probability' table)\n     - probability > 0.5\n   - In the 'xmatch' table:\n     - catid = 'ALLWISE' (to ensure the cross-match is with the ALLWISE catalog)\n   - In the 'allwise' table:\n     - w1mpro BETWEEN 7 AND 8\n\n4. **Establish the Join Logic:**\n   - Join 'probability' and 'xmatch' on 'oid'.\n   - Join 'xmatch' and 'allwise' on 'oid_catalog'.\n\n5. **Select the Required Columns:**\n   - Select all columns from 'probability', 'xmatch', and 'allwise' tables.\n\n6. **Apply the Row Limit:**\n   - Limit the result to 100 rows.\n\n7. **Order of Operations:**\n   - Filter the 'probability' table for the required class, classifier, ranking, and probability.\n   - Join to 'xmatch' and filter for 'ALLWISE' catalog.\n   - Join to 'allwise' and filter for the W1 magnitude range.\n   - Select all columns from the three tables.\n   - Limit the output to 100 rows.\n\n**Summary of Steps:**\n1. Filter 'probability' for class_name = 'LPV', classifier_name = 'lc_classifier', ranking = 1, and probability > 0.5.\n2. Join the filtered 'probability' results to 'xmatch' on 'oid'.\n3. Filter 'xmatch' for catid = 'ALLWISE'.\n4. Join the filtered 'xmatch' results to 'allwise' on 'oid_catalog'.\n5. Filter 'allwise' for w1mpro between 7 and 8.\n6. Select all columns from 'probability', 'xmatch', and 'allwise'.\n7. Limit the result to 100 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have a probability larger than 0.5 of being a long period variable in the light curve classifier, as well as a WISE W1 magnitude between 7 and 8. Return all columns from the 'probability', 'xmatch' and 'allwise' tables for such objects. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "101-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query:\n\n---\n\n### 1. **Identify Relevant Tables and Columns**\n   - The main tables involved are:\n     - `probability`: Contains classification probabilities for ZTF objects.\n     - `xmatch`: Contains cross-match information between ZTF objects and external catalogs (including ALLWISE).\n     - `allwise`: Contains photometric and positional data for ALLWISE sources.\n   - Key columns:\n     - `probability.oid`, `probability.class_name`, `probability.classifier_name`, `probability.probability`, `probability.ranking`\n     - `xmatch.oid`, `xmatch.catid`, `xmatch.oid_catalog`\n     - `allwise.oid_catalog`, `allwise.w1mpro`\n\n---\n\n### 2. **Set Filtering Conditions for the `probability` Table**\n   - Only consider objects classified as 'LPV' (Long Period Variable) in the light curve classifier:\n     - `probability.class_name = 'LPV'`\n     - `probability.classifier_name = 'lc_classifier'`\n   - Only consider the most likely class for each object:\n     - `probability.ranking = 1`\n   - Only consider objects with a probability greater than 0.5:\n     - `probability.probability > 0.5`\n\n---\n\n### 3. **Join with the `xmatch` Table**\n   - Join `probability` and `xmatch` on `oid` to get cross-match information for the selected ZTF objects.\n   - Only consider cross-matches with the ALLWISE catalog:\n     - `xmatch.catid = 'ALLWISE'`\n   - Retrieve the `oid_catalog` from `xmatch` to use for joining with the `allwise` table.\n\n---\n\n### 4. **Join with the `allwise` Table**\n   - Join `xmatch.oid_catalog` with `allwise.oid_catalog` to get the photometric data for the matched ALLWISE sources.\n   - Filter for WISE W1 magnitude between 7 and 8:\n     - `allwise.w1mpro >= 7 AND allwise.w1mpro <= 8`\n\n---\n\n### 5. **Select Required Columns**\n   - Select all columns from the `probability`, `xmatch`, and `allwise` tables for the objects that meet all the above criteria.\n   - Use table aliases or explicit column selection to avoid ambiguity if necessary.\n\n---\n\n### 6. **Limit the Number of Results**\n   - Restrict the output to at most 100 rows.\n\n---\n\n### 7. **Order of Operations and Query Structure**\n   - Start with the filtered `probability` table as the base.\n   - INNER JOIN with `xmatch` on `oid` and filter for `catid = 'ALLWISE'`.\n   - INNER JOIN with `allwise` on `oid_catalog`.\n   - Apply the W1 magnitude filter in the `allwise` table.\n   - Select all columns from the three tables.\n   - Apply the row limit.\n\n---\n\n### 8. **Summary of Steps**\n   1. Filter `probability` for `class_name = 'LPV'`, `classifier_name = 'lc_classifier'`, `ranking = 1`, and `probability > 0.5`.\n   2. INNER JOIN with `xmatch` on `oid`, filter for `catid = 'ALLWISE'`.\n   3. INNER JOIN with `allwise` on `oid_catalog`.\n   4. Filter for `w1mpro` between 7 and 8.\n   5. Select all columns from `probability`, `xmatch`, and `allwise`.\n   6. Limit the result to 100 rows.\n\n---\n\nThis step-by-step plan ensures that the query is accurate, efficient, and returns the required information as specified.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have a probability larger than 0.5 of being a long period variable in the light curve classifier, as well as a WISE W1 magnitude between 7 and 8. Return all columns from the 'probability', 'xmatch' and 'allwise' tables for such objects. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main ZTF object identifier is in the `object` table (`oid`).\n   - Classification probabilities are in the `probability` table (`oid`, `class_name`, `classifier_name`, `classifier_version`, `probability`, `ranking`).\n   - Information about the nearest PS1 source is in the `ps1_ztf` table (`oid`, `objectidps1`, `sgscore1`, `distpsnr1`).\n   - Per-epoch (detection) information is in the `detection` table (`candid`, `oid`, `fid`).\n   - The SExtractor star/galaxy score and reduced chi-square are not explicitly listed in the schema. If these are present, they are likely in the `detection` table, but if not, they cannot be returned. For this plan, assume columns like `sextractor_sgscore` and `sextractor_chi2` exist in `detection`.\n\n2. **Set Up the Probability Filter:**\n   - Filter the `probability` table for:\n     - `class_name = 'AGN'`\n     - `classifier_name = 'lc_classifier'`\n     - `classifier_version = 'hierarchical_rf_1.1.0'`\n     - `probability > 0.7`\n     - `ranking = 1` (default condition)\n\n3. **Join with the Object Table:**\n   - Join `probability` with `object` on `oid` to get the ZTF object identifier.\n\n4. **Join with the PS1 Table and Apply PS1 Filters:**\n   - Join the result with `ps1_ztf` on `oid`.\n   - Apply the filter: `distpsnr1 < 2` (distance to nearest PS1 source in arcsec).\n\n5. **Apply the Star/Galaxy Score Difference Filter:**\n   - The difference between the PS1 star/galaxy score (`sgscore1` from `ps1_ztf`) and the SExtractor star/galaxy score (assumed as `sextractor_sgscore` from `detection`) must be `< 0.5`.\n   - This requires joining with the `detection` table on `oid` and comparing these two columns for each detection.\n\n6. **Select the Required Columns:**\n   - For the ZTF object: `object.oid` (ZTF identifier), `probability.probability`.\n   - For each epoch (detection): `detection.candid`, `detection.fid`, `detection.sextractor_chi2` (reduced chi-square), `detection.sextractor_sgscore` (SExtractor star/galaxy score).\n   - For the nearest PS1 source: `ps1_ztf.objectidps1`, `ps1_ztf.sgscore1`, `ps1_ztf.distpsnr1`.\n\n7. **Limit the Number of Objects:**\n   - Limit the result to at most 50 unique ZTF objects. If multiple detections per object are returned, ensure the limit applies to the number of unique objects, not detections.\n\n8. **Order and Grouping:**\n   - If needed, order the results by probability (descending) or another relevant metric.\n   - Group by ZTF object if you want to ensure only 50 objects are returned, with all their detections.\n\n9. **Summary of Steps/Subqueries:**\n   - Subquery 1: Select oids from `probability` with the required AGN probability and classifier conditions.\n   - Subquery 2: Join with `object` to get ZTF identifiers.\n   - Subquery 3: Join with `ps1_ztf` and filter on `distpsnr1`.\n   - Subquery 4: Join with `detection` and filter on the star/galaxy score difference.\n   - Final selection: Choose the required columns and apply the 50-object limit.\n\n10. **Assumptions and Notes:**\n    - If the SExtractor star/galaxy score and reduced chi-square are not present in the schema, these fields cannot be returned.\n    - If there are multiple detections per object, the result will include all detections for each of the 50 objects.\n    - All joins are INNER JOINs to ensure only objects meeting all criteria are returned.\n\n**End of Decomposition Plan.**\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - **object**: Contains ZTF object identifiers (`oid`).\n   - **probability**: Contains classification probabilities (`probability`), class name (`class_name`), classifier name (`classifier_name`), classifier version (`classifier_version`), and object identifier (`oid`).\n   - **ps1_ztf**: Contains information about the nearest PS1 source for each ZTF object, including distance to the nearest source (`distpsnr1`), PS1 star/galaxy score (`sgscore1`), and PS1 object identifier (`objectidps1`).\n   - **detection**: Contains per-epoch information, including candidate identifier (`candid`), filter identifier (`fid`), and object identifier (`oid`).\n   - **feature**: Contains per-epoch features, including reduced chi-square (`chi2red`) and SExtractor star/galaxy score (`sgscore`), both associated with a candidate (`candid`).\n\n2. **Filter ZTF Objects by AGN Probability:**\n   - Create a subquery on the `probability` table to select `oid` and `probability` where:\n     - `class_name = 'AGN'`\n     - `classifier_name = 'lc_classifier'`\n     - `classifier_version = 'hierarchical_rf_1.1.0'`\n     - `probability > 0.7`\n     - `ranking = 1` (default condition)\n   - This subquery will yield the set of ZTF objects (oids) with the required AGN probability.\n\n3. **Filter by Distance to Nearest PS1 Source:**\n   - Join the result from step 2 with the `ps1_ztf` table on `oid`.\n   - Filter for `distpsnr1 < 2` (arcsec).\n   - Retain the following columns from `ps1_ztf`: `objectidps1`, `sgscore1`, `distpsnr1`.\n\n4. **Retrieve SExtractor Star/Galaxy Score and Reduced Chi-square:**\n   - For each detection (epoch) of the selected objects, join the `detection` table on `oid`.\n   - For each detection, join the `feature` table twice:\n     - Once to get the `chi2red` value for the corresponding `candid`.\n     - Once to get the SExtractor star/galaxy score (`sgscore`) for the same `candid`.\n   - Ensure that the `feature` table is filtered for the correct feature names (`chi2red` and `sgscore`), and that the join is on `candid`.\n\n5. **Compute the Difference Between PS1 and SExtractor Star/Galaxy Scores:**\n   - For each detection, calculate the absolute difference between `sgscore1` (from `ps1_ztf`) and `sgscore` (from `feature`).\n   - Filter for detections where this difference is less than 0.5.\n\n6. **Assemble the Final Result Set:**\n   - For each detection that passes all filters, select the following columns:\n     - From `object`/`probability`: ZTF identifier (`oid`), AGN probability (`probability`).\n     - From `detection`: candidate identifier (`candid`), filter identifier (`fid`).\n     - From `feature`: reduced chi-square (`chi2red`), SExtractor star/galaxy score (`sgscore`).\n     - From `ps1_ztf`: PS1 object identifier (`objectidps1`), PS1 star/galaxy score (`sgscore1`), distance to nearest PS1 source (`distpsnr1`).\n\n7. **Limit the Number of ZTF Objects:**\n   - Since the request is for at most 50 ZTF objects, apply a `LIMIT 50` to the number of unique ZTF objects (`oid`) in the result set.\n   - If there are multiple detections per object, ensure that the limit is applied to the number of unique objects, not the number of rows (detections).\n\n8. **Order and Grouping:**\n   - Optionally, order the results by probability (descending) or another relevant metric.\n   - Group the results by ZTF object if needed, but ensure all required columns per detection are included.\n\n**Summary of Steps:**\n- Subquery on `probability` for AGN objects with required probability and classifier version.\n- Join with `ps1_ztf` for PS1 proximity and star/galaxy score.\n- Join with `detection` for per-epoch data.\n- Join with `feature` (twice) for reduced chi-square and SExtractor star/galaxy score.\n- Filter on the difference between PS1 and SExtractor star/galaxy scores.\n- Select required columns.\n- Limit to 50 unique ZTF objects.\n- Return all detections (epochs) for those objects, with the specified columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The query requires information from the `probability` table (for classification probabilities and class names) and the `ps1_ztf` table (for star/galaxy scores of the closest PS1 objects).\n   - The common key for joining these tables is `oid`.\n\n2. **Set Default and User-Specified Conditions on the `probability` Table:**\n   - Only consider rows where `probability.ranking = 1` (default condition).\n   - Only consider rows where `probability.classifier_name = 'lc_classifier'` (default condition).\n   - Only consider rows where `probability.classifier_version = 'hierarchical_rf_1.1.0'` (user-specified).\n   - Only consider rows where `probability.class_name` is one of ('CEP', 'DSCT', 'RRL') (user-specified).\n   - Only consider rows where `probability.probability > 0.6` (user-specified).\n\n3. **Set Condition on the `ps1_ztf` Table:**\n   - Only consider rows where the closest PS1 object's star/galaxy score is greater than 0.8. This corresponds to `ps1_ztf.sgscore1 > 0.8`.\n\n4. **Join the Tables:**\n   - Perform an INNER JOIN between the filtered `probability` table and the `ps1_ztf` table on the `oid` column to ensure only objects present in both tables and meeting all conditions are included.\n\n5. **Select Required Columns:**\n   - Select all columns from both the `probability` and `ps1_ztf` tables as requested.\n\n6. **Limit the Number of Results:**\n   - Restrict the output to at most 100 rows.\n\n7. **(Optional) Order the Results:**\n   - If the user does not specify an order, no explicit ordering is required. If needed, you could order by probability descending to get the most probable objects first, but this is not required by the user.\n\n**Summary of Steps:**\n- Filter `probability` for ranking=1, classifier_name='lc_classifier', classifier_version='hierarchical_rf_1.1.0', class_name in ('CEP', 'DSCT', 'RRL'), and probability > 0.6.\n- Filter `ps1_ztf` for sgscore1 > 0.8.\n- INNER JOIN the two tables on `oid`.\n- Select all columns from both tables.\n- Limit the result to 100 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the SQL Query:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The query requires information from the `probability` table (for classification probabilities and class names) and the `ps1_ztf` table (for star/galaxy scores of the closest PS1 objects).\n   - The common key for joining these tables is `oid`.\n\n2. **Set Default and User-Specified Conditions on the `probability` Table:**\n   - Use only rows where `probability.ranking = 1` (default condition).\n   - Use only rows where `probability.classifier_name = 'lc_classifier'` (default condition).\n   - Filter for the specific classifier version: `probability.classifier_version = 'hierarchical_rf_1.1.0'`.\n   - Filter for class names: `probability.class_name IN ('CEP', 'DSCT', 'RRL')` (Cepheid, delta Scuti, RR Lyrae).\n   - Filter for probability: `probability.probability > 0.6`.\n\n3. **Set Condition on the `ps1_ztf` Table:**\n   - Only consider rows where the closest PS1 object has a star/galaxy score greater than 0.8: `ps1_ztf.sgscore1 > 0.8`.\n\n4. **Join the Tables:**\n   - Perform an INNER JOIN between `probability` and `ps1_ztf` on the `oid` column to ensure only objects present in both tables and meeting all conditions are selected.\n\n5. **Select Required Columns:**\n   - Select all columns from both `probability` and `ps1_ztf` tables as requested.\n\n6. **Limit the Number of Results:**\n   - Restrict the output to at most 100 rows.\n\n7. **Summary of Steps:**\n   - a. Filter `probability` table for ranking, classifier name, classifier version, class names, and probability.\n   - b. Filter `ps1_ztf` table for star/galaxy score of the closest PS1 object.\n   - c. Join the filtered results on `oid`.\n   - d. Select all columns from both tables.\n   - e. Limit the result to 100 rows.\n\n**Note:** No SQL code is provided, only the step-by-step plan as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Identify Relevant Tables and Columns:**\n   - The main tables involved are `probability` (for classification probabilities) and possibly `object` (for ZTF identifier, which is `oid`).\n   - The required columns are:\n     - ZTF identifier: `oid` (from `probability` or `object`)\n     - Probability in the stamp classifier for AGN: `probability` (from `probability` table, filtered for `class_name='AGN'` and `classifier_name='stamp_classifier'` and the specified version)\n     - Probability in the light curve classifier for LPV: `probability` (from `probability` table, filtered for `class_name='LPV'` and `classifier_name='lc_classifier'` and default version)\n\n2. **Set Filtering Conditions for Each Classifier:**\n   - For the stamp classifier:\n     - `class_name = 'AGN'`\n     - `classifier_name = 'stamp_classifier'`\n     - `classifier_version = 'stamp_classifier_1.0.4'`\n     - `probability > 0.6`\n   - For the light curve classifier:\n     - `class_name = 'LPV'`\n     - `classifier_name = 'lc_classifier'`\n     - `probability > 0.7`\n     - `ranking = 1` (default condition for `lc_classifier`)\n\n3. **Determine How to Combine the Two Conditions:**\n   - Both conditions must be satisfied for the same object (`oid`).\n   - This requires finding objects that have both a qualifying AGN probability in the stamp classifier and a qualifying LPV probability in the light curve classifier.\n   - This can be achieved by joining or intersecting the results for each condition on `oid`.\n\n4. **Select and Rename the Required Columns:**\n   - For each qualifying object, select:\n     - `oid` as the ZTF identifier.\n     - The AGN probability from the stamp classifier, renamed as `prob_stamp_agn`.\n     - The LPV probability from the light curve classifier, renamed as `prob_lc_lpv`.\n\n5. **Limit the Number of Results:**\n   - Restrict the output to at most 50 objects.\n\n6. **Plan the Query Structure:**\n   - Use two subqueries or CTEs (Common Table Expressions) to select the relevant probabilities for each classifier and class.\n   - Join these subqueries on `oid` to ensure both conditions are met for the same object.\n   - In the final selection, rename the probability columns as specified.\n   - Apply the `LIMIT 50` clause to restrict the number of results.\n\n7. **Summary of Steps:**\n   - Subquery 1: Select `oid` and `probability` (as `prob_stamp_agn`) from `probability` where `class_name='AGN'`, `classifier_name='stamp_classifier'`, `classifier_version='stamp_classifier_1.0.4'`, and `probability > 0.6`.\n   - Subquery 2: Select `oid` and `probability` (as `prob_lc_lpv`) from `probability` where `class_name='LPV'`, `classifier_name='lc_classifier'`, `probability > 0.7`, and `ranking=1`.\n   - Join the two subqueries on `oid`.\n   - Select `oid`, `prob_stamp_agn`, and `prob_lc_lpv` from the joined result.\n   - Limit the output to 50 rows.\n\n**No SQL code is provided, only the step-by-step decomposition as requested.**\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nHere is a detailed decomposition plan for generating the required PostgreSQL query:\n\n---\n\n### 1. **Identify Relevant Tables and Columns**\n   - The main tables involved are:\n     - `probability`: Contains classification probabilities for each object, classifier, and class.\n     - `object`: Contains the ZTF object identifier (`oid`), but not needed for additional columns since `oid` is present in `probability`.\n   - Required columns:\n     - ZTF identifier: `oid` (from `probability` or `object`)\n     - Probability in the stamp classifier for AGN: `probability` (from `probability` where `classifier_name='stamp_classifier'`, `class_name='AGN'`, and `classifier_version='stamp_classifier_1.0.4'`)\n     - Probability in the light curve classifier for LPV: `probability` (from `probability` where `classifier_name='lc_classifier'` and `class_name='LPV'`)\n   - The output columns should be aliased as:\n     - `oid`\n     - `prob_stamp_agn`\n     - `prob_lc_lpv`\n\n---\n\n### 2. **Define Filtering Conditions**\n   - For the AGN probability in the stamp classifier:\n     - `probability.classifier_name = 'stamp_classifier'`\n     - `probability.class_name = 'AGN'`\n     - `probability.classifier_version = 'stamp_classifier_1.0.4'`\n     - `probability.probability > 0.6`\n   - For the LPV probability in the light curve classifier:\n     - `probability.classifier_name = 'lc_classifier'`\n     - `probability.class_name = 'LPV'`\n     - `probability.probability > 0.7`\n     - `probability.ranking = 1` (default condition for `lc_classifier`)\n\n---\n\n### 3. **Handle the Transposed Structure of the `probability` Table**\n   - Since each probability is a separate row, and we need both AGN (stamp) and LPV (lc) probabilities for the same object, we need to:\n     - Create a subquery for objects with AGN probability > 0.6 in the stamp classifier (with the specified version).\n     - Create a subquery for objects with LPV probability > 0.7 in the light curve classifier (with ranking=1).\n     - Find the intersection of `oid`s that satisfy both conditions.\n\n---\n\n### 4. **Retrieve and Join Probabilities for Output**\n   - For each `oid` that satisfies both conditions, retrieve:\n     - The AGN probability from the stamp classifier (aliased as `prob_stamp_agn`).\n     - The LPV probability from the light curve classifier (aliased as `prob_lc_lpv`).\n   - This requires joining the two subqueries on `oid`.\n\n---\n\n### 5. **Limit the Number of Results**\n   - Apply a `LIMIT 50` clause to restrict the output to at most 50 objects.\n\n---\n\n### 6. **Assemble the Query Using Subqueries and JOINs**\n   - Subquery 1: Select `oid` and `probability` as `prob_stamp_agn` from `probability` where the AGN/stamp conditions are met.\n   - Subquery 2: Select `oid` and `probability` as `prob_lc_lpv` from `probability` where the LPV/lc conditions are met.\n   - INNER JOIN the two subqueries on `oid` to get only objects that satisfy both conditions.\n   - Select the required columns from the joined result.\n\n---\n\n### 7. **Final Output Columns and Aliasing**\n   - Ensure the output columns are:\n     - `oid`\n     - `prob_stamp_agn`\n     - `prob_lc_lpv`\n\n---\n\n### 8. **Summary of Steps**\n   1. Subquery for AGN in stamp classifier with probability > 0.6 and correct version.\n   2. Subquery for LPV in lc_classifier with probability > 0.7 and ranking=1.\n   3. INNER JOIN the two subqueries on `oid`.\n   4. Select `oid`, `prob_stamp_agn`, and `prob_lc_lpv`.\n   5. Limit the result to 50 rows.\n\n---\n\nThis plan ensures that only objects meeting both probability criteria are returned, with the required columns and aliases, and that the query is efficient and accurate given the database schema and context.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "91-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the Query:**\n\n1. **Identify the Main Table for ZTF Objects:**\n   - The main table containing ZTF object identifiers and their statistics is the `object` table.\n   - The ZTF identifier is stored in the `oid` column.\n   - The number of detections is stored in the `ndet` column.\n\n2. **Identify the Table and Columns for Features:**\n   - The `feature` table contains the features for each object, including 'W1-W2', 'delta_mag_fid' (difference between maximum and minimum observed magnitude in a given band), and their associated versions.\n   - The relevant columns in the `feature` table are: `oid`, `name`, `value`, `fid`, and `version`.\n\n3. **Filter for Objects with 'W1-W2' Color Lower Than 1:**\n   - Select rows from the `feature` table where `name = 'W1-W2'` and `value < 1`.\n   - This will give the oids of objects that satisfy the color condition, along with the 'W1-W2' value and the feature version.\n\n4. **Retrieve the Required Columns:**\n   - For each object that meets the 'W1-W2' color condition, retrieve:\n     - ZTF identifier (`oid` from `object` table)\n     - Number of detections (`ndet` from `object` table)\n     - 'W1-W2' feature value (`value` from `feature` table, renamed as `w1_w2`)\n     - Feature version (`version` from `feature` table)\n   - For the difference between minimum g- and r-band difference magnitudes:\n     - Find the 'delta_mag_fid' feature for each object, for `fid=1` (g-band) and `fid=2` (r-band).\n     - Retrieve the `value` for both bands, then compute the difference: `delta_mag_fid_g - delta_mag_fid_r`.\n\n5. **Join the Tables Appropriately:**\n   - Join the `object` table with the filtered `feature` table (for 'W1-W2') on `oid`.\n   - For the 'delta_mag_fid' values, join the `feature` table again (aliased as needed) to get the g-band and r-band values for each object.\n\n6. **Select and Rename Columns:**\n   - Select the following columns in the output:\n     - `object.oid` as the ZTF identifier\n     - `object.ndet` as the number of detections\n     - The computed difference between minimum g- and r-band difference magnitudes (`delta_mag_fid_g - delta_mag_fid_r`)\n     - The 'W1-W2' feature value as `w1_w2`\n     - The feature version\n\n7. **Limit the Number of Results:**\n   - Limit the output to at most 100 rows.\n\n8. **Summary of Steps/Subqueries:**\n   - Subquery 1: Filter `feature` for 'W1-W2' < 1, select `oid`, `value` (as `w1_w2`), and `version`.\n   - Subquery 2: For each `oid`, get 'delta_mag_fid' for `fid=1` (g-band) and `fid=2` (r-band).\n   - Main Query: Join `object` with Subquery 1 (on `oid`), and with Subquery 2 (on `oid`), select and compute the required columns, and limit to 100 rows.\n\n9. **Ensure Correctness and Efficiency:**\n   - Use appropriate indexes (e.g., on `feature.oid`, `feature.name`, `feature.fid`) for efficient joins and filtering.\n   - Ensure that the joins do not produce duplicate rows for each object.\n\n**Note:** No SQL code is provided, only the step-by-step decomposition and logic for constructing the query.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have 'W1-W2' color lower than 1. Return the following columns: ZTF identifier, number of detections, difference between minimum g- and r-band difference magnitudes, 'W1-W2' feature value (rename this column to w1_w2), and feature version. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "91-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nDecomposition Plan for the Query:\n\n1. **Identify the Main Table for ZTF Objects:**\n   - The main table containing ZTF object identifiers and their statistics is the `object` table.\n   - The ZTF identifier is stored in the `oid` column.\n   - The number of detections is stored in the `ndet` column.\n\n2. **Identify the Table and Columns for Features:**\n   - The `feature` table contains features for each object, including 'W1-W2' and difference magnitudes for g and r bands.\n   - The 'W1-W2' color is stored as a row in the `feature` table with `name = 'W1-W2'`.\n   - The value of the feature is in the `value` column.\n   - The feature version is in the `version` column.\n\n3. **Identify the Columns for Minimum g- and r-band Difference Magnitudes:**\n   - The minimum g-band difference magnitude is stored as a row with `name = 'min_mag'` and `fid = 1` (g band).\n   - The minimum r-band difference magnitude is stored as a row with `name = 'min_mag'` and `fid = 2` (r band).\n   - The difference between these two values needs to be calculated: min_mag_g - min_mag_r.\n\n4. **Determine the Required Joins and Subqueries:**\n   - Join the `object` table with the `feature` table to get the 'W1-W2' feature for each object.\n   - Join or use subqueries to get the minimum g-band and r-band difference magnitudes for each object from the `feature` table.\n   - Ensure that all features are from the same `version` for each object, or select the appropriate version if not specified.\n\n5. **Apply the Filtering Condition:**\n   - Only include objects where the 'W1-W2' feature value is less than 1 (`feature.value < 1` for `name = 'W1-W2'`).\n\n6. **Select and Rename the Required Columns:**\n   - Select the following columns:\n     - `object.oid` as the ZTF identifier.\n     - `object.ndet` as the number of detections.\n     - The calculated difference between minimum g- and r-band difference magnitudes (min_mag_g - min_mag_r).\n     - The 'W1-W2' feature value, renamed as `w1_w2`.\n     - The `feature.version` as the feature version.\n\n7. **Limit the Number of Results:**\n   - Restrict the output to at most 100 rows.\n\n8. **Assemble the Query Structure:**\n   - Use appropriate JOINs or subqueries to combine the required data from the `object` and `feature` tables.\n   - Ensure that the filtering and calculation are performed efficiently, possibly using CTEs (WITH clauses) for clarity and performance.\n\n9. **Order of Operations:**\n   - First, filter for objects with 'W1-W2' < 1.\n   - Then, retrieve and calculate the required features and statistics.\n   - Finally, limit the result set to 100 rows.\n\n10. **Final Output:**\n    - The resulting table should have columns: ZTF identifier, number of detections, difference between minimum g- and r-band difference magnitudes, w1_w2, and feature version, with at most 100 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have 'W1-W2' color lower than 1. Return the following columns: ZTF identifier, number of detections, difference between minimum g- and r-band difference magnitudes, 'W1-W2' feature value (rename this column to w1_w2), and feature version. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "76-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\n**Decomposition Plan for the User Request:**\n\n1. **Define the External Solar System Object (MPC object):**\n   - The user is interested in the Solar System object with the name '115185' as listed in the MPC archive.\n   - Since the ALeRCE database does not have a direct table for the MPC archive, but the `ss_ztf` table contains a column `ssnamenr` which stores the name of the nearest known Solar System object, use this column to identify relevant entries.\n\n2. **Identify the Closest ZTF Objects:**\n   - The goal is to find all ZTF objects (from the `object` table) that are associated with the Solar System object '115185' and are within 1.5 arcseconds of it.\n   - The `ss_ztf` table links ZTF objects (`oid`) to Solar System objects via the `ssnamenr` column.\n   - The `ssdistnr` column in `ss_ztf` gives the distance (in arcseconds) between the ZTF object and the Solar System object.\n\n3. **Set the Filtering Conditions:**\n   - Filter `ss_ztf` rows where `ssnamenr = '115185'`.\n   - Further filter these rows to only include those where `ssdistnr <= 1.5` (since the user wants objects within 1.5 arcseconds).\n\n4. **Select the Required Columns:**\n   - ZTF identifier: This is the `oid` column from the `ss_ztf` (or `object`) table.\n   - MPC archive magnitude: This is the `ssmagnr` column from the `ss_ztf` table.\n   - Distance between ZTF object detection and MPC object: This is the `ssdistnr` column from the `ss_ztf` table.\n\n5. **Sort the Results:**\n   - Sort the output by the distance column (`ssdistnr`) in ascending order, as requested.\n\n6. **Assemble the Query Structure:**\n   - The main table for this query is `ss_ztf`, as it contains all the required information and links to the ZTF objects.\n   - There is no need to join with the `object` table unless additional object information is required (not requested here).\n\n7. **Final Output:**\n   - The query should return a list of ZTF objects (`oid`) that are within 1.5 arcseconds of the Solar System object '115185', along with their associated MPC archive magnitude (`ssmagnr`) and the distance (`ssdistnr`), sorted by distance.\n\n**Summary of Steps:**\n1. Use the `ss_ztf` table.\n2. Filter rows where `ssnamenr = '115185'`.\n3. Further filter where `ssdistnr <= 1.5`.\n4. Select columns: `oid`, `ssmagnr`, `ssdistnr`.\n5. Sort results by `ssdistnr` ascending.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the Solar System object called '115185' in the MPC archive, find all ZTF objects that lie within 1.5 arcsec from it. Return the following columns, sort by distance: ZTF identifier, MPC archive magnitude, and distance between ZTF object detection and MPC object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
