{"custom_id": "13-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for December = 59914.0\n-- mjd date for September = 60217.0\nDomain Knowledge: \n-- Super Nova (SNe) is a large explosion that takes place at the end of a star's life cycle\n\n # User Request: ''Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "13-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for December = 59914.0\n-- mjd date for September = 60217.0\nDomain Knowledge: \n-- Super Nova (SNe) is a large explosion that takes place at the end of a star's life cycle\n\n # User Request: ''Give me all the SNe that were first detected between december first 2022 and september first 2023. Return the probability class, the last and the first detection date and the oids of the objects.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "10-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the light curve classifier for objects classified in the light curve classifier as SNIa with ranking=1 and CV/Nova with ranking=2, where the difference between the probabilities at each ranking is lower than 0.1. Return the oids, and the probability for each class, naming the columns 'SN_prob' and 'CV_prob' respectively.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "10-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the light curve classifier for objects classified in the light curve classifier as SNIa with ranking=1 and CV/Nova with ranking=2, where the difference between the probabilities at each ranking is lower than 0.1. Return the oids, and the probability for each class, naming the columns 'SN_prob' and 'CV_prob' respectively.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "7-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of January = 59945.0\n-- mjd date for the end of January = 59975.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the stamp classifier for objects whose most likely class according to the stamp classifier is SN, and that had their first detection in January of 2023''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "7-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of January = 59945.0\n-- mjd date for the end of January = 59975.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the stamp classifier for objects whose most likely class according to the stamp classifier is SN, and that had their first detection in January of 2023''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "2-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Give me the objects classified as YSO by their lightcurves (with probability higher than 0.7)''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "2-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Give me the objects classified as YSO by their lightcurves (with probability higher than 0.7)''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "3-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- last june in mjd date: [start=60096.0, end=60125.0]\nDomain Knowledge: 0\n # User Request: ''Give me the objects classified as YSO by the lc classifier (prob higher than 0.7) that were last detected last June''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "3-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- last june in mjd date: [start=60096.0, end=60125.0]\nDomain Knowledge: 0\n # User Request: ''Give me the objects classified as YSO by the lc classifier (prob higher than 0.7) that were last detected last June''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "23-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- it is important to return all the probabilites (different rankings)\n\nDomain Knowledge: 0\n # User Request: ''I want the objects most likely to be either \"SNIa\", \"SNIbc\", \"SNII\", \"SLSN\" classified by the lc_classifier with a probability higher than 0.2, with all the classification probabilites.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "23-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- it is important to return all the probabilites (different rankings)\n\nDomain Knowledge: 0\n # User Request: ''I want the objects most likely to be either \"SNIa\", \"SNIbc\", \"SNII\", \"SLSN\" classified by the lc_classifier with a probability higher than 0.2, with all the classification probabilites.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "32-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- consider the list of objects identifiers: ['ZTF21aaqosfj' 'ZTF21aaqosfm' 'ZTF21aaqosfs' 'ZTF21aaqosff'\n 'ZTF21aaqoski' 'ZTF21aaqoskz' 'ZTF21aaqosfo' 'ZTF21aaqosly'\n 'ZTF21aaqosgi' 'ZTF21aaqospe']\nDomain Knowledge: 0\n # User Request: ''Given a list of oids of asteroids candidates, write a SQL script that returns data from the ss_ztf table with a positive ssdistnr value. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "32-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- consider the list of objects identifiers: ['ZTF21aaqosfj' 'ZTF21aaqosfm' 'ZTF21aaqosfs' 'ZTF21aaqosff'\n 'ZTF21aaqoski' 'ZTF21aaqoskz' 'ZTF21aaqosfo' 'ZTF21aaqosly'\n 'ZTF21aaqosgi' 'ZTF21aaqospe']\nDomain Knowledge: 0\n # User Request: ''Given a list of oids of asteroids candidates, write a SQL script that returns data from the ss_ztf table with a positive ssdistnr value. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "20-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query objects classified by the light curve classifier that are most likely to be RRL with a probability larger than 0.55 and that have 100 or more detections. Write in PostgresSQL.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "20-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query objects classified by the light curve classifier that are most likely to be RRL with a probability larger than 0.55 and that have 100 or more detections. Write in PostgresSQL.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "35-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Give the first 10 elements from the probability table, ordered by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "35-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Give the first 10 elements from the probability table, ordered by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "28-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- table_schema can be 'alerce'\nDomain Knowledge: 0\n # User Request: ''Return a Query in PostgresSQL that returns all the table names available in the alerce DataBase.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "28-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- table_schema can be 'alerce'\nDomain Knowledge: 0\n # User Request: ''Return a Query in PostgresSQL that returns all the table names available in the alerce DataBase.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "36-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Show the feature names and values of the light curves of the object with the oid ZTF20aaelulu. Return also the oid column.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "36-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Show the feature names and values of the light curves of the object with the oid ZTF20aaelulu. Return also the oid column.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "38-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query the top 1000 active galactic nuclei and top 1000 quasi\u2013stellar objects candidates ordered by probability in descending order, that have a probability > 0.6 and 0.5 respectively according to the light curve classifier. From those objects obtain the ones that have between 30 and 200 detections both.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "38-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query the top 1000 active galactic nuclei and top 1000 quasi\u2013stellar objects candidates ordered by probability in descending order, that have a probability > 0.6 and 0.5 respectively according to the light curve classifier. From those objects obtain the ones that have between 30 and 200 detections both.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "24-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Return a query from ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221) for object within 10 degress of the given positions, and with their first detection the first 7 days of February''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "24-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Return a query from ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221) for object within 10 degress of the given positions, and with their first detection the first 7 days of February''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "33-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Given the next list of oids ['ZTF21aaqosfj' 'ZTF21aaqoski' 'ZTF21aaqoskz' 'ZTF21aaqosly' 'ZTF21aaqosmj' 'ZTF21aaqosmi' 'ZTF21aaqosmk' 'ZTF21aaqosmm' 'ZTF21aaqosmp' 'ZTF21aaqosmq'], make a query that returns the magnitudes of their detections, with their oids, candidate identifiers, the date of exposure and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "33-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Given the next list of oids ['ZTF21aaqosfj' 'ZTF21aaqoski' 'ZTF21aaqoskz' 'ZTF21aaqosly' 'ZTF21aaqosmj' 'ZTF21aaqosmi' 'ZTF21aaqosmk' 'ZTF21aaqosmm' 'ZTF21aaqosmp' 'ZTF21aaqosmq'], make a query that returns the magnitudes of their detections, with their oids, candidate identifiers, the date of exposure and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "21-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Can you do a query to get sources classfied as AGN, QSO or Blazar by the ALeRCE light curve classifier, with a minimum number of detections of 30, and a minimum time span between the first and the last detection of 200 days, and also filtering out sources by a predicted class probability higher than 0.5?''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "21-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Can you do a query to get sources classfied as AGN, QSO or Blazar by the ALeRCE light curve classifier, with a minimum number of detections of 30, and a minimum time span between the first and the last detection of 200 days, and also filtering out sources by a predicted class probability higher than 0.5?''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "26-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for August 25 2022 = 59816.0\n-- mjd date for September 10 2022 = 59832.0\nDomain Knowledge: 0\n # User Request: ''Query objects which appeared between august 25 and september 10 of 2022, which are classified as supernova by the stamp classifier with a probability greater than 0.5 or which have more than one detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "26-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for August 25 2022 = 59816.0\n-- mjd date for September 10 2022 = 59832.0\nDomain Knowledge: 0\n # User Request: ''Query objects which appeared between august 25 and september 10 of 2022, which are classified as supernova by the stamp classifier with a probability greater than 0.5 or which have more than one detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "29-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL using the Pan-STARRS1 photometry from the ps1_ztf table, return the oids, sgmag1, srmag1, simag1, szmag1 and sgscore1 columns using oids extracted from the following list: ['ZTF20aawwmqv' 'ZTF21aasqvza' 'ZTF19adcftfw' 'ZTF19aaxqrku' 'ZTF19adceucq']''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "29-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL using the Pan-STARRS1 photometry from the ps1_ztf table, return the oids, sgmag1, srmag1, simag1, szmag1 and sgscore1 columns using oids extracted from the following list: ['ZTF20aawwmqv' 'ZTF21aasqvza' 'ZTF19adcftfw' 'ZTF19aaxqrku' 'ZTF19adceucq']''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "52-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE forced_photometry ( /* this table contains information about the forced photometry */\n    pid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    mag DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    e_mag DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    mag_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    e_mag_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    e_mag_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    field INTEGER, /* field identifier */\n    rcid INTEGER, /* reference catalog identifier */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    sciinpseeing DOUBLE PRECISION, /* seeing in the science image */\n    scibckgnd DOUBLE PRECISION, /* background in the science image */\n    scisigpix DOUBLE PRECISION, /* sigma per pixel in the science image */\n    magzpsci DOUBLE PRECISION, /* zero point magnitude in the science image */\n    magzpsciunc DOUBLE PRECISION, /* uncertainty in the zero point magnitude in the science image */\n    magzpscirms DOUBLE PRECISION, /* rms of the zero point magnitude in the science image */\n    clrcoeff DOUBLE PRECISION, /* color correction coefficient */\n    clrcounc DOUBLE PRECISION, /* uncertainty in the color correction coefficient */\n    exptime DOUBLE PRECISION, /* exposure time */\n    adpctdif1 DOUBLE PRECISION, /* percentage difference in aperture photometry */\n    adpctdif2 DOUBLE PRECISION, /* percentage difference in aperture photometry */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitude */\n    programid INTEGER, /* program identifier */\n    procstatus VARCHAR, /* processing status */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    ranr DOUBLE PRECISION, /* right ascension of the nearest source in the reference image */\n    decnr DOUBLE PRECISION, /* declination of the nearest source in the reference image */\n    magnr DOUBLE PRECISION, /* magnitude of the nearest source in the reference image */\n    sigmagnr DOUBLE PRECISION, /* magnitude error of the nearest source in the reference image */\n    chinr DOUBLE PRECISION, /* chi of the nearest source in the reference image */\n    sharpnr DOUBLE PRECISION /* sharpness of the nearest source in the reference image */\n);\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF23aatekmu' and 'ZTF22abpxoyy', find all epochs in the 'forced_photometry' table that have a status code of '0'. Return all columns from such table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "52-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE forced_photometry ( /* this table contains information about the forced photometry */\n    pid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    mag DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    e_mag DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    mag_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    e_mag_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    e_mag_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    field INTEGER, /* field identifier */\n    rcid INTEGER, /* reference catalog identifier */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    sciinpseeing DOUBLE PRECISION, /* seeing in the science image */\n    scibckgnd DOUBLE PRECISION, /* background in the science image */\n    scisigpix DOUBLE PRECISION, /* sigma per pixel in the science image */\n    magzpsci DOUBLE PRECISION, /* zero point magnitude in the science image */\n    magzpsciunc DOUBLE PRECISION, /* uncertainty in the zero point magnitude in the science image */\n    magzpscirms DOUBLE PRECISION, /* rms of the zero point magnitude in the science image */\n    clrcoeff DOUBLE PRECISION, /* color correction coefficient */\n    clrcounc DOUBLE PRECISION, /* uncertainty in the color correction coefficient */\n    exptime DOUBLE PRECISION, /* exposure time */\n    adpctdif1 DOUBLE PRECISION, /* percentage difference in aperture photometry */\n    adpctdif2 DOUBLE PRECISION, /* percentage difference in aperture photometry */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitude */\n    programid INTEGER, /* program identifier */\n    procstatus VARCHAR, /* processing status */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    ranr DOUBLE PRECISION, /* right ascension of the nearest source in the reference image */\n    decnr DOUBLE PRECISION, /* declination of the nearest source in the reference image */\n    magnr DOUBLE PRECISION, /* magnitude of the nearest source in the reference image */\n    sigmagnr DOUBLE PRECISION, /* magnitude error of the nearest source in the reference image */\n    chinr DOUBLE PRECISION, /* chi of the nearest source in the reference image */\n    sharpnr DOUBLE PRECISION /* sharpness of the nearest source in the reference image */\n);\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF23aatekmu' and 'ZTF22abpxoyy', find all epochs in the 'forced_photometry' table that have a status code of '0'. Return all columns from such table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "49-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abywohm' and 'ZTF20abxgxjd', get all rows from the 'feature' table that provide a feature in the g band''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "49-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abywohm' and 'ZTF20abxgxjd', get all rows from the 'feature' table that provide a feature in the g band''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "46-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all information in the 'detection' table for the ZTF object 'ZTF23aaqmddq', sorting the columns by detection date''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "46-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all information in the 'detection' table for the ZTF object 'ZTF23aaqmddq', sorting the columns by detection date''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "93-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all columns from the 'probability' and 'magstat' tables for ZTF objects that satisfy the following conditions: the 'asteroid' class is first ranked in the stamp classifier, and have a computed corrected light curve. Give at most 10 rows in the resulting table. Order the results by the object identifier from the probability table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "93-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all columns from the 'probability' and 'magstat' tables for ZTF objects that satisfy the following conditions: the 'asteroid' class is first ranked in the stamp classifier, and have a computed corrected light curve. Give at most 10 rows in the resulting table. Order the results by the object identifier from the probability table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "62-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the following columns from the 'probability' table for the ZTF object 'ZTF21aadoizf': oid, name and version of the classifier, class name and its probability and ranking. Sort these columns by classifier name in ascending order and probability in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "62-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the following columns from the 'probability' table for the ZTF object 'ZTF21aadoizf': oid, name and version of the classifier, class name and its probability and ranking. Sort these columns by classifier name in ascending order and probability in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "82-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with identifiers 'J175005.63-141341.8' and 'J072933.88+030810.4' in the ALLWISE catalog, get all columns from the 'xmatch' table, sort by distance''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "82-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with identifiers 'J175005.63-141341.8' and 'J072933.88+030810.4' in the ALLWISE catalog, get all columns from the 'xmatch' table, sort by distance''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "64-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 1000 rows in the 'probability' table that have a probability larger than 0.95 in either 'lc_classifier_top' or 'stamp_classifier' classifiers. Return the following columns: ZTF identifier, name and version of the classifier, name of the class and its probability''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "64-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 1000 rows in the 'probability' table that have a probability larger than 0.95 in either 'lc_classifier_top' or 'stamp_classifier' classifiers. Return the following columns: ZTF identifier, name and version of the classifier, name of the class and its probability''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE gaia_ztf (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate */\n    neargaia DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [arcsec] */\n    neargaiabright DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [arcsec] */\n    maggaia DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [mag] */\n    maggaiabright DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [mag] */\n    unique1 BOOLEAN NOT NULL /* whether the closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid)\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE gaia_ztf (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate */\n    neargaia DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [arcsec] */\n    neargaiabright DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [arcsec] */\n    maggaia DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [mag] */\n    maggaiabright DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [mag] */\n    unique1 BOOLEAN NOT NULL /* whether the closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid)\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "108-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 15 ZTF objects that have more than 20 detections and a probability larger than 0.9 of being a bogus in the stamp classifier version 'stamp_classifier_1.0.4'. Return the following columns: ZTF identifier, number of detections, probability and Galactic latitude as 'gal_b'. Order the results by the object identifier from the object table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "108-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 15 ZTF objects that have more than 20 detections and a probability larger than 0.9 of being a bogus in the stamp classifier version 'stamp_classifier_1.0.4'. Return the following columns: ZTF identifier, number of detections, probability and Galactic latitude as 'gal_b'. Order the results by the object identifier from the object table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "65-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 500 rows in the 'probability' table that satisfy the following conditions for the stamp classifier: the class name is either 'asteroid' or 'bogus'; and the probability is between 0.7 and 0.99. Order the results by the object identifier in descending order.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "65-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 500 rows in the 'probability' table that satisfy the following conditions for the stamp classifier: the class name is either 'asteroid' or 'bogus'; and the probability is between 0.7 and 0.99. Order the results by the object identifier in descending order.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "101-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have a probability larger than 0.5 of being a long period variable in the light curve classifier, as well as a WISE W1 magnitude between 7 and 8. Return all columns from the 'probability', 'xmatch' and 'allwise' tables for such objects. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "101-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\nCREATE TABLE xmatch (\n    oid VARCHAR REFERENCES object(oid), /* ZTF object Id, same 'oid' from the others tables */\n    catid VARCHAR, /* Catalog Id / Name from which the object was matched */\n    oid_catalog VARCHAR NOT NULL, /* Object Id in Catalog */\n    dist DOUBLE PRECISION NOT NULL, /* Distance to the closest ZTF object [arcsec] */\n    class_catalog VARCHAR, /* Class in the given gatalog if reported */\n    period DOUBLE PRECISION /* Period in the given catalog if reported  [days] */\n);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have a probability larger than 0.5 of being a long period variable in the light curve classifier, as well as a WISE W1 magnitude between 7 and 8. Return all columns from the 'probability', 'xmatch' and 'allwise' tables for such objects. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "88-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have the 'bogus' class as ranking 1 in the stamp classifier, as well as a minimum of 20 detections. Return the following columns: ZTF identifier, number of detections, mean RA Dec coordinates, classifier version and probability. Give at most 50 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "88-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE detection (  /* this table contains information about the object detections, or its light curve. Avoid doing filters on this table in any parameter other than oid */\n    candid BIGINT PRIMARY KEY, /* unique candidate identifier */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    mjd DOUBLE PRECISION NOT NULL, /* time of detection in modified julian date */\n    fid INTEGER NOT NULL, /* filter identifier  (1=g; 2=r; 3=i)*/\n    pid FLOAT NOT NULL, /* program identifier */\n    diffmaglim DOUBLE PRECISION, /* limiting difference magnitud */\n    isdiffpos INTEGER NOT NULL, /* whether the difference is positive or negative */\n    nid INTEGER, /* unique night identifier */\n    ra DOUBLE PRECISION NOT NULL, /* inferred right ascension */\n    dec DOUBLE PRECISION NOT NULL, /* inferred declination */\n    magpsf DOUBLE PRECISION NOT NULL, /* point spread function (psf) difference magnitude */\n    sigmapsf DOUBLE PRECISION NOT NULL, /* psf difference magnitude error */\n    magap DOUBLE PRECISION, /* aperture difference magnitude */\n    sigmagap DOUBLE PRECISION, /* aperture difference magnitud error */\n    distnr DOUBLE PRECISION, /* distance to the nearest source in the reference image */\n    rb DOUBLE PRECISION, /* ZTF real bogus score */\n    rbversion VARCHAR, /* version of the ZTF real bogus score */\n    drb DOUBLE PRECISION, /* ZTF deep learning based real bogus score */\n    drbversion VARCHAR, /* versio  of the ZTF deep learning based real bogus score */\n    magapbig DOUBLE PRECISION, /* large aperture magnitude */\n    sigmagapbig DOUBLE PRECISION, /* large aperture magnitude error */\n    rfid INTEGER, /* identifier of the reference image used for the difference image */\n    magpsf_corr DOUBLE PRECISION, /* apparent magnitude (corrected difference magnitude) */\n    sigmapsf_corr DOUBLE PRECISION, /* error of the apparent magnitude assuming point like source */\n    sigmapsf_corr_ext DOUBLE PRECISION, /* error of the apparent magnitude assuming extended source */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s magnitude was corrected */\n    dubious BOOLEAN NOT NULL, /* whether the object is dubious or not */\n    parent_candid BIGINT, /* identifier of the candidate where this information was generated (this happens if the given detection does not pass the real bogus filter, but a later detection does */\n    has_stamp BOOLEAN NOT NULL, /* whether the candidate has an associated image stamp (same as before */\n    step_id_corr VARCHAR NOT NULL /* identifier of the correction step */\n);\nCREATE INDEX ix_ndetection_oid ON detection USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have the 'bogus' class as ranking 1 in the stamp classifier, as well as a minimum of 20 detections. Return the following columns: ZTF identifier, number of detections, mean RA Dec coordinates, classifier version and probability. Give at most 50 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "70-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE reference (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    rfid BIGINT, /* Processing ID for reference image to facilitate archive retrieval */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate (first detection for the template) */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    rcid INTEGER, /* Readout channel ID [00 .. 63] */\n    field INTEGER, /* ZTF field ID */\n    magnr DOUBLE PRECISION, /* magnitude of nearest source in reference image PSF-catalog within 30 arcsec [mag] */\n    sigmagnr DOUBLE PRECISION, /* 1-sigma uncertainty in magnr within 30 arcsec [mag] */\n    chinr DOUBLE PRECISION, /* DAOPhot chi parameter of nearest source in reference image PSF-catalog within 30 arcsec */\n    sharpnr DOUBLE PRECISION, /* DAOPhot sharp parameter of nearest source in reference image PSF-catalog within 30 arcsec */\n    ranr DOUBLE PRECISION NOT NULL, /* Right Ascension of nearest source in reference image PSF-catalog; J2000 [deg] */\n    decnr DOUBLE PRECISION NOT NULL, /* Declination of nearest source in reference image PSF-catalog; J2000 [deg] */\n    mjdstartref DOUBLE PRECISION NOT NULL, /* Observation Modified Julian date of earliest exposure used to generate reference image [days] */\n    mjdendref DOUBLE PRECISION NOT NULL, /* Observation Modified Julian date of latest exposure used to generate reference image [days] */\n    nframesref INTEGER NOT NULL /* Number of frames (epochal images) used to generate reference image */\n    PRIMARY KEY (oid, rfid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all the information available for the ZTF object 'ZTF22aayjqah' in the 'reference' table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "70-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE reference (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    rfid BIGINT, /* Processing ID for reference image to facilitate archive retrieval */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate (first detection for the template) */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    rcid INTEGER, /* Readout channel ID [00 .. 63] */\n    field INTEGER, /* ZTF field ID */\n    magnr DOUBLE PRECISION, /* magnitude of nearest source in reference image PSF-catalog within 30 arcsec [mag] */\n    sigmagnr DOUBLE PRECISION, /* 1-sigma uncertainty in magnr within 30 arcsec [mag] */\n    chinr DOUBLE PRECISION, /* DAOPhot chi parameter of nearest source in reference image PSF-catalog within 30 arcsec */\n    sharpnr DOUBLE PRECISION, /* DAOPhot sharp parameter of nearest source in reference image PSF-catalog within 30 arcsec */\n    ranr DOUBLE PRECISION NOT NULL, /* Right Ascension of nearest source in reference image PSF-catalog; J2000 [deg] */\n    decnr DOUBLE PRECISION NOT NULL, /* Declination of nearest source in reference image PSF-catalog; J2000 [deg] */\n    mjdstartref DOUBLE PRECISION NOT NULL, /* Observation Modified Julian date of earliest exposure used to generate reference image [days] */\n    mjdendref DOUBLE PRECISION NOT NULL, /* Observation Modified Julian date of latest exposure used to generate reference image [days] */\n    nframesref INTEGER NOT NULL /* Number of frames (epochal images) used to generate reference image */\n    PRIMARY KEY (oid, rfid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all the information available for the ZTF object 'ZTF22aayjqah' in the 'reference' table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "53-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE non_detection (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    mjd DOUBLE PRECISION NOT NULL, /* Observation Julian date at start of exposure [days] */\n    diffmaglim DOUBLE PRECISION, /* 5-sigma mag limit in difference image based on PSF-fit photometry [mag] */\n    PRIMARY KEY (oid, fid, mjd)\n);\n\nCREATE INDEX ix_non_detection_oid ON non_detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the date, filter identifier, ZTF identifier and 5-sigma magnitude limit for all non-detections of the ZTF object 'ZTF18adqxemz''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "53-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE non_detection (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    mjd DOUBLE PRECISION NOT NULL, /* Observation Julian date at start of exposure [days] */\n    diffmaglim DOUBLE PRECISION, /* 5-sigma mag limit in difference image based on PSF-fit photometry [mag] */\n    PRIMARY KEY (oid, fid, mjd)\n);\n\nCREATE INDEX ix_non_detection_oid ON non_detection USING hash (oid);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the date, filter identifier, ZTF identifier and 5-sigma magnitude limit for all non-detections of the ZTF object 'ZTF18adqxemz''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "77-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For Solar System identifiers '213673' and '49894', get all ZTF objects in the 'ss_ztf' table that lie at a zero distance from any of them. Return all columns from such table, sort by ZTF identifier and candidate identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "77-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For Solar System identifiers '213673' and '49894', get all ZTF objects in the 'ss_ztf' table that lie at a zero distance from any of them. Return all columns from such table, sort by ZTF identifier and candidate identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "41-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all ALLWISE objects that lie within 5 arcsec of an object called id_1, that has coordinates (RA, Dec) = (132.961, 41.397) deg, or within 10 arcsec of  an object called id_2, having coordinates (RA, Dec) = (139.01, 41.5653). Return a table that includes the following columns. For the input objects: identifier as 'id', coordinates as 'obj_ra' and 'obj_dec', and search radius used for each object in degrees as r_deg; and for the output ALLWISE objects: identifier in the ALLWISE catalog, RA Dec coordinates, and magnitude (and its uncertainty) in the WISE W1 filter''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "41-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE allwise ( /* oid_catalog is the unique identifier for this object in the ALLWISE catalog, is the same as the oid_catalog in the xmatch table, not the ZTF oid in other tables */\n    oid_catalog VARCHAR PRIMARY KEY, /* object Id inside catalog, correspond to column: designation  in ALLWISE : Sexagesimal, equatorial position-based source name in the form: hhmmss.ss+ddmmss.s. The full naming convention for AllWISE Source Catalog sources has the form \"WISEA  Jhhmmss.ss+ddmmss.s,\" where \"WISEA\" indicates the source is from the AllWISE Source Catalog, and \"J\" indicates the position is J2000. The \"WISEA\" acronym is not listed explicitly in the designation column. */\n    ra DOUBLE PRECISION NOT NULL, /* J2000 right ascension with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    dec DOUBLE PRECISION NOT NULL, /* J2000 declination with respect to the 2MASS PSC reference frame from the non-moving source extraction. */\n    w1mpro DOUBLE PRECISION, /* W1 magnitude measured with profile-fitting photometry, or the magnitude of the 95% confidence brightness upper limit if the W1 flux measurement has SNR<2. This column is null if the source is nominally detected in W1, but no useful brightness estimate could be made. */\n    w2mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w3mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w4mpro DOUBLE PRECISION, /* analogous to w1mpro */\n    w1sigmpro DOUBLE PRECISION, /* W1 profile-fit photometric measurement uncertainty in mag units. This column is null if the W1 profile-fit magnitude is a 95% confidence upper limit or if the source is not measurable. */\n    w2sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w3sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    w4sigmpro DOUBLE PRECISION, /* analogous to w1sigmpro */\n    j_m_2mass DOUBLE PRECISION, /* 2MASS J-band magnitude or magnitude upper limit of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band magnitude entry is \"null\". */\n    h_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    k_m_2mass DOUBLE PRECISION, /* analogous to j_m_2mass */\n    j_msig_2mass DOUBLE PRECISION, /* 2MASS J-band corrected photometric uncertainty of the associated 2MASS PSC source. This column is \"null\" if there is no associated 2MASS PSC source or if the 2MASS PSC J-band uncertainty entry is \"null\". */\n    h_msig_2mass DOUBLE PRECISION, /* analogous to j_msig_2mass */\n    k_msig_2mass DOUBLE PRECISION /* analogous to j_msig_2mass */\n);\n\nCREATE INDEX ix_allwise_dec ON allwise USING btree (dec);\nCREATE INDEX ix_allwise_ra ON allwise USING btree (ra);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all ALLWISE objects that lie within 5 arcsec of an object called id_1, that has coordinates (RA, Dec) = (132.961, 41.397) deg, or within 10 arcsec of  an object called id_2, having coordinates (RA, Dec) = (139.01, 41.5653). Return a table that includes the following columns. For the input objects: identifier as 'id', coordinates as 'obj_ra' and 'obj_dec', and search radius used for each object in degrees as r_deg; and for the output ALLWISE objects: identifier in the ALLWISE catalog, RA Dec coordinates, and magnitude (and its uncertainty) in the WISE W1 filter''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "74-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: Note that 'fainter' means 'larger' for magnitudes\nDomain Knowledge: 0\n # User Request: ''For ZTF objects 'ZTF20abmaqeh', 'ZTF18abwxduj' and 'ZTF19aactlln', find all MPC objects brighter than 19.2 mag in the MPC archive. Get the following columns from the 'ss_ztf' table, sort by MPC magnitude in descending order: identifier in both ZTF and MPC, and MPC magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "74-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: Note that 'fainter' means 'larger' for magnitudes\nDomain Knowledge: 0\n # User Request: ''For ZTF objects 'ZTF20abmaqeh', 'ZTF18abwxduj' and 'ZTF19aactlln', find all MPC objects brighter than 19.2 mag in the MPC archive. Get the following columns from the 'ss_ztf' table, sort by MPC magnitude in descending order: identifier in both ZTF and MPC, and MPC magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE probability ( /* this table contains the machine learning derived classification probabilities and rankings */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    class_name VARCHAR, /* name of the class */\n    classifier_name VARCHAR, /* name of the classifier */\n    classifier_version VARCHAR, /* version of the classiifer */\n    probability DOUBLE PRECISION NOT NULL, /* probability of the class given a classifier and version */\n    ranking INTEGER NOT NULL, /* class probability ranking (1 is the most likely class) */\n    PRIMARY KEY (oid, class_name, classifier_name, classifier_version)\n);\nCREATE INDEX ix_probabilities_oid ON probability USING hash (oid);\nCREATE INDEX ix_probabilities_probability ON probability USING btree (probability);\nCREATE INDEX ix_probabilities_ranking ON probability USING btree (ranking);\nCREATE INDEX ix_classification_rank1 ON probability USING btree (ranking) WHERE (ranking = 1);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "66-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE gaia_ztf (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate */\n    neargaia DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [arcsec] */\n    neargaiabright DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [arcsec] */\n    maggaia DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [mag] */\n    maggaiabright DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [mag] */\n    unique1 BOOLEAN NOT NULL /* whether the closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find the distance and Gaia magnitude of the nearest Gaia object to the ZTF object 'ZTF22abftjko', returning also the ZTF object identifier.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "66-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE gaia_ztf (\n    oid VARCHAR REFERENCES object(oid), /* unique identifier for this object */\n    candid BIGINT NOT NULL, /* unique identifier for the subtraction candidate */\n    neargaia DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [arcsec] */\n    neargaiabright DOUBLE PRECISION, /* Distance to closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [arcsec] */\n    maggaia DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog irrespective of magnitude; if exists within 90 arcsec [mag] */\n    maggaiabright DOUBLE PRECISION, /* Gaia (G-band) magnitude of closest source from Gaia DR1 catalog brighter than magnitude 14; if exists within 90 arcsec [mag] */\n    unique1 BOOLEAN NOT NULL /* whether the closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find the distance and Gaia magnitude of the nearest Gaia object to the ZTF object 'ZTF22abftjko', returning also the ZTF object identifier.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "50-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF21aaqytjr' and 'ZTF23abkhwgb', get all features that have a version of 'lc_classifier_1.2.1-P'. Return the following columns, sort by ZTF identifier, filter identifier and feature name: ZTF identifier, feature name and value, and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "50-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF21aaqytjr' and 'ZTF23abkhwgb', get all features that have a version of 'lc_classifier_1.2.1-P'. Return the following columns, sort by ZTF identifier, filter identifier and feature name: ZTF identifier, feature name and value, and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "91-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have 'W1-W2' color lower than 1. Return the following columns: ZTF identifier, number of detections, difference between minimum g- and r-band difference magnitudes, 'W1-W2' feature value (rename this column to w1_w2), and feature version. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "91-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE feature ( /* table with features for a given object, each row contains one feature per object */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    name VARCHAR NOT NULL, /* name of the feature */\n    value DOUBLE PRECISION, /* value of the feature */\n    fid INTEGER NOT NULL, /* which bandpass this is based (1: g, 2: r, 3: i, 12: gr, 13: gi, 23: ri, 123: gri, ) */\n    version VARCHAR REFERENCES feature_version(version) NOT NULL, /* version of the features (see table feature_version) */\n    PRIMARY KEY (oid, name, fid, version)\n);\nCREATE INDEX ix_feature_oid_2 ON feature USING hash (oid);\n\n# Feature Descriptions with their names in the database\n\nAmplitude: Half of the difference between the median of the maximum 5% and of the minimum 5% magnitudes\nAndersonDarling: Test of whether a sample of data comes from a population with a specific distribution (in this case a normal distribution)\nAutocor_length: Lag value where the auto-correlation function becomes smaller than Eta_e\nBeyond1Std: Percentage of points with photometric mag that lie beyond 1 sigma from the mean\nCon: Number of three consecutive data points brighter/fainter than 2 sigma of the light curve\ndelta_mag_fid: Difference between maximum and minimum observed magnitude in a given band\ndelta_mjd_fid: Total timespan of the light curve in a given band\ndelta_period: Absolute value of the difference between the Multiband_period and the MHAOV period obtained using a single band\ndmag_first_det_fid: Difference between the last non-detection diffmaglim in band \"x\" before the first detection in any band and the first detected magnitude in band \"x\"'\ndmag_non_det_fid: Difference between the median non-detection diffmaglim in the \"x\" band before the first detection and the minimum detected magnitude (peak) in the \"x\" band\nEta_e: Ratio of the mean of the squares of successive mag differences to the variance of the light curve\nExcessVar: Measure of the intrinsic variability amplitude [(Std - average photometric error)/Mean]\nfirst_mag: magnitude of the first alert in a given band\ng-r_max: g-r color obtained using the brightest lc_diff (difference light curve) magnitude in each band\ng-r_max_corr: g-r color obtained using the brightest lc_corr (corrected light curve or total magnitude light curve) magnitude in each band\ng-r_mean: g-r color obtained using the mean lc_diff magnitude of each band\ng-r_mean_corr: g-r color obtained using the mean lc_corr magnitude of each band\ng-W2: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\ng-W3: color computed using the mean lc_corr g band magnitude (or the mean g band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\ngal_b: Galactic latitude\ngal_l: Galactic longitude\nGP_DRW_sigma: Amplitude of the variability at short timescales (t << tau), from DRW modeling\nGP_DRW_tau: Relaxation time (tau) from DRW modeling\nGskew: Median-based measure of the skew\nHarmonics_mag_1: Amplitude of the 1st component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_2: Amplitude of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_3: Amplitude of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_4: Amplitude of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_5: Amplitude of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_6: Amplitude of the 6th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mag_7: Amplitude of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_mse: Mean squarre error of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_2: Phase of the 2nd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_3: Phase of the 3rd component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_4: Phase of the 4th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_5: Phase of the 5th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_6: Phase of the 6tth component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nHarmonics_phase_7: Phase of the 7th component of the harmonics series (obtained by fitting a harmonic series up to the seventh harmonic)\nIAR_phi: Level of autocorrelation using a  discrete-time representation of a DRW model\nlast_diffmaglim_before_fid: Last non-detection diffmaglim in the ''x'' band before the first detection in any band\nlast_mjd_before_fid: Last non-detection Modified Julian Date (MJD) in the ''x'' band before the first detection in any band.\nLinearTrend: Slope of a linear fit to the light curve\nmax_diffmaglim_after_fid: Maximum non-detection diffmaglim in the ''x'' band after the first detection in any band\nmax_diffmaglim_before_fid: Maximum non-detection diffmaglim in the ''x'' band before the first detection in any band\nMaxSlope: Maximum absolute magnitude slope between two consecutive observations\nMean: Mean lc_corr magnitude (or mean lc_diff if the source cannot be corrected)\nMeanvariance: Ratio of the standard deviation to the mean magnitude\nmedian_diffmaglim_after_fid: Median non-detection diffmaglim in the ''x'' band after the first detection in any band\nmedian_diffmaglim_before_fid: Median non-detection diffmaglim in the ''x'' band before the first detection in any band\nMedianAbsDev: Median discrepancy of the data from the median data\nMedianBRP: Fraction of photometric points within amplitude/10 of the median mag\nMHPS_high: Variance associated with a 10 day timescale obtained from a MHPS analysis\nMHPS_low: Variance associated with a 100 day timescale obtained from a MHPS analysis\nMHPS_non_zero: Number of points in the light curve used for the MHPS analysis\nMHPS_PN_flag: Flag that reports whether the Poisson Noise is higher than the MHPS_high variance\nMHPS_ratio: Ratio between the MHPS_low and MHPS_high variances for a given band\nmin_mag: minimun magnitude of the alert light curve in a given band\nMultiband_period: Period obtained using the multiband MHAOV periodogram\nn_det: number of detections in the alert light curve of a given band\nn_neg: number of negative detections in the alert light curve (isdiffpos=-1)\nn_non_det_after_fid: Number of non-detections in the ''x'' band after the first detection in any band\nn_non_det_before_fid: Number of non-detections in the ''x'' band before the first detection in any band\nn_pos: number of positive detections in the alert light curve (isdiffpos=+1)\nPairSlopeTrend: Fraction of increasing first differences minus fraction of decreasing first differences over the last 30 time-sorted mag measures\nPercentAmplitude: Largest percentage difference between either max or min mag and median mag\nPeriod_band: Single band period computed using a Multi Harmonic Analysis of Variance (MHAOV) periodogram\npositive_fraction: Fraction of detections in the difference-images of a given band which are brighter than the template image\nPower_rate_1/2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/2\nPower_rate_1/3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/3\nPower_rate_1/4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for P/4\nPower_rate_2: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 2*P\nPower_rate_3: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 3*P\nPower_rate_4: Ratio between the power of the multiband periodogram obtained for the best period candidate (P) and for 4*P\nPPE: Multiband Periodogram Pseudo Entropy\nPsi_CS: Range of a cumulative sum applied to the phase-folded light curve\nPsi_eta: Eta_e index calculated from the folded light curve\nPvar: Probability that the source is intrinsically variable\nQ31: Difference between the 3rd and the 1st quartile of the light curve\nr-W2: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W2 band of AllWISE\nr-W3: Color computed using the mean lc_corr r band magnitude (or the mean r band lc_diff if the source cannot be corrected) and the W3 band of AllWISE\nrb: Median rb (real-bogus) parameter from the ZTF alerts\nRcs: Range of a cumulative sum\nSF_ML_amplitude: Rms magnitude difference of the structure function, computed over a 1 yr timescale\nSF_ML_gamma: Logarithmic gradient of the mean change in magnitude (computed from the structure function)\nsgscore1: Morphological star/galaxy score of the closest source from PanSTARRS1 (values closer to 1 imply a higher likelihood of the source being a star)\nSkew: Skewness measure\nSmallKurtosis: Small sample kurtosis of the magnitudes\nSPM_A: Supernova parametric model  A\nSPM_beta: Supernova parametric model beta\nSPM_chi: Supernova parametric model reduced chi2 of the light curve fit\nSPM_gamma: Supernova parametric model gamma\nSPM_t0: Supernova parametric model t0\nSPM_tau_fall: Supernova parametric model fall time\nSPM_tau_rise: Supernova parametric model rise time\nStd: Standard deviation of the light curve\nStetsonK: Robust kurtosis measure\nW1-W2: color computed using the W1 and W2 bands of AllWISE\nW2-W3: color computed using the W2 and W3 bands of AllWISE\n\n\nCREATE TABLE feature_version (\n    version VARCHAR PRIMARY KEY, /* feature processing version */\n    step_id_feature VARCHAR REFERENCES step(step_id), /* feture step docker id*/\n    step_id_preprocess VARCHAR REFERENCES step(step_id) /* preprocess step docker id*/\n);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have 'W1-W2' color lower than 1. Return the following columns: ZTF identifier, number of detections, difference between minimum g- and r-band difference magnitudes, 'W1-W2' feature value (rename this column to w1_w2), and feature version. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "68-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the ZTF object 'ZTF21abfrbnm' get the following information about its nearest PS1 source: PS1 identifier, g-band magnitude, star/galaxy score, and distance to the ZTF object detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "68-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE ps1_ztf ( /* information about the three closest sources in Pan STARRS */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    objectidps1 DOUBLE PRECISION, /* identifier of the closest source in pan starrs (ps) */\n    sgmag1 DOUBLE PRECISION, /* ps g band magnitude */\n    srmag1 DOUBLE PRECISION, /* ps r band magnitude */\n    simag1 DOUBLE PRECISION, /* ps i band magnitude */\n    szmag1 DOUBLE PRECISION, /* ps z band magnitude */\n    sgscore1 DOUBLE PRECISION, /* ps star galaxy score */\n    distpsnr1 DOUBLE PRECISION, /* distance to closest source in panstarrs */\n    objectidps2 DOUBLE PRECISION,  /* identifier of the second closest source in pan starrs (ps) */\n    sgmag2 DOUBLE PRECISION, /* g-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag2 DOUBLE PRECISION, /* r-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag2 DOUBLE PRECISION, /* i-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag2 DOUBLE PRECISION, /* z-band PSF magnitude of second closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore2 DOUBLE PRECISION, /* Star/Galaxy score of second closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr2 DOUBLE PRECISION, /* Distance to second closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    objectidps3 DOUBLE PRECISION, /* Object ID of third closest source from PS1 catalog; if exists within 30 arcsec */\n    sgmag3 DOUBLE PRECISION, /* g-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    srmag3 DOUBLE PRECISION, /* r-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    simag3 DOUBLE PRECISION, /* i-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    szmag3 DOUBLE PRECISION, /* z-band PSF magnitude of third closest source from PS1 catalog; if exists within 30 arcsec [mag] */\n    sgscore3 DOUBLE PRECISION, /* Star/Galaxy score of third closest source from PS1 catalog; if exists within 30 arcsec: 0 <= sgscore <= 1 where closer to 1 implies higher likelihood of being a star */\n    distpsnr3 DOUBLE PRECISION, /* Distance to third closest source from PS1 catalog; if exists within 30 arcsec [arcsec] */\n    nmtchps INTEGER NOT NULL, /* Number of source matches from PS1 catalog falling within 30 arcsec */\n    unique1 BOOLEAN NOT NULL, /* Whether the first closest object has changed w.r.t the first alert */\n    unique2 BOOLEAN NOT NULL, /* Whether the second closest object has changed w.r.t the first alert */\n    unique3 BOOLEAN NOT NULL /* Whether the third closest object has changed w.r.t the first alert */\n    PRIMARY KEY (oid, candid)\n);\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the ZTF object 'ZTF21abfrbnm' get the following information about its nearest PS1 source: PS1 identifier, g-band magnitude, star/galaxy score, and distance to the ZTF object detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "60-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20adadshh', 'ZTF21aaabvit' and 'ZTF21aaabvjk', find all rows in the 'magstat' table that have zero dubious corrections in the g band. Return the following columns: ZTF identifier, number of detections, initial rise estimate, and first difference magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "60-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE magstat ( /* different statistics for the object divided by band or filter */\n    oid VARCHAR REFERENCES object(oid), /* unique object identifier */\n    fid INTEGER NOT NULL, /* band or filter identifier (1=g; 2=r; 3=i) */\n    stellar BOOLEAN NOT NULL, /* whether we believe the object is stellar */\n    corrected BOOLEAN NOT NULL, /* whether the object\u2019s light curve has been corrected */\n    ndet INTEGER NOT NULL, /* the object number of detection in the given band */\n    ndubious INTEGER NOT NULL, /* the points in the light curve in the given band that we don\u2019t trust  */\n    dmdt_first DOUBLE PRECISION, /* lower limit for the the rate of magnitude change at detection in the given band */\n    dm_first DOUBLE PRECISION, /* change in magnitude with respect to the last non detection at detection in the given band */\n    sigmadm_first DOUBLE PRECISION, /* error in the change of magnitude w.r.t. the last detection in the given band */\n    dt_first DOUBLE PRECISION, /* time between the last non detection and the first detection for the given band */\n    magmean DOUBLE PRECISION, /* mean difference magnitude for the given band */\n    magmedian DOUBLE PRECISION, /* median difference magnitude for the given band */\n    magmax DOUBLE PRECISION, /* maximum difference magnitude for the given band */\n    magmin DOUBLE PRECISION, /* minimum difference magnitude for the given band */\n    magsigma DOUBLE PRECISION, /* dispersion of the difference magnitude for the given band */\n    maglast DOUBLE PRECISION, /* last difference magnitude for the given band */\n    magfirst DOUBLE PRECISION, /* first difference magnitude for the given band */\n    magmean_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    magmedian_corr DOUBLE PRECISION, /* median apparent (corrected) magnitude for the given band */\n    magmax_corr DOUBLE PRECISION, /* maximum apparent (corrected) magnitude for the given band */\n    magmin_corr DOUBLE PRECISION, /* minimum apparent (corrected) magnitude for the given band */\n    magsigma_corr DOUBLE PRECISION, /* dispersion of the apparent (corrected) magnitude for the given band */\n    maglast_corr DOUBLE PRECISION, /* last apparent (corrected) magnitude for the given band */\n    magfirst_corr DOUBLE PRECISION, /* mean apparent (corrected) magnitude for the given band */\n    firstmjd DOUBLE PRECISION, /* time of first detection for the given band */\n    lastmjd DOUBLE PRECISION, /* time of last detection for the given band */\n    step_id_corr VARCHAR NOT NULL, /* correction step id */\n    saturation_rate DOUBLE PRECISION /* saturation level for the given band */\n);\nCREATE INDEX ix_magstats_dmdt_first ON magstat USING btree (dmdt_first);\nCREATE INDEX ix_magstats_firstmjd ON magstat USING btree (firstmjd);\nCREATE INDEX ix_magstats_lastmjd ON magstat USING btree (lastmjd);\nCREATE INDEX ix_magstats_magmean ON magstat USING btree (magmean);\nCREATE INDEX ix_magstats_magmin ON magstat USING btree (magmin);\nCREATE INDEX ix_magstats_magfirst ON magstat USING btree (magfirst);\nCREATE INDEX ix_magstats_ndet ON magstat USING btree (ndet);\nCREATE INDEX ix_magstats_maglast ON magstat USING btree (maglast);\nCREATE INDEX ix_magstats_oid ON magstat USING hash (oid);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20adadshh', 'ZTF21aaabvit' and 'ZTF21aaabvjk', find all rows in the 'magstat' table that have zero dubious corrections in the g band. Return the following columns: ZTF identifier, number of detections, initial rise estimate, and first difference magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "76-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\nThe request is a very difficult and advanced query, so you will need to use JOINs, INTERSECTs and UNIONs statements, together with Nested queries. It is very important that you give every possible detail in each step, describing the statements and the nested-queries that are required.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the Solar System object called '115185' in the MPC archive, find all ZTF objects that lie within 1.5 arcsec from it. Return the following columns, sort by distance: ZTF identifier, MPC archive magnitude, and distance between ZTF object detection and MPC object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "76-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# Your task is to DECOMPOSE the user request into a series of steps required to generate a PostgreSQL query that will be used for retrieving requested information from the ALeRCE database.\nFor this, outline a detailed decomposition plan for its systematic resolution, describing and breaking down the problem into subtasks and/or subqueries. \nBe careful to put all the information and details needed in the description, like conditions, the table and column names, and the details of the database schema. This is very important to ensure the query is optimal and accurate.\nTake in consideration the advices, conditions and names from \"General Context\" and details of the database, or the query will not be optimal.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\nCreating a decomposition plan to generate a PostgreSQL query for retrieving information from the ALeRCE astronomy broker database involves several steps. ALeRCE (Automatic Learning for the Rapid Classification of Events) is a system designed to classify large amounts of astronomical data, typically from surveys like the Zwicky Transient Facility (ZTF). To create a detailed and understandable plan, follow these steps:\n\n1. **Understand the Database Schema:**\n   - Obtain the database schema, which includes tables, columns, data types, relationships, and constraints.\n   - Identify the relevant tables and columns that contain the information you need.\n\n2. **Define the Information Needed:**\n   - Clearly specify what information you want to retrieve. For example, you might be interested in transient events, their classifications, light curves, or cross-matches with other catalogs.\n   - Determine the level of detail required (e.g., specific time ranges, magnitude limits, or particular sky regions).\n\n3. **Formulate the Query Requirements:**\n   - Decide on the selection criteria (e.g., date, magnitude, classification confidence).\n   - Determine if you need to join multiple tables and how they are related.\n   - Consider if you need to aggregate data (e.g., average magnitudes, count of events).\n\n4. **Design the Query:**\n   - Start with the main table that contains the bulk of the information you need.\n   - Use `JOIN` clauses to combine related tables based on common keys.\n   - Apply `WHERE` clauses to filter the data according to your criteria.\n   - Use `GROUP BY` and aggregate functions if necessary.\n   - Decide on the sorting order of the results using `ORDER BY`.\n\n5. **Document the Query:**\n   - Write comments within the SQL code to explain the purpose of different parts of the query.\n   - Create external documentation that describes the query's purpose, the information it retrieves, and any assumptions or limitations.\n\nRemember that the actual query will depend on the specific schema and requirements of the ALeRCE database. Always test your queries to ensure they perform as expected and return accurate results. \n\n# General context about the database:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\nCREATE TABLE ss_ztf ( /* this table contains information about the closest known solar system object */\n    oid VARCHAR REFERENCES object(oid),\n    candid BIGINT NOT NULL, /* unique candidate identifier */\n    ssdistnr DOUBLE PRECISION, /* distance to nearest known solar system object */\n    ssmagnr DOUBLE PRECISION, /* magnitude of nearest known solar system object */\n    ssnamenr VARCHAR /* name to nearest known solar system object. If the object is not a known solar system object, this field is 'null' (VARCHAR) */\n    PRIMARY KEY (oid)\n);\nCREATE INDEX ix_ss_ztf_candid ON ss_ztf USING btree (candid);\nCREATE INDEX ix_ss_ztf_ssnamenr ON ss_ztf USING btree (ssnamenr);\n\n\n# Important details about the database required for the query:\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from all the tables that are used in the query.\n- Use the exact table and column names as they are in the database. This is crucial for the query to work correctly.\n- Use the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', choosing the best option for the query.\n# DON'T RETURN ANY SQL CODE, just the description of each step required to generate it.\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the Solar System object called '115185' in the MPC archive, find all ZTF objects that lie within 1.5 arcsec from it. Return the following columns, sort by distance: ZTF identifier, MPC archive magnitude, and distance between ZTF object detection and MPC object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "44-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abfcszi' and 'ZTF21aaqwjlz', get all epochs that have a reduced chi-square value lower than 3. Return all columns from the 'dataquality' table, sorting them by ZTF identifier in ascending order and peak-pixel S/N in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "44-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o-mini-2024-07-18", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# Context:\n\n## ALeRCE Pipeline Details\n- Stamp Classifier (denoted as \u2018stamp_classifier\u2019): All alerts related to new objects undergo stamp-based classification.\n- Light Curve Classifier (denoted as \u2018lc_classifier\u2019): A balanced hierarchical random forest classifier employing four models and 15 classes.\n- The first hierarchical classifier has three classes: [Periodic, Stochastic, Transient], denoted as \u2018lc_classifier_top.\u2019\n- Three additional classifiers specialize in different spatial object types: Periodic, Transient, and Stochastic, denoted as \u2018lc_classifier_periodic,\u2019 \u2018lc_classifier_transient,\u2019 and \u2018lc_classifier_stochastic,\u2019 respectively.\n- The 15 classes are separated for each object type:\n  - Transient: [SNe Ia ('SNIa'), SNe Ib/c ('SNIbc'), SNe II ('SNII'), and Super Luminous SNe ('SLSN')].\n  - Stochastic: [Active Galactic Nuclei ('AGN'), Quasi Stellar Object ('QSO'), 'Blazar', Cataclysmic Variable/Novae ('CV/Nova'), and Young Stellar Object ('YSO')].\n  - Periodic: [Delta Scuti ('DSCT'), RR Lyrae ('RRL'), Cepheid ('CEP'), Long Period Variable ('LPV'), Eclipsing Binary ('E'), and other periodic objects ('Periodic-Other')].\n## Spatial Object Types by Classifier\n- classifier_name=('lc_classifier', 'lc_classifier_top', 'lc_classifier_transient', 'lc_classifier_stochastic', 'lc_classifier_periodic', 'stamp_classifier')\n- Classes in 'lc_classifier'= ('SNIa', 'SNIbc', 'SNII', 'SLSN', 'QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO', 'LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'lc_classifier_top'= ('Transient', 'Stochastic', 'Periodic')\n- Classes in 'lc_classifier_transient'= ('SNIa', 'SNIbc', 'SNII', 'SLSN')\n- Classes in 'lc_classifier_stochastic'= ('QSO', 'AGN', 'Blazar', 'CV/Nova', 'YSO')\n- Classes in 'lc_classifier_periodic'= ('LPV', 'E', 'DSCT', 'RRL', 'CEP', 'Periodic-Other')\n- Classes in 'stamp_classifier'= ('SN', 'AGN', 'VS', 'asteroid', 'bogus')\n\nIf a query involves selecting astronomical objects based on their celestial coordinates, the Q3C extension for PostgreSQL provides a suite of specialized functions optimized for this purpose. \nThese functions enable efficient spatial queries on large astronomical datasets, including:\n- Retrieving the angular distance between two objects,\n- Determining whether two objects lie within a specified angular separation,\n- Identifying objects located within a circular region, elliptical region, or arbitrary spherical polygon on the celestial sphere.\n\nThe following functions are available in the Q3C extension:\n- q3c_dist(ra1, dec1, ra2, dec2) -- returns the distance in degrees between two points (ra1,dec1) and (ra2,dec2)\n- q3c_join(ra1, dec1, ra2, dec2, radius)  -- returns true if (ra1, dec1) is within radius spherical distance of (ra2, dec2).\n- q3c_ellipse_join(ra1, dec1, ra2, dec2, major, ratio, pa) -- like q3c_join, except (ra1, dec1) have to be within an ellipse with semi-major axis major, the axis ratio ratio and the position angle pa (from north through east)\n- q3c_radial_query(ra, dec, center_ra, center_dec, radius) -- returns true if ra, dec is within radius degrees of center_ra, center_dec. This is the main function for cone searches.\n- q3c_ellipse_query(ra, dec, center_ra, center_dec, maj_ax, axis_ratio, PA ) -- returns true if ra, dec is within the ellipse from center_ra, center_dec. The ellipse is specified by semi-major axis, axis ratio and positional angle.\n- q3c_poly_query(ra, dec, poly) -- returns true if ra, dec is within the spherical polygon specified as an array of right ascensions and declinations. Alternatively poly can be an PostgreSQL polygon type.\n\nIt can be useful to define a set of astronomical sources with associated coordinates directly in a SQL query, you can use a WITH clause such as:\n    WITH catalog (source_id, ra, dec) AS (\n        VALUES ('source_name', ra_value, dec_value),\n        ...)\nThis construct creates a temporary inline table named catalog, which can be used in subsequent queries for cross-matching or spatial filtering operations.\nThis is useful for defining a set of astronomical sources with associated coordinates directly in a SQL query. Then, you can use the Q3C functions to perform spatial queries on this temporary table (e.g. 'FROM catalog c').\nBe careful with the order of the input parameters in the Q3C functions, as they are not always the same as the order of the columns in the catalog table.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with a SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\n\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abfcszi' and 'ZTF21aaqwjlz', get all epochs that have a reduced chi-square value lower than 3. Return all columns from the 'dataquality' table, sorting them by ZTF identifier in ascending order and peak-pixel S/N in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
