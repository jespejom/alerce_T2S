{"custom_id": "15-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that fulfills the user request, the following detailed decomposition plan should be followed:\n\n1. **Identify Relevant Tables and Columns:**\n   - Use the `probability` table to filter objects classified by the `stamp_classifier` with the highest probability (ranking=1) for class `'SN'`.\n     - Columns needed: `oid`, `probability`, `class_name`, `classifier_name`, `ranking`.\n   - Use the `object` table to get the object identifiers (`oid`) and the time of first detection (`firstmjd`).\n   - Use the `detection` table to retrieve the light curve detections for the objects, including `oid`, `candid`, `fid` (filter ID), and other detection details.\n   - Use the `magstat` table to get the filter ID (`fid`) as `magstat_fid` and the initial rise estimate, which corresponds to the feature `dmag_first` for the relevant filter.\n     - Note: The initial rise estimate is defined as the difference in magnitude between the last non-detection and the first detection in the same filter, which corresponds to the `dmag_first` column in `magstat`.\n\n2. **Apply Classification Filter:**\n   - Filter the `probability` table for:\n     - `classifier_name = 'stamp_classifier'`\n     - `class_name = 'SN'`\n     - `ranking = 1` (to get the highest probability class only)\n   - This will yield the list of object IDs (`oid`) classified as SN with the highest probability by the stamp classifier.\n\n3. **Filter Objects by First Detection Date:**\n   - Join the filtered `probability` results with the `object` table on `oid`.\n   - Filter objects whose `firstmjd` is between 60188.0 and 60189.0 inclusive, corresponding to the first two days of September.\n\n4. **Identify Fast Risers:**\n   - The fast riser condition requires that the initial rise rate is at least 0.25 magnitudes/day.\n   - The initial rise rate can be calculated as the difference in magnitude between the last non-detection and the first detection divided by the time difference between these two events.\n   - The `magstat` table contains `dmag_first` (difference in magnitude at first detection) and `dt_first` (time difference between last non-detection and first detection) for each filter.\n   - Join the `magstat` table on `oid` to get these values.\n   - Filter for `dmag_first / dt_first >= 0.25` to select fast risers.\n   - Also, ensure that the `magstat` entries correspond to the same filter as the first detection filter in the `detection` table (or at least consistent with the filter used for the initial rise estimate).\n   - Since the user wants the filter ID from `magstat` as `magstat_fid`, include `magstat.fid` in the output.\n\n5. **Retrieve Light Curve Detections:**\n   - Join the `detection` table on `oid` to get all detections for the selected objects.\n   - Include columns: `oid`, `candid`, `fid` (filter ID).\n   - Only include detections (all rows in `detection` correspond to detections).\n   - No additional filtering on detections is specified, so include all detections for the selected objects.\n\n6. **Retrieve Probabilities from Stamp Classifier:**\n   - For each selected object, retrieve the probability value from the `probability` table for the `stamp_classifier` and class `'SN'` (already filtered in step 2).\n   - Include the `probability` column in the output.\n\n7. **Select and Alias Columns:**\n   - Select the following columns in the final output:\n     - `oid` (object identifier)\n     - `probability` (from `probability` table for `stamp_classifier` and class `'SN'`)\n     - `candid` (from `detection` table)\n     - `fid` (filter ID from `detection` table)\n     - `magstat_fid` (alias for `magstat.fid`)\n     - `dmag_first` (initial rise estimate from `magstat`)\n\n8. **Join Strategy:**\n   - Start from the filtered `probability` table (step 2).\n   - Join with `object` to filter by `firstmjd` (step 3).\n   - Join with `magstat` to get initial rise parameters and filter by fast riser condition (step 4).\n   - Join with `detection` to get light curve detections (step 5).\n   - Ensure joins are on `oid`.\n   - Use INNER JOINs to ensure only objects meeting all criteria are included.\n\n9. **Ordering:**\n   - Order the final results by `oid` ascending.\n\n10. **Additional Considerations:**\n    - Ensure that the `magstat` entries used correspond to the same filter as the first detection filter or at least are consistent with the initial rise estimate definition.\n    - If multiple filters exist for an object in `magstat`, consider selecting the filter corresponding to the first detection filter or the filter with the maximum initial rise rate.\n    - If the user does not specify, include all detections regardless of filter.\n    - Use the exact column and table names as specified.\n    - Apply the default condition for `probability` table: `ranking=1` and `classifier_name='stamp_classifier'` for the classification filter.\n    - The user wants the probability from the stamp classifier, so do not include probabilities from other classifiers.\n\nBy following these steps, the resulting query will retrieve the object identifiers, their highest probability for class `'SN'` from the stamp classifier, all detections (with candid and filter ID), the filter ID from `magstat` as `magstat_fid`, and the initial rise estimate (`dmag_first`), for objects first detected in the first two days of September and qualifying as fast risers, ordered by `oid`.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - Use the `probability` table to filter objects classified by the `stamp_classifier` with the highest probability for class `'SN'`.\n     - Columns: `oid`, `class_name`, `classifier_name`, `probability`, `ranking`.\n   - Use the `object` table to get object identifiers and first detection times.\n     - Columns: `oid`, `firstmjd`.\n   - Use the `detection` table to retrieve light curve detections for the objects.\n     - Columns: `oid`, `candid`, `fid` (filter ID), `mjd`.\n   - Use the `magstat` table to get the filter ID (`fid`) and the initial rise estimate feature.\n     - Columns: `oid`, `fid` (to be aliased as `magstat_fid`), and the feature related to initial rise (likely `dmag_first` or similar, but since the user requests \"initial rise estimate,\" it corresponds to the feature `dmag_first` in `magstat`).\n\n2. **Apply Classification Filter:**\n   - Filter the `probability` table for:\n     - `classifier_name = 'stamp_classifier'`\n     - `class_name = 'SN'`\n     - `ranking = 1` (to get the highest probability class only)\n   - This will give the list of objects (`oid`) classified as SN with the highest confidence by the stamp classifier.\n\n3. **Filter Objects by First Detection Date:**\n   - Use the `object` table to filter objects whose `firstmjd` is within the first two days of September.\n     - Since MJD for September 1 is 60188.0 and for September 2 is 60189.0, filter for `firstmjd >= 60188.0` and `firstmjd < 60190.0` (to include both days fully).\n\n4. **Identify Fast Risers:**\n   - The definition of a fast riser is an object whose first detection is brighter by at least 0.25 magnitudes/day than the last non-detection before the first detection, both in the same filter.\n   - This information is stored in the `magstat` table, specifically in the column `dmag_first` (difference in magnitude between last non-detection and first detection in the same filter).\n   - Filter for `dmag_first >= 0.25` to select fast risers.\n   - Also, ensure that the `magstat` entries correspond to the same object (`oid`) and that the `firstmjd` in `magstat` aligns with the first detection date.\n   - Since the user wants the filter ID from `magstat` as `magstat_fid`, select `fid` from `magstat` and alias it accordingly.\n\n5. **Retrieve Light Curve Detections:**\n   - From the `detection` table, select all detections (`oid`, `candid`, `fid`) for the filtered objects.\n   - Join on `oid` to ensure only detections for the selected objects are included.\n   - No additional filtering on detection dates is specified, so include all detections for these objects.\n   - Include the filter ID (`fid`) and candidate ID (`candid`) as requested.\n\n6. **Combine Data from Multiple Tables:**\n   - Join the filtered `probability` table (step 2) with the `object` table (step 3) on `oid`.\n   - Join the result with the `magstat` table (step 4) on `oid` to get the filter ID and initial rise estimate.\n   - Join with the `detection` table (step 5) on `oid` to get the light curve detections.\n   - Ensure that the joins maintain the filtering conditions and do not multiply rows unnecessarily.\n\n7. **Select Required Columns:**\n   - From `object` or `probability`: `oid`.\n   - From `probability`: `probability` (for the stamp classifier).\n   - From `detection`: `candid`, `fid` (filter ID).\n   - From `magstat`: `fid` aliased as `magstat_fid`, and the initial rise estimate (`dmag_first`).\n\n8. **Ordering the Results:**\n   - Order the final results by `oid` ascending as requested.\n\n9. **Additional Considerations:**\n   - Use the default condition for `probability.ranking = 1` and `classifier_name = 'stamp_classifier'` unless specified otherwise.\n   - Ensure that the `magstat` entries correspond to the same correction step or version if applicable, or use the latest available.\n   - Since the user wants only detections (light curves), avoid including non-detection data.\n   - If multiple `magstat` entries exist per object (due to different filters), include all relevant ones or clarify if only one filter is needed.\n   - Use appropriate INNER JOINs to ensure only objects meeting all criteria are included.\n\nBy following these steps, the resulting query will efficiently retrieve the object identifiers, their highest stamp classifier probabilities for class 'SN', the light curve detections with candid and filter ID, the filter ID from `magstat` as `magstat_fid`, and the initial rise estimate, all filtered by first detection date and fast riser criteria, ordered by object ID.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main object identifier is in the `object` table (`oid`).\n   - Candidate identifier (`candid`), magnitudes, magnitude errors, time of detection (`mjd`), and band identifiers (`fid`) are in the `detection` table.\n   - Classification information, including class name, classifier name, probability, and ranking, is in the `probability` table.\n   - Initial rise estimate (initial rise rate) is represented by `dmdt_first` in the `magstat` table.\n   - Number of detections (`ndet`) is available in the `object` table.\n   \n2. **Define the Selection Criteria Based on User Request:**\n   - Objects classified as 'SNII' (Supernova Type II) by the light curve classifier (`classifier_name = 'lc_classifier'`).\n   - Probability of classification greater than 0.6.\n   - Classification ranking must be 1 (most likely class).\n   - Time range for detections between 2019 and 2022. Since time is stored as Modified Julian Date (MJD), convert the calendar years 2019-2022 to MJD ranges:\n     - 2019-01-01 corresponds approximately to MJD 58484.\n     - 2022-12-31 corresponds approximately to MJD 59926.\n   - Initial rise rate (`dmdt_first`) greater than 0.5 mag/day.\n   - Band identifiers limited to ZTF g and r bands (`fid` in (1, 2)).\n   - Number of detections (`ndet`) greater than 50.\n   \n3. **Determine the Necessary Joins Between Tables:**\n   - Join `probability` and `object` tables on `oid` to filter objects classified as 'SNII' with the required probability and ranking.\n   - Join `magstat` on `oid` to filter objects with initial rise rate (`dmdt_first`) > 0.5 and to ensure the band is g or r (`fid` in (1, 2)).\n   - Join `detection` on `oid` to retrieve candidate identifiers (`candid`), magnitudes (`magpsf` or `magpsf_corr`), magnitude errors (`sigmapsf` or `sigmapsf_corr`), band identifiers (`fid`), and detection times (`mjd`).\n   \n4. **Apply Filters and Conditions:**\n   - Filter `probability` table for:\n     - `class_name = 'SNII'`\n     - `classifier_name = 'lc_classifier'`\n     - `ranking = 1`\n     - `probability > 0.6`\n   - Filter `object` table for:\n     - `ndet > 50`\n   - Filter `magstat` table for:\n     - `dmdt_first > 0.5`\n     - `fid` in (1, 2) (g and r bands)\n   - Filter `detection` table for:\n     - `fid` in (1, 2) (g and r bands)\n     - `mjd` between 58484 and 59926 (corresponding to 2019-2022)\n   \n5. **Select Required Columns:**\n   - From `object`: `oid` (object identifier)\n   - From `detection`: `candid` (candidate identifier), `magpsf` or `magpsf_corr` (magnitude), `sigmapsf` or `sigmapsf_corr` (magnitude error), `fid` (band identifier), `mjd` (time of detection)\n   - From `magstat`: `dmdt_first` (initial rise estimate)\n   \n6. **Decide on the Type of Join:**\n   - Use INNER JOINs to ensure only objects meeting all criteria are included.\n   - Join `probability` to `object` on `oid`.\n   - Join `magstat` to `object` on `oid` and filter by band.\n   - Join `detection` to `object` on `oid` and filter by band and time.\n   \n7. **Ordering and Output:**\n   - Order results by `oid` and `mjd` to show the time evolution of magnitudes for each object.\n   \n8. **Summary of the Query Logic:**\n   - Start from `probability` filtered by class 'SNII', classifier 'lc_classifier', ranking 1, and probability > 0.6.\n   - Join to `object` filtered by `ndet > 50`.\n   - Join to `magstat` filtered by `dmdt_first > 0.5` and `fid` in (1, 2).\n   - Join to `detection` filtered by `fid` in (1, 2) and `mjd` between 58484 and 59926.\n   - Select the requested columns.\n   - Order by object and detection time.\n   \nThis decomposition ensures the query is efficient, uses appropriate filters, and retrieves all requested information accurately.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main object identifier (`oid`) is in the **object** table.\n   - Candidate identifier (`candid`), magnitudes, magnitude errors, time of detection (`mjd`), and band identifiers (`fid`) are in the **detection** table.\n   - Initial rise estimate corresponds to the magnitude change rate at first detection, which is stored as `dmdt_first` in the **magstat** table.\n   - Classification information, including class name and probability, is in the **probability** table.\n   - Number of detections (`ndet`) is in the **object** table.\n   - The time range filter (2019-2022) applies to the detection times (`mjd`), which are in Modified Julian Date (MJD). The MJD range for 2019-2022 needs to be calculated or approximated.\n\n2. **Define Filtering Criteria:**\n   - Select objects classified as 'SNII' (Supernova Type II) with:\n     - `probability.class_name = 'SNII'`\n     - `probability.classifier_name = 'lc_classifier'` (default condition)\n     - `probability.ranking = 1` (default condition to get the most likely class)\n     - `probability.probability > 0.6`\n   - Objects must have:\n     - Number of detections (`object.ndet`) greater than 50.\n   - Initial rise rate (`magstat.dmdt_first`) greater than 0.5 mag/day.\n   - Band identifiers restricted to ZTF g and r bands, which correspond to `fid` values 1 (g) and 2 (r).\n   - Time of detections (`detection.mjd`) within the years 2019 to 2022. Convert calendar years to MJD:\n     - Approximate MJD for 2019-01-01: 58484\n     - Approximate MJD for 2022-12-31: 59927\n     - Filter detections with `mjd` between 58484 and 59927.\n\n3. **Determine Table Joins and Relationships:**\n   - Join **probability** to **object** on `oid` to filter objects by classification and probability.\n   - Join **magstat** to **object** on `oid` to filter by initial rise rate (`dmdt_first`) and band (`fid`).\n   - Join **detection** to **object** on `oid` to retrieve candidate identifiers, magnitudes, magnitude errors, band identifiers, and detection times.\n   - Ensure that the joins maintain the filtering conditions and do not multiply rows unnecessarily.\n\n4. **Select Required Columns:**\n   - From **object**: `oid` (object identifier).\n   - From **detection**: `candid` (candidate identifier), `magpsf` (magnitude), `sigmapsf` (magnitude error), `fid` (band identifier), `mjd` (time of detection).\n   - From **magstat**: `dmdt_first` (initial rise rate).\n   - Optionally, include `step_id_corr` or other relevant columns if needed for data provenance or filtering.\n\n5. **Apply Filtering Conditions in the Query:**\n   - Filter on `probability.class_name = 'SNII'`, `probability.classifier_name = 'lc_classifier'`, `probability.ranking = 1`, and `probability.probability > 0.6`.\n   - Filter on `object.ndet > 50`.\n   - Filter on `magstat.dmdt_first > 0.5` and `magstat.fid IN (1, 2)` to restrict to g and r bands.\n   - Filter on `detection.mjd` between 58484 and 59927.\n   - Filter on `detection.fid IN (1, 2)` to restrict detections to g and r bands.\n\n6. **Consider Query Performance and Index Usage:**\n   - Use indexed columns for filtering where possible (`probability.ranking`, `probability.classifier_name`, `probability.class_name`, `object.ndet`, `magstat.dmdt_first`, `detection.mjd`, `detection.fid`).\n   - Use INNER JOINs to ensure only matching records are returned.\n   - Avoid unnecessary columns in SELECT to optimize performance.\n\n7. **Order and Format the Results:**\n   - Order results by `oid` and `mjd` to present detections chronologically per object.\n   - Return all requested columns clearly labeled.\n\n8. **Summary of the Query Logic:**\n   - Start from the **probability** table filtered by class 'SNII', classifier 'lc_classifier', ranking 1, and probability > 0.6.\n   - Join to **object** to get `oid` and `ndet > 50`.\n   - Join to **magstat** filtered by `dmdt_first > 0.5` and `fid` in (1, 2).\n   - Join to **detection** filtered by `mjd` in 2019-2022 and `fid` in (1, 2).\n   - Select the requested columns: `oid`, `candid`, `magpsf`, `sigmapsf`, `dmdt_first`, `fid`, and `mjd`.\n   - Order by `oid` and `mjd`.\n\nThis decomposition plan ensures the query will retrieve the object identifiers, candidate identifiers, magnitudes, magnitude errors, initial rise estimates, and band identifiers as a function of time for SN II classified objects meeting the specified criteria in the years 2019-2022.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves objects from the ALeRCE database based on the user's request, follow this detailed decomposition plan:\n\n1. **Define the Input Positions and Radius:**\n   - Create a temporary inline table (using a WITH clause) named, for example, `catalog`, containing the three sources with their identifiers and celestial coordinates (right ascension and declination):\n     - 'source_1' at RA=160.18301441363647, Dec=33.0164673528409\n     - 'source_2' at RA=174.21524897555543, Dec=44.83789535222221\n   - The search radius is 10 degrees around each source position.\n\n2. **Select Objects Within 10 Degrees of the Given Positions:**\n   - Use the Q3C extension function `q3c_join` to perform a spatial join between the `object` table and the `catalog` temporary table.\n   - The join condition should check if the object's mean coordinates (`meanra`, `meandec`) lie within 10 degrees of any of the catalog positions.\n   - This will filter objects spatially near the specified sources.\n\n3. **Filter Objects by First Detection Date:**\n   - Use the `firstmjd` column in the `object` table to filter objects whose first detection occurred within the first 7 days of February.\n   - According to the external knowledge, the Modified Julian Date (MJD) for February 1 is 59976.0 and for February 7 is 59982.0.\n   - Apply a `WHERE` clause to select objects with `firstmjd` between 59976.0 and 59982.0 inclusive.\n\n4. **Join with the Probability Table for Classification Filtering:**\n   - Join the `object` table with the `probability` table on the `oid` column to access classification probabilities.\n   - Apply the default conditions for the `probability` table:\n     - `ranking = 1` to select only the most likely class.\n     - `classifier_name = 'stamp_classifier'` as specified by the user.\n   - Filter for classes related to supernovae (SN) in the `stamp_classifier`.\n     - According to the general context, the `stamp_classifier` classes include 'SN', 'AGN', 'VS', 'asteroid', 'bogus'.\n     - Since the user requests SN probabilities > 0.4, filter for `class_name = 'SN'`.\n   - Apply a probability threshold condition: `probability > 0.4`.\n\n5. **Select the Required Columns:**\n   - Since the user did not specify particular columns, select all columns (`SELECT *`) from the joined tables (`object` and `probability`).\n   - Optionally, include the source identifier from the `catalog` table to indicate which input source each object is near.\n\n6. **Combine All Conditions and Joins:**\n   - The query will involve:\n     - A WITH clause defining the `catalog` table with the input sources.\n     - An INNER JOIN between `object` and `catalog` using `q3c_join` for spatial filtering.\n     - An INNER JOIN between `object` and `probability` for classification filtering.\n     - WHERE clauses for date filtering (`firstmjd`), classification filtering (`ranking`, `classifier_name`, `class_name`), and probability threshold.\n\n7. **Ordering and Final Output:**\n   - If desired, order the results by probability descending to prioritize higher confidence SN classifications.\n   - Otherwise, no specific ordering is required.\n\nThis decomposition ensures the query efficiently retrieves objects near the specified positions, detected in the first week of February, classified as supernovae by the stamp classifier with high confidence.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that fulfills the user request, the following detailed decomposition plan should be followed:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main table for object information is `object`.\n     - Columns needed: `oid` (object identifier), `meanra`, `meandec`.\n   - The `probability` table contains classification probabilities.\n     - Columns needed: `oid`, `class_name`, `classifier_name`, `probability`, `ranking`.\n   - The user requests columns `value`, `name`, `version`, and a \"source identifier\" (likely referring to the step or classification source).\n     - `name` and `version` can be obtained from the `step` table, which contains step metadata.\n     - `value` is not explicitly defined in the schema; it may refer to the probability value or another relevant metric. Since the user requests it alongside `name` and `version`, it is likely the `probability` column from the `probability` table.\n     - The \"source identifier\" is ambiguous but likely corresponds to the `step_id` or `classifier_version` from the `probability` table or the `step` table. Since the user wants `name` and `version` from the `step` table, the source identifier can be the `step_id` or `classifier_version` linked to the classification.\n   - The `object` table does not have `sgscore1` column mentioned in the schema. This suggests `sgscore1` is either a user-defined column or from another table not listed. Since it is required, assume it is a column in the `object` table or a related table. If it is in another table, identify and join accordingly. If not available, clarify or omit.\n   - The user wants the distance from the center of Abell 370 calculated using the `q3c_dist` function.\n\n2. **Apply Time Filter for First Detection in July 2023:**\n   - Use the `firstmjd` column in the `object` table.\n   - Filter objects where `firstmjd` is between 60126.0 and 60156.0 (start and end of July 2023).\n\n3. **Apply Spatial Filter Using Q3C:**\n   - The center coordinates of Abell 370 are RA=39.97, Dec=-1.5768.\n   - The search radius is 1000 arcmin, which equals 16.16667 degrees.\n   - Use the `q3c_radial_query` function to filter objects within this radius based on their `meanra` and `meandec`.\n   - Also calculate the distance using `q3c_dist(meanra, meandec, 39.97, -1.5768)` and return it as `dist`.\n\n4. **Filter Based on `sgscore1` < 0.3:**\n   - Since `sgscore1` is not in the provided schema, verify its location.\n   - If it is in the `object` table, apply the filter directly.\n   - If it is in another table, join that table accordingly.\n   - If unavailable, note this as a limitation or clarify.\n\n5. **Filter Based on Stamp Classifier Probabilities:**\n   - Use the `probability` table.\n   - Filter for `classifier_name = 'stamp_classifier'`.\n   - Only consider the highest probability class per object (`ranking = 1`).\n   - Exclude objects where the highest probability class is 'asteroid' or 'bogus'.\n   - Join the `probability` table with the `object` table on `oid`.\n\n6. **Retrieve Required Columns:**\n   - From `object`: `oid`, `meanra`, `meandec`.\n   - From `probability`: `probability` as `value`, `class_name` (if needed), `classifier_version` as `version`.\n   - From `step`: `name` and `version` corresponding to the `classifier_version` or `step_id` linked to the classification.\n     - Join `step` table on `step_id` = `classifier_version` or another appropriate key.\n   - Include the calculated distance as `dist`.\n\n7. **Construct Joins:**\n   - Inner join `object` and `probability` on `oid`.\n   - Inner join `probability` and `step` on `classifier_version` = `step_id` (assuming this relation).\n   - If `sgscore1` is in another table, join that table accordingly.\n\n8. **Apply Default Conditions:**\n   - For the `probability` table, always filter by `ranking = 1` and `classifier_name = 'stamp_classifier'` as per user request.\n   - Apply all other filters as described.\n\n9. **Ordering and Output:**\n   - The user does not specify ordering; default ordering can be by distance ascending or by `oid`.\n   - Select the columns as requested: `oid`, `value` (probability), `name` (from step), `version` (from step), `meanra`, `meandec`, source identifier (likely `classifier_version` or `step_id`), and `dist`.\n\n10. **Summary of Steps:**\n    - Filter `object` by `firstmjd` in July 2023.\n    - Filter `object` by spatial location within 16.16667 degrees of (39.97, -1.5768) using `q3c_radial_query`.\n    - Filter `object` by `sgscore1 < 0.3`.\n    - Join with `probability` filtered by `classifier_name = 'stamp_classifier'` and `ranking = 1`.\n    - Exclude objects with `class_name` in ('asteroid', 'bogus').\n    - Join with `step` table to get `name` and `version`.\n    - Calculate distance using `q3c_dist`.\n    - Select requested columns.\n\nThis decomposition plan ensures the query will retrieve the object identifiers and associated metadata for objects first detected in July 2023, within the specified spatial radius, with low `sgscore1`, and whose top stamp classifier probability is not 'asteroid' or 'bogus', including the requested columns and the distance from the Abell 370 center.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that fulfills the user request, the following detailed decomposition plan should be followed:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main table for object information is `object`, which contains `oid`, `meanra`, and `meandec`.\n   - The `probability` table contains classification probabilities, including the classifier name, class name, probability, and ranking.\n   - The user requests columns `oid`, `value`, `name`, `version`, `meanra`, `meandec`, the source identifier, and the distance as `dist`.\n     - `oid` is from the `object` table.\n     - `meanra` and `meandec` are from the `object` table.\n     - `name` and `version` likely refer to the `step` table columns, which contain pipeline step information.\n     - `value` and \"source identifier\" are not explicitly defined in the schema provided. Since the user requests \"value\" and \"source identifier,\" and these are not columns in `object` or `probability`, it is necessary to clarify or interpret:\n       - Possibly \"value\" refers to the probability value from the `probability` table.\n       - \"source identifier\" could be the `oid` or another identifier; since no other source identifier is defined, assume it is `oid`.\n   - The `stamp_classifier` classification probabilities are stored in the `probability` table with `classifier_name='stamp_classifier'`.\n   - The `sgscore1` column is not explicitly listed in the schema provided. It is likely a column in the `object` table or another table not listed. Since it is not in the schema, assume it is in the `object` table or a related table. If it is in another table, a join will be needed. For this plan, assume it is in the `object` table.\n\n2. **Apply Time Filter for First Detection in July 2023:**\n   - Use the `firstmjd` column in the `object` table.\n   - Filter objects where `firstmjd` is between 60126.0 and 60156.0 (start and end of July 2023).\n\n3. **Apply Spatial Filter Using Q3C:**\n   - Use the `q3c_radial_query` function to filter objects within a radius of 16.16667 degrees (1000 arcmin) from the center of Abell 370 (RA=39.97, Dec=-1.5768).\n   - The function will be applied on `meanra` and `meandec` columns of the `object` table.\n\n4. **Apply sgscore1 Filter:**\n   - Filter objects with `sgscore1 < 0.3`.\n   - Since `sgscore1` is not explicitly in the schema, confirm its table and join if necessary. If it is in the `object` table, apply the filter directly.\n\n5. **Filter Based on Stamp Classifier Probabilities:**\n   - Join the `probability` table on `oid` to get the classification probabilities for each object.\n   - Filter for `classifier_name = 'stamp_classifier'`.\n   - Restrict to the highest probability class per object by filtering `ranking = 1`.\n   - Exclude objects where the highest probability class is 'asteroid' or 'bogus'.\n   - Retrieve the `value` column as the probability value from the `probability` table.\n\n6. **Retrieve Step Information:**\n   - Join the `step` table to get the `name` and `version` columns.\n   - The join key is likely `step_id` in the `object` table or `probability` table. Since `step_id_corr` is in the `object` table, and the user requests `name` and `version`, join `step` on `object.step_id_corr = step.step_id`.\n   - This will provide the pipeline step name and version related to the object.\n\n7. **Calculate Distance Using q3c_dist:**\n   - Use the `q3c_dist` function to calculate the angular distance between each object's `meanra`, `meandec` and the Abell 370 center (RA=39.97, Dec=-1.5768).\n   - Return this value as `dist`.\n\n8. **Select Required Columns:**\n   - Select the following columns in the output:\n     - `oid` from `object`\n     - `value` from `probability` (probability value of the highest ranked class in the stamp classifier)\n     - `name` and `version` from `step`\n     - `meanra` and `meandec` from `object`\n     - The source identifier (assumed to be `oid` again, or clarify if different)\n     - The calculated distance as `dist`\n\n9. **Construct the Query with Appropriate Joins and Filters:**\n   - Start from the `object` table.\n   - Join `probability` on `oid` with conditions `classifier_name='stamp_classifier'` and `ranking=1`.\n   - Join `step` on `object.step_id_corr = step.step_id`.\n   - Apply all filters: `firstmjd` date range, spatial radius, `sgscore1 < 0.3`, and exclude classes 'asteroid' and 'bogus' in the highest probability stamp classifier.\n   - Calculate distance using `q3c_dist`.\n\n10. **Ordering and Final Output:**\n    - The user does not specify ordering; default ordering can be by distance ascending or by `oid`.\n    - Ensure the query returns only distinct objects if duplicates are possible.\n\n11. **Additional Considerations:**\n    - Confirm the exact table and column for `sgscore1`. If it is in another table, include the necessary join.\n    - Confirm the meaning of \"source identifier\" if different from `oid`.\n    - Use exact column and table names as per the schema.\n    - Use the default conditions for the `probability` table as specified (ranking=1 and classifier_name='stamp_classifier' in this case).\n    - Use the Q3C extension functions correctly with the right parameter order.\n\nBy following these steps, the resulting query will accurately retrieve the requested object identifiers and associated information filtered by date, spatial location, classification, and other criteria.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify the Relevant Tables and Columns:**\n   - From the user request, the following tables and columns are needed:\n     - `object` table: to get the object identifier (`oid`) and number of detections (`ndet`).\n     - `probability` table: to filter objects classified as 'SNII' with probability > 0.6.\n     - `feature` table: to get the feature name (`name`), feature value (`value`), and feature band identifier (`fid`), which should be renamed as `feature_fid`.\n     - `detection` table: to get candidate identifier (`candid`), PSF magnitudes (`magpsf`), magnitude errors (`sigmapsf`), and band identifiers (`fid`).\n     - `magstat` table: to filter objects with difference between minimum and maximum magnitudes in ZTF g-band (fid=1) greater than 2 mag.\n\n2. **Apply the Default Conditions for the `probability` Table:**\n   - Use `probability.ranking = 1` to select the most likely class.\n   - Use `probability.classifier_name = 'lc_classifier'` to select classifications from the light curve classifier.\n   - Filter for `class_name = 'SNII'` and `probability > 0.6`.\n\n3. **Filter Objects Based on Number of Detections:**\n   - Use the `object.ndet` column to filter objects with more than 50 detections (`ndet > 50`).\n\n4. **Filter Objects Based on Magnitude Difference in g-band:**\n   - Use the `magstat` table to find objects with `fid = 1` (ZTF g-band).\n   - Calculate the difference between minimum and maximum magnitudes (`magmax - magmin`) and filter for values greater than 2 mag.\n\n5. **Join Tables Appropriately:**\n   - Join `object` and `probability` on `oid` to filter objects classified as 'SNII' with the required probability.\n   - Join `object` and `magstat` on `oid` to apply the magnitude difference filter for g-band.\n   - Join `object` and `feature` on `oid` to retrieve feature information.\n   - Join `object` and `detection` on `oid` to retrieve detection information including candidate id, PSF magnitudes, magnitude errors, and band identifiers.\n\n6. **Select Required Columns:**\n   - From `object`: `oid` (object identifier).\n   - From `detection`: `candid` (candidate identifier), `magpsf` (PSF magnitude), `sigmapsf` (magnitude error), `fid` (band identifier).\n   - From `feature`: `name` (feature name), `value` (feature value), and `fid` renamed as `feature_fid`.\n   - From `detection`: `mjd` (time of detection) to order results as a function of time.\n\n7. **Apply Ordering:**\n   - Order the results by `oid` as requested.\n   - Optionally, within each `oid`, order by `mjd` (time) to reflect the time evolution.\n\n8. **Additional Considerations:**\n   - Ensure that the joins do not multiply rows unnecessarily; consider if distinct or grouping is needed depending on the data.\n   - Since the user wants the data \"as a function of time,\" ensure that the `mjd` column from `detection` is included or used for ordering.\n   - Rename the `feature.fid` column as `feature_fid` in the SELECT clause.\n\nBy following these steps, the query will retrieve the object identifiers, candidate identifiers, feature names and values, PSF magnitudes, magnitude errors, and band identifiers (with the feature band id renamed), for objects classified as SN II with probability > 0.6, having more than 50 detections, and with a g-band magnitude difference greater than 2 mag, ordered by object identifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify the Main Tables and Columns Needed:**\n   - From the user request, the main entities are:\n     - Objects classified as SN II with probability > 0.6.\n     - Detections of those objects.\n     - Features of those objects.\n   - Relevant tables and columns:\n     - `probability`: to filter objects classified as 'SNII' with probability > 0.6, classifier_name='lc_classifier', and ranking=1.\n       - Columns: `oid`, `class_name`, `probability`, `ranking`, `classifier_name`.\n     - `object`: to filter objects with number of detections (`ndet`) > 50.\n       - Columns: `oid`, `ndet`.\n     - `magstat`: to filter objects with difference between minimum and maximum magnitudes in ZTF g-band (fid=1) greater than 2 mag.\n       - Columns: `oid`, `fid`, `magmax`, `magmin`.\n     - `feature`: to retrieve feature name, value, and feature fid (renamed as `feature_fid`).\n       - Columns: `oid`, `name`, `value`, `fid`.\n     - `detection`: to retrieve candidate identifier (`candid`), psf magnitudes (`magpsf`), magnitude errors (`sigmapsf`), and band identifiers (`fid`).\n       - Columns: `oid`, `candid`, `magpsf`, `sigmapsf`, `fid`, `mjd` (time of detection).\n\n2. **Step 1: Filter Objects Classified as SN II with Probability > 0.6**\n   - Query the `probability` table with conditions:\n     - `class_name = 'SNII'`\n     - `probability > 0.6`\n     - `ranking = 1` (to get the most likely class)\n     - `classifier_name = 'lc_classifier'`\n   - This will produce a list of `oid`s of objects classified as SN II with high confidence.\n\n3. **Step 2: Filter Objects with Number of Detections > 50**\n   - Join the filtered `oid`s from Step 1 with the `object` table.\n   - Apply the condition `ndet > 50` on the `object` table.\n   - This step narrows down the objects to those with sufficient detections.\n\n4. **Step 3: Filter Objects with Magnitude Difference in g-band > 2 mag**\n   - Join the filtered `oid`s from Step 2 with the `magstat` table.\n   - Filter `magstat` rows where `fid = 1` (g-band).\n   - Calculate the difference between `magmax` and `magmin` and filter where this difference is greater than 2.\n   - This step ensures the objects have significant variability in the g-band.\n\n5. **Step 4: Retrieve Features for the Filtered Objects**\n   - Since the user requests the feature name, value, and feature fid (renamed as `feature_fid`), query the `feature` table.\n   - Join the `feature` table with the filtered `oid`s from Step 3.\n   - Select columns: `oid`, `name`, `value`, and `fid` (renamed as `feature_fid`).\n   - No specific feature filtering is requested, so retrieve all features for these objects.\n\n6. **Step 5: Retrieve Detections for the Filtered Objects**\n   - Query the `detection` table for the filtered `oid`s from Step 3.\n   - Select columns: `oid`, `candid` (candidate identifier), `magpsf` (psf magnitude), `sigmapsf` (magnitude error), `fid` (band identifier), and `mjd` (time of detection).\n   - This will provide the time series data for the detections.\n\n7. **Step 6: Combine Features and Detections**\n   - The user wants the output as a function of time, implying that detection time (`mjd`) is important.\n   - Since features are static per object and detections are time-dependent, the query should join the `feature` and `detection` tables on `oid`.\n   - This join will produce rows with:\n     - `oid`\n     - `candid`\n     - `feature` name, value, and `feature_fid`\n     - `magpsf`, `sigmapsf`, `fid` (from detection)\n     - `mjd` (time of detection)\n   - This join will produce multiple rows per object per detection per feature.\n\n8. **Step 7: Final Selection and Ordering**\n   - Select the columns as requested:\n     - `oid` (object identifier)\n     - `candid` (candidate identifier)\n     - `feature` name\n     - `feature` value\n     - `magpsf` (psf magnitude)\n     - `sigmapsf` (magnitude error)\n     - `fid` from `feature` table renamed as `feature_fid`\n     - `mjd` (time of detection)\n   - Order the results by `oid` ascending.\n\n9. **Step 8: Optimize the Query**\n   - Use INNER JOINs to ensure only objects meeting all criteria are included.\n   - Use subqueries or CTEs (WITH clauses) to filter objects stepwise:\n     - First filter by classification and probability.\n     - Then filter by number of detections.\n     - Then filter by magnitude difference in g-band.\n   - Join the filtered object list with `feature` and `detection` tables.\n   - Apply the renaming of the `fid` column from the `feature` table as `feature_fid` in the SELECT clause.\n\n10. **Summary of the Query Logic:**\n    - Start with a subquery filtering `probability` for SNII with probability > 0.6, ranking=1, classifier_name='lc_classifier'.\n    - Join with `object` to filter `ndet > 50`.\n    - Join with `magstat` filtered on `fid=1` and `(magmax - magmin) > 2`.\n    - Use the resulting `oid`s to join with `feature` and `detection`.\n    - Select the requested columns, rename `feature.fid` as `feature_fid`.\n    - Order by `oid`.\n\nThis decomposition plan ensures the query is accurate, efficient, and meets all user requirements.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that fulfills the user request, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main object information, including the first detection time and galactic coordinates, is stored in the `object` table.\n     - Use `firstmjd` column to filter objects detected between February 1 and 2, 2023.\n     - Use `gal_l` and `gal_b` columns for galactic longitude and latitude, respectively.\n   - The classification information is in the `probability` table.\n     - Filter by `classifier_name = 'lc_classifier'` to get classifications from the light curve classifier.\n     - Use `class_name` to get the class assigned to each object.\n     - Use `ranking = 1` to get only the most likely classification.\n   - The features are stored in the `feature` table.\n     - Retrieve all feature columns for each object.\n     - The `feature` table contains multiple rows per object, one per feature, so these need to be pivoted or aggregated appropriately.\n\n2. **Define the Time Range Filter:**\n   - Use the `firstmjd` column in the `object` table.\n   - Filter for `firstmjd >= 59976.0` and `firstmjd < 59978.0` to cover February 1 and 2, 2023 (MJD dates inclusive of the start date and exclusive of the end date).\n\n3. **Join Tables Appropriately:**\n   - Join `object` and `probability` tables on `oid` to associate each object with its classification.\n   - Join `feature` table on `oid` to get the features for each object.\n   - Since `feature` has multiple rows per object (one per feature), consider how to present these features:\n     - Option 1: Return multiple rows per object, each with one feature name and value.\n     - Option 2: Aggregate features into a JSON or key-value structure per object.\n     - Option 3: Select only specific features if the user wants a fixed set.\n   - Since the user requests \"feature columns,\" the best approach is to pivot features into columns or return them as key-value pairs.\n\n4. **Apply Default Probability Conditions:**\n   - Filter `probability` table by `classifier_name = 'lc_classifier'`.\n   - Filter by `ranking = 1` to get the most likely class only.\n\n5. **Select Required Columns:**\n   - From `object`: `oid`, `gal_l`, `gal_b`.\n   - From `probability`: `class_name`.\n   - From `feature`: all feature names and their values for each object.\n\n6. **Handle Feature Data:**\n   - Since the `feature` table stores features in rows, to get feature columns, you need to pivot the data.\n   - Use a subquery or CTE to pivot features for each object into columns.\n   - Alternatively, aggregate features into a JSON object per object for easier retrieval.\n\n7. **Construct the Query Logic:**\n   - Start with filtering objects by `firstmjd` in the specified date range.\n   - Join with `probability` to get the classification, applying the default filters.\n   - Join or aggregate features for each object.\n   - Select the requested columns.\n\n8. **Ordering and Output:**\n   - Optionally order results by `firstmjd` or `oid` for clarity.\n   - Return all requested columns: galactic coordinates, features, class name, and object identifiers.\n\n9. **Summary of Steps:**\n   - Filter `object` by `firstmjd` between 59976.0 and 59978.0.\n   - Join with `probability` on `oid` where `classifier_name = 'lc_classifier'` and `ranking = 1`.\n   - Join or aggregate `feature` rows per `oid` to get feature columns.\n   - Select `oid`, `gal_l`, `gal_b`, `class_name`, and all feature columns.\n   - Return the result set.\n\nThis plan ensures the query returns the galactic coordinates, all features, classification class name, and object identifiers for objects first detected between February 1 and 2, 2023, classified by the light curve classifier with the highest ranking.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that fulfills the user request, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main table for object information is `object`.\n     - Relevant columns: `oid` (object identifier), `firstmjd` (time of first detection), `gal_l` (galactic longitude), and `gal_b` (galactic latitude).\n   - The classification information is stored in the `probability` table.\n     - Relevant columns: `oid` (object identifier), `class_name` (classification class), `classifier_name` (classifier used), `ranking` (class probability ranking).\n   - The features are stored in the `feature` table.\n     - Relevant columns: `oid` (object identifier), `name` (feature name), `value` (feature value).\n\n2. **Define the Time Range Filter:**\n   - The user wants objects first detected between February 1 and 2, 2023.\n   - Using the provided MJD dates, this corresponds to `firstmjd` between 59976.0 and 59977.0 (assuming the end date is exclusive or inclusive depending on interpretation; here, to cover February 1 and 2 fully, use 59976.0 \u2264 firstmjd < 59978.0).\n   - This filter will be applied on the `object.firstmjd` column.\n\n3. **Filter by Classifier and Ranking:**\n   - Only include classifications from the light curve classifier: `probability.classifier_name = 'lc_classifier'`.\n   - Only include the most likely class per object: `probability.ranking = 1`.\n\n4. **Join Conditions:**\n   - Join `object` and `probability` tables on `oid` to associate each object with its classification.\n   - Join `feature` table on `oid` to retrieve all features for each object.\n   - Since features are stored as multiple rows per object (one per feature), the query will need to handle this appropriately, either by returning multiple rows per object (one per feature) or by aggregating features into columns (pivot). The user request is to return \"feature columns,\" so the query should pivot or aggregate features into columns.\n   - To pivot features, select a set of relevant features or all features if feasible, and use conditional aggregation or a crosstab function to transform rows into columns.\n\n5. **Select Columns to Return:**\n   - From `object`: `oid`, `gal_l`, `gal_b`.\n   - From `probability`: `class_name`.\n   - From `feature`: multiple feature columns (each feature name as a column, with its corresponding value).\n   - If the user does not specify which features, include all features available for the selected objects.\n\n6. **Handle Feature Version and Bandpass:**\n   - The `feature` table includes `version` and `fid` columns.\n   - If the user does not specify a feature version or bandpass, select the latest or default version and all bands, or choose a specific version if known.\n   - To keep the query manageable, filter features by a specific version (e.g., the latest version) or include all versions if necessary.\n\n7. **Query Structure:**\n   - Start with filtering `object` by `firstmjd` in the specified range.\n   - Join with `probability` filtered by `classifier_name='lc_classifier'` and `ranking=1`.\n   - Join with `feature` filtered by the chosen version(s).\n   - Use aggregation or pivot to convert feature rows into columns.\n   - Select the required columns: `oid`, `gal_l`, `gal_b`, `class_name`, and feature columns.\n\n8. **Ordering and Output:**\n   - Optionally order results by `firstmjd` or `oid`.\n   - Return all matching objects with their galactic coordinates, classification, and features.\n\n9. **Performance Considerations:**\n   - Use indexes on `object.firstmjd`, `probability.oid`, and `feature.oid` for efficient joins and filtering.\n   - Limit the number of features if the dataset is large to avoid performance issues.\n   - Use appropriate filtering on `feature.version` to reduce data volume.\n\nBy following these steps, the resulting query will accurately retrieve the galactic coordinates, features, class names, and object identifiers for objects classified by the light curve classifier with first detections between February 1 and 2, 2023.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify Relevant Tables and Columns:**\n   - The main object information is in the `object` table.\n   - Classification probabilities are in the `probability` table.\n   - Light curve data (detections) are in the `detection` table.\n   - Initial rise rate and observation duration per band are in the `magstat` table.\n   \n   Columns needed:\n   - From `object`: `oid` (object identifier).\n   - From `detection`: `candid` (candidate identifier), `magpsf` (magnitude), `sigmapsf` (magnitude error), `fid` (band identifier, to be renamed as `f_id`), `mjd` (time).\n   - From `probability`: `class_name`, `probability`, `ranking`, `classifier_name`.\n   - From `magstat`: `fid`, `dmdt_first` (initial rise rate), `ndet` (number of detections), `firstmjd`, `lastmjd` (to calculate observation duration).\n\n2. **Apply Classification and Probability Filters:**\n   - Filter `probability` table for:\n     - `class_name = 'SNII'` (Supernova Type II).\n     - `classifier_name = 'lc_classifier'` (default classifier).\n     - `ranking = 1` (most likely class).\n     - `probability > 0.6`.\n   - This will give the set of object IDs (`oid`) classified as SNII with high confidence.\n\n3. **Filter Objects by Observation Time Range:**\n   - Use the `object` table to ensure the objects have detections within the time range corresponding to years 2019-2022.\n   - The Modified Julian Date (MJD) range is from 58484.0 (start of 2019) to 59944.0 (end of 2022).\n   - Filter objects where `firstmjd` and `lastmjd` overlap with this range, or more conservatively, where `firstmjd <= 59944.0` and `lastmjd >= 58484.0`.\n   - Join with the filtered `probability` results on `oid`.\n\n4. **Filter by Initial Rise Rate and Number of Detections in g and r Bands:**\n   - Use the `magstat` table to filter objects with:\n     - `fid` in (1, 2) corresponding to g and r bands.\n     - `dmdt_first > 0.5` mag/day (initial rise rate).\n     - `ndet > 30` (number of detections).\n     - Observation duration in r-band (`fid=2`) of at least 100 days, calculated as `lastmjd - firstmjd >= 100`.\n   - Since the initial rise rate and number of detections are band-specific, ensure these conditions are met for both g and r bands.\n   - This requires joining or intersecting the `magstat` entries for the same `oid` for both bands.\n   - To do this:\n     - Create two subqueries from `magstat` filtered by `fid=1` and `fid=2` respectively, applying the conditions on `dmdt_first` and `ndet`.\n     - For the r-band (`fid=2`), also apply the observation duration condition.\n     - Intersect the sets of `oid` from both subqueries to ensure the object meets criteria in both bands.\n\n5. **Combine Filters on Objects:**\n   - Join the filtered `probability` results (step 2) with the filtered `object` results (step 3).\n   - Join the result with the filtered `magstat` results (step 4) to ensure all conditions are met.\n   - This will yield the final list of `oid` that satisfy classification, probability, time range, initial rise rate, number of detections, and observation duration criteria.\n\n6. **Retrieve Detection Data for Selected Objects:**\n   - From the `detection` table, select:\n     - `oid` (object identifier).\n     - `candid` (candidate identifier).\n     - `magpsf` (magnitude).\n     - `sigmapsf` (magnitude error).\n     - `fid` (band identifier), rename as `f_id`.\n     - `mjd` (time of detection).\n   - Filter detections to include only those with `oid` in the final filtered set from step 5.\n   - Optionally, filter detections to the time range 2019-2022 (`mjd` between 58484.0 and 59944.0) to match the user\u2019s request.\n\n7. **Final Output:**\n   - Select the columns as specified: object identifier (`oid`), candidate identifier (`candid`), magnitudes (`magpsf`), magnitude errors (`sigmapsf`), band identifiers renamed as `f_id`, and time (`mjd`).\n   - Order the results by `oid` and `mjd` to present the light curve data in chronological order per object.\n\n8. **Summary of Query Structure:**\n   - Subquery 1: Filter `probability` for SNII with probability > 0.6 and ranking=1.\n   - Subquery 2: Filter `object` for time range overlap.\n   - Subquery 3a: Filter `magstat` for g-band with `dmdt_first > 0.5` and `ndet > 30`.\n   - Subquery 3b: Filter `magstat` for r-band with `dmdt_first > 0.5`, `ndet > 30`, and observation duration >= 100 days.\n   - Intersect subqueries 3a and 3b on `oid`.\n   - Join subqueries 1, 2, and the intersection of 3a and 3b on `oid`.\n   - Use the resulting `oid` list to filter `detection` table.\n   - Select and rename columns as requested.\n\nThis decomposition ensures the query is efficient, uses appropriate joins and intersections, applies all filters correctly, and returns the requested data with the correct column names and conditions.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the requested information from the ALeRCE database, follow this detailed decomposition plan:\n\n1. **Identify the Relevant Tables and Columns:**\n   - The main tables involved will be:\n     - `probability`: to filter objects classified as 'SNII' with probability > 0.6 and ranking = 1, classifier_name = 'lc_classifier'.\n     - `object`: to get the object identifier and to filter objects with number of detections (`ndet`) > 30.\n     - `magstat`: to filter objects with at least 100 days of observations in the r-band (filter id = 2).\n     - `detection`: to retrieve candidate identifier (`candid`), magnitudes (`magpsf` or corrected magnitudes), magnitude errors (`sigmapsf` or corrected errors), band identifiers (`fid`), and time (`mjd`).\n   \n2. **Filter Objects by Classification and Probability:**\n   - From the `probability` table:\n     - Select objects (`oid`) where `class_name` = 'SNII'.\n     - Use `classifier_name` = 'lc_classifier'.\n     - Use `ranking` = 1 to get the most likely class.\n     - Filter for `probability` > 0.6.\n   - This will give a list of candidate objects classified as SN II with high confidence.\n\n3. **Filter Objects by Number of Detections:**\n   - Join the filtered `probability` results with the `object` table on `oid`.\n   - Filter objects where `ndet` (total number of detections) > 30.\n\n4. **Filter Objects by Observation Duration in r-band:**\n   - Join the above result with the `magstat` table on `oid`.\n   - Filter for `fid` = 2 (r-band).\n   - Filter for objects where the difference between `lastmjd` and `firstmjd` in `magstat` is at least 100 days.\n     - This ensures the object has at least 100 days of observations in the r-band.\n\n5. **Filter Objects by Initial Rise Rate in g and r Bands:**\n   - The initial rise rate is given by `dmdt_first` in the `magstat` table.\n   - We need to ensure that for both g-band (`fid`=1) and r-band (`fid`=2), the `dmdt_first` is greater than 0.5 mag/day.\n   - Since `magstat` is per band, we need to:\n     - Create two subqueries or use a self-join on `magstat` filtered by `oid`:\n       - One for `fid`=1 with `dmdt_first` > 0.5.\n       - One for `fid`=2 with `dmdt_first` > 0.5.\n     - Intersect or join these subqueries on `oid` to get objects satisfying the rise rate condition in both bands.\n\n6. **Filter Objects by Time Range (2019-2022):**\n   - Use the `object` table's `firstmjd` and `lastmjd` columns to ensure the object was observed within the Modified Julian Date range corresponding to 2019-2022:\n     - `firstmjd` <= 59944.0 (end of 2022)\n     - `lastmjd` >= 58484.0 (start of 2019)\n   - This ensures the object has observations overlapping the requested time period.\n\n7. **Retrieve Detection Information:**\n   - Join the filtered list of objects with the `detection` table on `oid`.\n   - Retrieve the following columns:\n     - `oid` (object identifier)\n     - `candid` (candidate identifier)\n     - `magpsf` (magnitude)\n     - `sigmapsf` (magnitude error)\n     - `fid` (band identifier) \u2014 rename this column as `f_id` in the output\n     - `mjd` (time of detection)\n   - No additional filters on detections are specified, so include all detections for the filtered objects.\n\n8. **Final Output and Ordering:**\n   - Select the columns as specified.\n   - Rename `fid` as `f_id`.\n   - Optionally, order the results by `oid` and `mjd` to have detections sorted by object and time.\n\n9. **Summary of Joins and Filters:**\n   - Start with `probability` filtered by class, classifier, ranking, and probability.\n   - Join with `object` to filter by `ndet` and time range.\n   - Join with `magstat` twice or use subqueries to filter by initial rise rate in g and r bands and observation duration in r-band.\n   - Join with `detection` to retrieve detection-level data.\n   \n10. **Additional Notes:**\n    - Ensure that all joins use the `oid` column.\n    - Use INNER JOINs to ensure only objects meeting all criteria are included.\n    - Use the default conditions for the `probability` table as specified.\n    - Use the exact class name 'SNII' as per the database.\n    - Use the exact filter IDs: 1 for g-band, 2 for r-band.\n    - Use the MJD dates for the time range filter as provided.\n    - Rename `fid` to `f_id` in the final SELECT clause.\n\nBy following these steps, the resulting query will efficiently retrieve the requested information about SN II objects observed between 2019 and 2022, with the specified probability, rise rate, observation duration, and detection count, including detailed detection data with renamed band identifiers.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves up to 50 ZTF objects meeting the specified conditions, the following detailed decomposition plan should be followed:\n\n1. **Identify Relevant Tables and Columns:**\n   - From the user request, the main tables involved are:\n     - `probability`: to filter objects classified as AGN with probability > 0.7, classifier version 'hierarchical_rf_1.1.0', classifier_name 'lc_classifier', and ranking = 1.\n     - `ps1_ztf`: to get the nearest PS1 source information, including star/galaxy score and distance to the nearest PS1 source.\n     - `detection`: to get candidate identifiers, filter identifiers, and star/galaxy score from SExtractor (likely stored in a column related to star/galaxy score; since the schema does not explicitly mention a star/galaxy score from SExtractor, it might be stored in the `rb` or another relevant column\u2014this needs clarification or assumption).\n     - `object`: to get the ZTF object identifier (oid).\n   \n2. **Define Selection Criteria:**\n   - Probability conditions:\n     - `probability.class_name = 'AGN'`\n     - `probability.classifier_name = 'lc_classifier'`\n     - `probability.classifier_version = 'hierarchical_rf_1.1.0'`\n     - `probability.ranking = 1`\n     - `probability.probability > 0.7`\n   - Distance to nearest PS1 source:\n     - `ps1_ztf.distpsnr1 < 2` (distance in arcseconds)\n   - Difference between star/galaxy score from PS1 and star/galaxy score from SExtractor less than 0.5:\n     - The PS1 star/galaxy score is `ps1_ztf.sgscore1`.\n     - The SExtractor star/galaxy score is not explicitly defined in the schema; assuming it is stored in the `detection.rb` column (ZTF real bogus score) or another column. Since the user explicitly requests star/galaxy score from SExtractor, and the schema does not provide a direct column, this needs to be clarified or assumed to be `detection.rb`.\n     - The condition is: `ABS(ps1_ztf.sgscore1 - detection.rb) < 0.5`.\n   \n3. **Determine Columns to Return:**\n   - For the ZTF object:\n     - `object.oid` (ZTF identifier)\n     - `probability.probability` (probability of being AGN)\n   - For each epoch (detection):\n     - `detection.candid` (candidate identifier)\n     - `detection.fid` (filter identifier)\n     - Reduced chi-square: This column is not explicitly present in the schema. It might be a derived or stored value under a different name or not available. If not available, this needs to be clarified or omitted.\n     - Star/galaxy score from SExtractor: assumed to be `detection.rb` or another column if specified.\n     - For the nearest PS1 source:\n       - `ps1_ztf.objectidps1` (identifier of the nearest PS1 source)\n       - `ps1_ztf.sgscore1` (PS1 star/galaxy score)\n       - `ps1_ztf.distpsnr1` (distance to nearest PS1 source)\n   \n4. **Establish Table Joins:**\n   - Join `probability` with `object` on `oid`.\n   - Join `ps1_ztf` with `object` on `oid`.\n   - Join `detection` with `object` on `oid`.\n   - This will allow retrieving all required columns and applying filters.\n   \n5. **Apply Filters in WHERE Clause:**\n   - Filter on `probability` table for class_name, classifier_name, classifier_version, ranking, and probability.\n   - Filter on `ps1_ztf.distpsnr1 < 2`.\n   - Filter on the absolute difference between `ps1_ztf.sgscore1` and `detection.rb` less than 0.5.\n   \n6. **Limit the Number of Results:**\n   - Since the user requests at most 50 objects, apply a limit of 50 on the number of distinct objects.\n   - Because multiple detections (epochs) per object can exist, the query should limit the number of objects first, then retrieve all detections for those objects.\n   - This can be done by:\n     - First selecting up to 50 `oid`s that satisfy the conditions.\n     - Then retrieving all detections for those `oid`s.\n   \n7. **Ordering and Sorting:**\n   - The user does not specify ordering, so default ordering can be by probability descending or by object identifier.\n   \n8. **Final Output Structure:**\n   - The query should return rows with columns:\n     - `oid` (ZTF object identifier)\n     - `probability` (probability of AGN classification)\n     - `candid` (candidate identifier for each detection)\n     - `fid` (filter identifier)\n     - Reduced chi-square (if available; otherwise, note its absence)\n     - Star/galaxy score from SExtractor (assumed `detection.rb`)\n     - `objectidps1` (nearest PS1 source identifier)\n     - `sgscore1` (PS1 star/galaxy score)\n     - `distpsnr1` (distance to nearest PS1 source)\n   \n9. **Additional Considerations:**\n   - Verify the presence and meaning of the reduced chi-square column; if not present, clarify or omit.\n   - Confirm the correct column for the star/galaxy score from SExtractor; if not available, clarify or omit.\n   - Ensure that the joins do not multiply rows unnecessarily; use appropriate join types (INNER JOIN) and conditions.\n   - Use indexes on `probability.oid`, `ps1_ztf.oid`, and `detection.oid` for performance.\n   - Use subqueries or CTEs to first filter the 50 objects, then join to detections and PS1 data.\n   \nBy following these steps, the resulting query will efficiently retrieve up to 50 ZTF objects classified as AGN with high confidence, close to a PS1 source, and with similar star/galaxy scores between PS1 and SExtractor, including detailed detection epoch information.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-mini-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves up to 50 ZTF objects meeting the specified conditions, the following detailed decomposition plan should be followed:\n\n1. **Identify Relevant Tables and Columns:**\n   - From the user request, the main tables involved are:\n     - `object`: for the ZTF object identifier (`oid`).\n     - `probability`: for classification probabilities, specifically for class 'AGN' with classifier version 'hierarchical_rf_1.1.0'.\n     - `ps1_ztf`: for information about the nearest Pan-STARRS1 (PS1) source, including star/galaxy score (`sgscore1`) and distance to the nearest PS1 source (`distpsnr1`).\n     - `detection`: for epoch-level data including candidate identifier (`candid`), filter identifier (`fid`), star/galaxy score from SExtractor (likely stored in a column such as `sgscore` or similar; since the schema does not explicitly mention SExtractor star/galaxy score, verify if it is stored in `detection` or if it needs to be inferred or joined from another table; if not available, clarify or assume it is in `detection` as `sgscore` or a similar column), and reduced chi-square (not explicitly listed in the schema, so check if it is stored under a different name or if it needs to be calculated or omitted if unavailable).\n   \n2. **Clarify Columns for SExtractor Star/Galaxy Score and Reduced Chi-Square:**\n   - Since the schema does not explicitly mention a column for the SExtractor star/galaxy score or reduced chi-square in the `detection` table, confirm if these are stored under different column names or if additional tables are needed.\n   - If these columns are not present, the query cannot retrieve them directly; the user should be informed or the query adjusted accordingly.\n   \n3. **Set Filtering Conditions:**\n   - From the `probability` table:\n     - Filter for `class_name = 'AGN'`.\n     - Filter for `classifier_name = 'lc_classifier'` (default condition).\n     - Filter for `classifier_version = 'hierarchical_rf_1.1.0'`.\n     - Filter for `probability > 0.7`.\n     - Filter for `ranking = 1` (default condition to get the most likely class).\n   - From the `ps1_ztf` table:\n     - Filter for `distpsnr1 < 2` (distance to nearest PS1 source less than 2 arcseconds).\n   - For the difference between the star/galaxy score from PS1 and SExtractor:\n     - Calculate the absolute difference between `sgscore1` (PS1 star/galaxy score) and the SExtractor star/galaxy score (assumed to be in `detection` or another table).\n     - Filter for this difference to be less than 0.5.\n   \n4. **Join Tables Appropriately:**\n   - Join `probability` with `object` on `oid` to get the ZTF object identifier.\n   - Join `ps1_ztf` on `oid` to get PS1 source information.\n   - Join `detection` on `oid` to get epoch-level data (candidate id, filter id, SExtractor star/galaxy score, reduced chi-square).\n   - Ensure that the joins are INNER JOINs to only include objects that have matching entries in all tables.\n   \n5. **Select Required Columns:**\n   - From `object` or `probability`:\n     - ZTF object identifier (`oid`).\n     - Probability of being AGN (`probability`).\n   - From `detection`:\n     - Candidate identifier (`candid`).\n     - Filter identifier (`fid`).\n     - Reduced chi-square (if available; otherwise, note its absence).\n     - SExtractor star/galaxy score (assumed column).\n   - From `ps1_ztf`:\n     - Identifier of the nearest PS1 source (`objectidps1`).\n     - PS1 star/galaxy score (`sgscore1`).\n     - Distance to nearest PS1 source (`distpsnr1`).\n   \n6. **Limit the Number of Results:**\n   - Limit the output to at most 50 distinct ZTF objects.\n   - Since multiple epochs per object are requested, decide whether to limit the total number of rows or the number of objects.\n   - To ensure at most 50 objects, use a subquery or CTE to first select the 50 objects meeting the conditions, then join to detections to get all epochs for those objects.\n   \n7. **Ordering and Presentation:**\n   - Optionally order the results by probability descending to prioritize the most probable AGN.\n   - Present the results with clear column aliases if needed for clarity.\n   \n8. **Summary of Steps to Implement in the Query:**\n   - Step 1: Filter `probability` for AGN class, classifier version, ranking=1, and probability > 0.7.\n   - Step 2: Join with `ps1_ztf` and filter for `distpsnr1 < 2`.\n   - Step 3: Join with `detection` and filter for absolute difference between `sgscore1` and SExtractor star/galaxy score < 0.5.\n   - Step 4: Select distinct `oid` from the above with a limit of 50.\n   - Step 5: Join back to `detection` and `ps1_ztf` to retrieve all epochs for those 50 objects.\n   - Step 6: Select the requested columns.\n   \n9. **Additional Considerations:**\n   - Verify the exact column name for the SExtractor star/galaxy score and reduced chi-square in the `detection` table or elsewhere.\n   - If reduced chi-square is not available, consider omitting it or clarifying with the user.\n   - Use appropriate indexes for performance, especially on `probability(oid)`, `ps1_ztf(oid)`, and `detection(oid)`.\n   - Use explicit filtering on `probability.classifier_name = 'lc_classifier'` as per default conditions.\n   \nBy following this decomposition plan, the resulting query will efficiently retrieve up to 50 ZTF objects classified as AGN with high confidence, close to a PS1 source, and with consistent star/galaxy scores between PS1 and SExtractor, including detailed epoch-level information.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
