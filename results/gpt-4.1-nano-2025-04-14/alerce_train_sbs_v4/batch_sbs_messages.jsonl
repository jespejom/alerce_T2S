{"custom_id": "10-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`) and other object-specific information.\n   - The `probability` table, which stores classification probabilities, including `oid`, `class_name`, `classifier_name`, `probability`, and `ranking`.\n\n2. **Determine the relevant classifier and class names:**\n   - The classifier of interest is `'lc_classifier'`.\n   - The classes of interest are `'SNIa'` and `'CV/Nova'`.\n   - The rankings of interest are `1` for `'SNIa'` and `2` for `'CV/Nova'`.\n\n3. **Filter the probability table:**\n   - Select only entries where `classifier_name='lc_classifier'`.\n   - Filter for `ranking=1` and `class_name='SNIa'`.\n   - Filter for `ranking=2` and `class_name='CV/Nova'`.\n   - Ensure that only the most probable classification per object is considered by filtering `probability.ranking=1` (for `'SNIa'`) and `probability.ranking=2` (for `'CV/Nova'`).\n\n4. **Join the probability data with object identifiers:**\n   - Use an `INNER JOIN` between the `probability` table and the `object` table on `oid` to retrieve object identifiers alongside probabilities.\n\n5. **Retrieve probabilities for the specified classes:**\n   - For each object, obtain the probability of `'SNIa'` with `ranking=1`.\n   - For each object, obtain the probability of `'CV/Nova'` with `ranking=2`.\n\n6. **Calculate the difference between the probabilities:**\n   - For each object, compute the absolute difference between the `'SNIa'` probability and the `'CV/Nova'` probability.\n   - Filter objects where this difference is less than `0.1`.\n\n7. **Select and label the output columns:**\n   - Return the object identifier (`oid`).\n   - Return the `'SNIa'` probability as `'SN_prob'`.\n   - Return the `'CV/Nova'` probability as `'CV_prob'`.\n\n8. **Ensure the query only includes objects satisfying the probability difference condition:**\n   - Use a `WHERE` clause to filter based on the absolute difference of probabilities being less than `0.1`.\n\n9. **Order or group the results if necessary:**\n   - No specific ordering is requested, so this step can be optional unless needed for clarity.\n\n10. **Test the query for correctness:**\n    - Verify that the join conditions correctly match objects with their respective class probabilities.\n    - Confirm that the probability difference filter is correctly applied.\n\nThis systematic decomposition ensures that the final query will accurately retrieve object identifiers and their class probabilities for `'SNIa'` and `'CV/Nova'`, with the specified probability difference constraint, and with appropriately labeled output columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the light curve classifier for objects classified in the light curve classifier as SNIa with ranking=1 and CV/Nova with ranking=2, where the difference between the probabilities at each ranking is lower than 0.1. Return the oids, and the probability for each class, naming the columns 'SN_prob' and 'CV_prob' respectively.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "10-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`) and other object properties.\n   - The `probability` table, which contains classification probabilities, class names, classifier names, and rankings.\n\n2. **Determine the relevant classifier and class names:**\n   - Focus on the `probability` entries where `classifier_name` is `'lc_classifier'`.\n   - Filter for class names `'SNIa'` and `'CV/Nova'` as specified.\n   - Use `ranking=1` for `'SNIa'` and `ranking=2` for `'CV/Nova'`.\n\n3. **Apply default conditions for probabilities:**\n   - Ensure that only the most probable classification per object is considered by filtering `probability.ranking=1`.\n   - Confirm that the `classifier_name` is `'lc_classifier'`.\n   \n4. **Retrieve the probabilities for the specified classes:**\n   - For each object, extract the probability associated with `'SNIa'` at `ranking=1`.\n   - For each object, extract the probability associated with `'CV/Nova'` at `ranking=2`.\n\n5. **Join the probability data with the object data:**\n   - Use an `INNER JOIN` between the `object` table and the filtered `probability` table on the `oid` field.\n   - This allows retrieval of object identifiers (`oid`) along with their classification probabilities.\n\n6. **Calculate the difference between the probabilities:**\n   - For each object, compute the absolute difference between the `'SNIa'` probability and the `'CV/Nova'` probability.\n   - Filter objects where this difference is less than 0.1.\n\n7. **Select and alias the output columns:**\n   - Return the object identifiers (`oid`).\n   - Return the `'SNIa'` probability as `'SN_prob'`.\n   - Return the `'CV/Nova'` probability as `'CV_prob'`.\n\n8. **Ensure the query filters only objects meeting the probability difference condition:**\n   - Use a `WHERE` clause to filter objects where the absolute difference between `'SN_prob'` and `'CV_prob'` is less than 0.1.\n\n9. **Order or group the results if necessary:**\n   - No specific ordering is requested, so this step can be optional.\n   - If desired, order by object identifier or probability difference for clarity.\n\n10. **Test the query for correctness:**\n    - Verify that the join conditions correctly match probabilities to objects.\n    - Confirm that the filtering conditions accurately reflect the user request.\n\nThis systematic decomposition ensures that the final query will accurately retrieve object identifiers and their respective probabilities for `'SNIa'` and `'CV/Nova'`, filtered by the specified ranking and probability difference constraints.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the light curve classifier for objects classified in the light curve classifier as SNIa with ranking=1 and CV/Nova with ranking=2, where the difference between the probabilities at each ranking is lower than 0.1. Return the oids, and the probability for each class, naming the columns 'SN_prob' and 'CV_prob' respectively.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table for object identifiers and basic statistics.\n   - The `probability` table to retrieve the highest probability in the stamp classifier for class 'SN'.\n   - The `detection` table to obtain the detections (light curves) for each object.\n   - The `magstat` table for additional information about the light curve, specifically the filter ID and initial rise estimate.\n   - The `stamp_classifier` or `probability` table to confirm the classification as 'SN' with the highest probability.\n\n2. **Filter objects with the highest probability in the stamp classifier for class 'SN':**\n   - Use the `probability` table to select entries where:\n     - `classifier_name` is 'stamp_classifier'.\n     - `class_name` is 'SN'.\n     - `ranking` is 1 (most likely class).\n   - Join this filtered set with the `object` table on `oid` to get object identifiers.\n   - Ensure that for each object, the maximum probability for class 'SN' is obtained, possibly by grouping or filtering for the maximum probability per object.\n\n3. **Identify objects whose first detection occurred within the first 2 days of September:**\n   - Use the `object` table's `firstmjd` column.\n   - Filter objects where `firstmjd` is between 60188.0 and 60189.0 (inclusive), corresponding to September 1 and 2.\n\n4. **Determine which objects qualify as fast risers:**\n   - For each object, find the last non-detection before the first detection:\n     - Use the `detection` table to identify non-positive detections (`isdiffpos` indicating negative difference magnitude or similar).\n     - Find the maximum `mjd` of such non-detections that occurred before the `firstmjd` of the object.\n   - Calculate the initial rise rate:\n     - Use the difference in magnitude (`magpsf` or `magpsf_corr`) between the first detection and the last non-detection.\n     - Divide this magnitude difference by the time difference in days (`firstmjd` - `last non-detection mjd`).\n   - Confirm the object qualifies as a fast riser if this rate is at least 0.25 magnitudes/day.\n\n5. **Retrieve detections (light curves) for each qualifying object:**\n   - Filter the `detection` table for detections associated with each object (`oid`).\n   - Select only detections that are actual positive detections (`isdiffpos` indicating positive difference magnitude).\n   - For each detection, retrieve:\n     - `candid` (candidate ID).\n     - `fid` (filter ID).\n     - `mjd` (detection time).\n     - `magpsf` or `magpsf_corr` (magnitude).\n   - Order detections by `mjd` to get the light curve sequence.\n\n6. **Retrieve the filter ID for each detection and the `magstat` filter ID:**\n   - Join the `magstat` table with the `object` table on `oid`.\n   - Filter `magstat` entries where `fid` matches the filter used in the detection.\n   - Retrieve the `fid` as `magstat_fid`.\n\n7. **Combine all filters and conditions:**\n   - Use subqueries or CTEs (Common Table Expressions) to organize:\n     - The set of objects with maximum stamp classifier probability for 'SN'.\n     - The subset of objects that first detected within the specified date range.\n     - The subset of objects that qualify as fast risers based on the initial rise rate calculation.\n   - Intersect these sets to get objects satisfying all criteria.\n\n8. **Select the final output:**\n   - For each qualifying object, select:\n     - `oid`.\n     - The maximum probability in the stamp classifier for class 'SN'.\n     - The detections (candid, fid, mjd, magpsf) ordered by `mjd`.\n     - The `fid` from `magstat` as `magstat_fid`.\n     - The initial rise estimate (computed as the magnitude difference divided by the time difference).\n   - Order the final results by `oid`.\n\n9. **Ensure the query is optimized:**\n   - Use indexes on `oid`, `firstmjd`, `mjd`, `probability.ranking`, and `probability.class_name`.\n   - Limit the scope of subqueries to only relevant objects to improve performance.\n   - Use `JOIN`s efficiently to avoid unnecessary data duplication.\n\n10. **Document the query logic:**\n    - Clearly comment on each step, especially the calculation of the initial rise rate and the filtering criteria.\n    - Indicate the use of nested subqueries or CTEs for clarity and maintainability.\n\nThis decomposition ensures that the final SQL query will accurately retrieve the object identifiers, their highest stamp classifier probability for 'SN', their light curves (detections), the filter ID from `magstat`, and the initial rise estimate, all ordered by object ID.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "15-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table for object identifiers and basic statistics.\n   - The `probability` table to retrieve the highest probability in the stamp classifier for class 'SN'.\n   - The `detection` table to obtain the detections (only detections, not non-detections) for each object.\n   - The `magstat` table for the filter ID associated with the object, specifically to label as 'magstat_fid'.\n   - The `stamp_classifier` or `probability` table to confirm the classification as 'SN' with the highest probability.\n\n2. **Filter objects with the highest probability in the stamp classifier for class 'SN':**\n   - Use the `probability` table filtered by `classifier_name='stamp_classifier'` and `class_name='SN'`.\n   - Filter for `ranking=1` to get the most probable class per object.\n   - Ensure the `probability` value is the maximum for that object and class, possibly by using a sub-query or window function to identify the maximum probability per object.\n\n3. **Identify objects whose maximum probability in the stamp classifier is for class 'SN':**\n   - For each object, select the record with the highest probability where `class_name='SN'` and `ranking=1`.\n   - Confirm that this maximum probability is greater than any other class probability for that object, ensuring 'SN' is the top class.\n\n4. **Filter objects with their first detection within the first 2 days of September:**\n   - Use the `object` table's `firstmjd` column.\n   - Filter for `firstmjd` between 60188.0 and 60189.0 (inclusive), corresponding to September 1 and 2.\n\n5. **Determine which objects qualify as fast risers:**\n   - For each object, identify the last non-detection before the first detection in the same filter.\n   - Use the `detection` table to find the last non-detection (`isdiffpos=0`) with `mjd` less than the `firstmjd` of the object, in the same filter.\n   - Calculate the initial rise rate as: `(magpsf_corr - maglast_non_detection) / (firstmjd - mjd_last_non_detection)`.\n   - Filter for objects where this rate is at least 0.25 magnitudes/day, indicating a fast rise.\n\n6. **Retrieve the object identifiers (`oid`), the maximum probability in the stamp classifier, and the light curve detections:**\n   - For each qualifying object, select the `oid`.\n   - Retrieve the maximum probability value for class 'SN' from the `probability` table.\n   - From the `detection` table, select only the detections (`candid`, `fid`, `mjd`, `magpsf_corr`) for each object, filtering to include only detection events (`isdiffpos=1`).\n\n7. **Include the filter ID of the object from `magstat` as 'magstat_fid':**\n   - Join with the `magstat` table on `oid`.\n   - Filter or select the `fid` value from `magstat` for each object, possibly the one corresponding to the initial rise or the first detection.\n\n8. **Calculate or retrieve the initial rise estimate:**\n   - For each object, compute the initial rise as `(magpsf_corr - maglast_non_detection) / (firstmjd - mjd_last_non_detection)`.\n   - This may involve sub-queries to find the last non-detection before the first detection, and their respective `mjd` and `magpsf_corr`.\n\n9. **Order the final results by `oid`:**\n   - Ensure the output is sorted alphabetically or numerically by the object identifier.\n\n10. **Combine all steps into a cohesive query:**\n    - Use sub-queries or Common Table Expressions (CTEs) to organize filtering, maximum probability selection, and initial rise calculation.\n    - Use JOINs to connect `object`, `probability`, `detection`, and `magstat` tables.\n    - Apply all filters and conditions systematically to ensure only objects meeting all criteria are included.\n\n11. **Ensure the query returns the following columns:**\n    - `oid`\n    - `max_probability` (for class 'SN')\n    - Light curve detections: `candid`, `fid`, `mjd`, `magpsf_corr`\n    - `magstat_fid` (from `magstat`)\n    - `initial_rise` (computed value)\n\n12. **Test and validate the query:**\n    - Verify that the filters for date, classification, and rise rate are correctly applied.\n    - Confirm that only the top probability class 'SN' objects are included.\n    - Check that the ordering by `oid` is correct.\n\nThis detailed decomposition ensures that the final SQL query will accurately retrieve the requested information, efficiently filter the data, and correctly compute the initial rise for each qualifying object.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for September 01 = 60188.0\n-- mjd date for September 02 = 60189.0\nDomain Knowledge: \n-- A fast riser is defined as an object whose first detection is brighter by at least a rate of 0.25 magnitudes/day than the last non-detection obtained before the first detection (both first detection and last non-detection are in the same filter)\n\n # User Request: ''Get the object identifiers, probabilities in the stamp classifier and light curves (only detections) for objects whose highest probability in the stamp classifier is obtained for class SN, that had their first detection in the first 2 days of september, and that qualify as fast risers. Also, return the filter ID and candid of the detections, and filter ID of magstat as 'magstat_fid', with the initial rise estimate. Order the results by the oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`), mean right ascension (`meanra`), mean declination (`meandec`), and other static object properties.\n   - The `probability` table, which provides classification probabilities for each object, including class names, classifier name, and probability values.\n   - The `detection` table, which records individual detections with timestamps (`mjd`), magnitudes (`magpsf`), magnitude errors (`sigmapsf`), band identifiers (`fid`), and candidate identifiers (`candid`).\n   - The `magstat` table, which contains statistics per object per band, including the initial rise estimate (`dmdt_first`), and possibly other relevant metrics.\n\n2. **Filter objects classified as 'SN II' with high confidence:**\n   - Use the `probability` table to select objects where:\n     - `class_name` = 'SNII' (or the exact class name used in the database for Type II supernovae).\n     - `classifier_name` = 'lc_classifier' (or the appropriate classifier name).\n     - `probability` > 0.6.\n     - `ranking` = 1 (to ensure only the most probable classification).\n   - Ensure the classification is for objects in the date range 2019-2022:\n     - Use the `object` table's `firstmjd` and `lastmjd` columns to filter objects with observations within this period.\n     - Convert the date range into Julian Date (MJD) bounds, e.g., 2019-01-01 to 2022-12-31, and filter objects with `firstmjd` and `lastmjd` overlapping this range.\n\n3. **Ensure objects have more than 50 detections:**\n   - Filter objects where `ndet` (total number of detections) > 50, using the `object` table.\n\n4. **Calculate or retrieve the initial rise estimate:**\n   - Use the `magstat` table, filtering by `fid` (band) for g and r bands (e.g., `fid` = 1 for g, `fid` = 2 for r).\n   - Retrieve the `dmdt_first` value for each object in each band, which represents the initial rise rate in magnitudes per day.\n   - Filter for objects where `dmdt_first` > 0.5 mag/day in both g and r bands.\n\n5. **Retrieve the magnitudes, magnitude errors, and observation times:**\n   - Use the `detection` table to get the time series data:\n     - For each object, select detections with `mjd` within the date range.\n     - Filter detections to include only those in the g and r bands (`fid` = 1 or 2).\n     - Retrieve `magpsf` (magnitudes), `sigmapsf` (errors), `mjd` (observation time), and `fid` (band identifier).\n\n6. **Construct the temporal function:**\n   - For each object, organize the detection data as a function of time (`mjd`), including the magnitude, error, and band.\n   - This may involve ordering detections by `mjd` and possibly aggregating or selecting relevant points if needed.\n\n7. **Combine all filters and conditions:**\n   - Use subqueries or Common Table Expressions (CTEs) to:\n     - Select objects meeting classification, date, and detection count criteria.\n     - Join with `magstat` to filter objects with the required initial rise rate.\n     - Join with `detection` to retrieve the time series data for each object in g and r bands.\n\n8. **Ensure the final output includes:**\n   - Object identifier (`oid`).\n   - Candidate identifier (`candid`) from the `detection` table.\n   - Magnitudes (`magpsf`).\n   - Magnitude errors (`sigmapsf`).\n   - Initial rise estimate (`dmdt_first`).\n   - Band identifiers (`fid`).\n   - Observation times (`mjd`).\n\n9. **Order and structure the final query:**\n   - Present the data as a function of time, possibly ordered by `mjd`.\n   - Ensure the query filters are applied correctly at each step to optimize performance.\n\n10. **Additional considerations:**\n    - Use spatial filtering if needed, but since the user request does not specify a sky region, this step can be omitted unless specified.\n    - Confirm the class names and classifier names match the exact strings used in the database.\n    - Use appropriate date conversions for the date range (e.g., MJD for 2019-01-01 and 2022-12-31).\n\nThis systematic decomposition ensures that the final SQL query will accurately retrieve the object IDs, detection details, and initial rise estimates for Type II supernovae in the specified period, with the specified probability and detection criteria.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "4-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table for object identifiers and general statistics.\n   - The `detection` table for time-series data, magnitudes, and magnitude errors.\n   - The `probability` table for classification probabilities.\n   - The `magstat` table for initial rise estimates and band-specific statistics.\n\n2. **Filter objects classified as 'SN II' with high probability:**\n   - Use the `probability` table to select entries where `class_name='SNII'`, `classifier_name='lc_classifier'`, and `ranking=1`.\n   - Apply a filter for `probability > 0.6`.\n   - Join this filtered probability subset with the `object` table on `oid` to retrieve object identifiers.\n\n3. **Restrict objects to the specified time frame (2019-2022):**\n   - Use the `firstmjd` and `lastmjd` columns in the `object` table.\n   - Convert the date range (2019-2022) into Julian Date (MJD) equivalents.\n   - Filter objects where `firstmjd` and `lastmjd` overlap with the date range, ensuring the object was active during this period.\n\n4. **Apply the detection-based filters:**\n   - Join the selected objects with the `detection` table on `oid`.\n   - Filter detections to those within the date range (2019-2022).\n   - Count the number of detections per object; keep only objects with `ndet > 50`.\n\n5. **Filter objects based on initial rise rate:**\n   - Use the `magstat` table to find the `dmdt_first` (initial rise estimate) for each object.\n   - Filter for objects where `dmdt_first > 0.5` mag/day.\n   - Ensure the `magstat` entries are for the relevant bands (`fid=1` for g-band and `fid=2` for r-band).\n\n6. **Retrieve the required information:**\n   - For each object, extract:\n     - Object identifier (`oid`).\n     - Candidate identifier (`candid`) from the `detection` table.\n     - Magnitudes (`magpsf`) and magnitude errors (`sigmapsf`) from the `detection` table.\n     - Initial rise estimate (`dmdt_first`) from the `magstat` table.\n     - Band identifiers (`fid`) from the `detection` table.\n\n7. **Construct the temporal component:**\n   - For each detection, include the detection time (`mjd`).\n   - Ensure the detections are ordered chronologically per object to analyze the magnitude evolution over time.\n\n8. **Combine all filters and conditions:**\n   - Use nested subqueries or Common Table Expressions (CTEs) to organize the filtering steps.\n   - Use `JOIN`s to connect `probability`, `object`, `detection`, and `magstat` tables.\n   - Apply `WHERE` clauses for date ranges, probability thresholds, rise rate, and detection counts.\n   - Use `GROUP BY` to aggregate detections per object and candidate, and to count detections.\n\n9. **Finalize the query:**\n   - Select the specified columns: object ID, candidate ID, magnitude, magnitude error, initial rise estimate, and band ID.\n   - Order the results by object ID and detection time for clarity.\n   - Ensure all filters are correctly applied to meet the user\u2019s criteria.\n\n10. **Validate and optimize:**\n    - Confirm that indexes on `oid`, `mjd`, `class_name`, `probability`, and `ndet` are utilized.\n    - Check that the date conversions and filters are accurate for the specified period.\n    - Test the query with sample data to ensure correctness and performance.\n\nThis systematic decomposition ensures that the final SQL query will accurately retrieve the objects classified as SN II in the specified period, with the desired probability, rise rate, detection count, and associated observational data, all structured for clarity and efficiency.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, initial rise estimate, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band and number of detections greater than 50.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics and positional information (`meanra`, `meandec`) for each astronomical object.\n   - The `probability` table, which holds the classification probabilities, including SN probabilities and rankings.\n   - The `stamp_classifier` probabilities, filtered by `classifier_name='stamp_classifier'` and `ranking=1`.\n\n2. **Define the spatial filtering criteria:**\n   - For each of the three specified sources, use the Q3C function `q3c_join` or `q3c_dist` to select objects within 10 degrees of the given RA and Dec.\n   - Create a combined condition that includes all three sources, using OR logic to include objects near any of the specified positions.\n\n3. **Define the temporal filtering criteria:**\n   - Filter objects based on their first detection date (`firstmjd`) to be within the first 7 days of February.\n   - Convert the date range into Julian days:\n     - Start date: February 1, 59976.0\n     - End date: February 7, 59982.0\n   - Use a `WHERE` clause to select objects with `firstmjd` between 59976.0 and 59982.0.\n\n4. **Filter based on SN probability:**\n   - Join the `probability` table with the `object` table on `oid`.\n   - Filter for `class_name='SNIa'` (or other SN classes if needed), with `probability.probability > 0.4`.\n   - Ensure `probability.ranking=1` and `probability.classifier_name='lc_classifier'` (or `stamp_classifier` if relevant, but based on context, likely the `lc_classifier`).\n\n5. **Combine spatial, temporal, and probability filters:**\n   - Use `JOIN` operations to connect `object` and `probability`.\n   - Apply the spatial filter with Q3C functions for each source position.\n   - Apply the date filter on `firstmjd`.\n   - Apply the probability filter on `probability`.\n\n6. **Select the relevant columns:**\n   - Retrieve all columns from `object` for comprehensive information.\n   - Optionally, include probability and classification details for context.\n\n7. **Order and limit the results:**\n   - Decide on an ordering criterion, such as by `firstmjd` or probability.\n   - Limit the number of results if necessary, or leave open-ended.\n\n8. **Ensure the query adheres to default conditions:**\n   - Use `probability.ranking=1`.\n   - Use `probability.classifier_name='lc_classifier'`.\n   - Filter for `probability.probability > 0.4`.\n\n9. **Document the query structure:**\n   - Use comments to clarify each filter and join.\n   - Clearly specify the spatial, temporal, and probability conditions.\n\nThis systematic approach ensures the query will accurately retrieve objects within 10 degrees of the specified positions, detected in the first week of February, with SN probabilities above 0.4, and with the highest ranking in the light curve classifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "25-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics and positional information (`meanra`, `meandec`) for each astronomical object.\n   - The `probability` table, which holds the classification probabilities, including SN probabilities and rankings.\n   - The `stamp_classifier` probabilities, filtered by `classifier_name='stamp_classifier'` and `ranking=1`.\n\n2. **Define the spatial filtering criteria:**\n   - For each of the three specified sources, use the Q3C function `q3c_join` or `q3c_dist` to select objects within 10 degrees of the given RA and Dec.\n   - Create a combined condition that includes all three sources, using OR logic, to retrieve objects near any of these positions.\n\n3. **Define the temporal filtering criteria:**\n   - Filter objects based on their `firstmjd` (first detection date) to be within the first 7 days of February, i.e., between MJD 59976.0 and 59982.0.\n   - Use a `WHERE` clause to select objects with `firstmjd >= 59976.0` and `firstmjd <= 59982.0`.\n\n4. **Filter based on SN probability:**\n   - Join the `object` table with the `probability` table on `oid`.\n   - Filter for entries where `probability.class_name='SNIa'` (or other SN classes if needed), `probability.classifier_name='lc_classifier'`, and `probability.ranking=1`.\n   - Ensure the `probability.probability > 0.4` as specified.\n\n5. **Combine spatial, temporal, and classification filters:**\n   - Use `AND` to combine the spatial proximity condition, the date range condition, and the probability threshold condition.\n   - Use `OR` to combine the spatial proximity conditions for the three sources.\n\n6. **Select the relevant columns:**\n   - Retrieve all columns from the `object` table (`SELECT *`) to include positional, temporal, and statistical information.\n   - Optionally, include the probability value from the `probability` table for context.\n\n7. **Order and limit the results:**\n   - Decide whether to order by proximity, probability, or detection date.\n   - Limit the number of results if necessary, or leave it open for all matching objects.\n\n8. **Ensure the query is optimized:**\n   - Use the existing indexes on `object` (`ix_object_meanra`, `ix_object_meandec`, etc.) for efficient spatial and date filtering.\n   - Use the index on `probability` for quick filtering by class, ranking, and probability.\n\n9. **Document the query logic:**\n   - Clearly specify that the query retrieves objects within 10 degrees of three specified positions.\n   - It filters objects with their first detection within the first 7 days of February.\n   - It includes only objects with SN probabilities > 0.4, ranked 1 in the stamp classifier.\n\nThis systematic decomposition ensures that the final SQL query will accurately and efficiently retrieve the desired objects based on spatial proximity, temporal detection window, and classification probability criteria.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Query objects within 10 degress of the next postitions: ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221), and with their first detection the first 7 days of February, with SN probabilities > 0.4, and ranking=1 in the stamp classifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "7-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`), detection dates (`firstmjd`), and other object properties.\n   - The `probability` table, which contains classification probabilities, linked to objects via `oid`.\n   - The `stamp_classifier` table, which contains classification labels, including the class 'SN' (supernovae).\n\n2. **Determine the filtering criteria based on the user request:**\n   - The most likely class according to the stamp classifier is 'SN'.\n   - The classification must be the top-ranked (most probable) for the object, which is indicated by `probability.ranking = 1`.\n   - The classification must be from the `stamp_classifier` classifier.\n   - The object must have had its first detection in January 2023, which corresponds to `firstmjd` values between 59945.0 and 59975.0.\n\n3. **Filter objects based on detection date:**\n   - Use the `firstmjd` column in the `object` table.\n   - Apply a `WHERE` clause to select objects with `firstmjd` >= 59945.0 and `firstmjd` <= 59975.0.\n\n4. **Filter objects based on the most likely class being 'SN':**\n   - Join the `object` table with the `probability` table on `oid`.\n   - Filter for `probability.ranking = 1` to ensure the top probability.\n   - Filter for `probability.class_name` corresponding to the 'SN' class. Since the class names are specific, identify the exact class name used in the `probability` table for supernovae classified as 'SN' or similar. If the class name is 'SN' or 'SNe', use that; otherwise, clarify the exact class name.\n\n5. **Filter for the classifier being 'stamp_classifier':**\n   - Add a condition on `probability.classifier_name` to be 'stamp_classifier'.\n\n6. **Identify the most likely class as 'SN' according to the stamp classifier:**\n   - Ensure that the class with `ranking=1` for each object is 'SN' (or the exact class name used for supernovae in the database).\n\n7. **Select the required output columns:**\n   - Retrieve the object identifiers (`oid`) from the `object` table.\n   - Retrieve the associated probability value from the `probability` table.\n\n8. **Construct the query structure:**\n   - Use a `JOIN` between `object` and `probability` on `oid`.\n   - Apply the filtering conditions in the `WHERE` clause.\n   - Select the `oid` and `probability` columns.\n\n9. **Ensure the query adheres to the default conditions:**\n   - Use `probability.ranking = 1`.\n   - Use `probability.classifier_name='stamp_classifier'`.\n   - Confirm the class name for supernovae is correctly specified (e.g., 'SN').\n\n10. **Optional: Add ordering or limit if needed:**\n    - Order results by probability descending if desired.\n    - Limit the number of results if necessary.\n\nBy following these steps, you will systematically generate a precise and efficient PostgreSQL query that retrieves object identifiers and their probabilities for objects classified as 'SN' by the stamp classifier, with their first detection in January 2023.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of January = 59945.0\n-- mjd date for the end of January = 59975.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the stamp classifier for objects whose most likely class according to the stamp classifier is SN, and that had their first detection in January of 2023''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "7-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves object identifiers and their probabilities from the stamp classifier for objects whose most likely class is 'SN' and that had their first detection in January 2023, follow these detailed steps:\n\n1. **Identify the relevant tables:**\n   - Use the `object` table to access object metadata, including detection dates and object identifiers.\n   - Use the `probability` table to access classification probabilities, filtering for the stamp classifier and the most likely class.\n\n2. **Filter objects based on detection date:**\n   - Since the first detection date is stored in the `firstmjd` column of the `object` table, filter for objects where `firstmjd` falls within the range corresponding to January 2023.\n   - Convert the given MJD range for January 2023 (59945.0 to 59975.0) into a filter condition on `firstmjd`.\n\n3. **Join the `object` and `probability` tables:**\n   - Perform an INNER JOIN between `object` and `probability` on the `oid` column, which is the object identifier.\n   - This allows access to both object metadata and classification probabilities in a single result set.\n\n4. **Filter for the most likely class being 'SN':**\n   - In the `probability` table, filter for entries where:\n     - `classifier_name` is 'stamp_classifier' (to ensure we're only considering stamp classifier results).\n     - `ranking` is 1 (to select only the most probable class for each object).\n     - `class_name` is 'SN' (or the appropriate class label for supernovae, based on the schema; if the class label is 'SN', use that; if not, clarify the exact class name).\n\n5. **Select the required columns:**\n   - Retrieve the object identifier (`oid`) from the `object` table.\n   - Retrieve the probability value (`probability`) from the `probability` table.\n   - Optionally, include other relevant columns if needed, but based on the request, focus on `oid` and `probability`.\n\n6. **Order and limit the results:**\n   - Decide if the results should be ordered by probability (descending) to see the most confident classifications first.\n   - Determine if any limit on the number of results is necessary; if not specified, return all matching objects.\n\n7. **Ensure default conditions are applied:**\n   - Use the default conditions for the `probability` table:\n     - `ranking = 1`\n     - `classifier_name = 'stamp_classifier'`\n   - These conditions should be explicitly included unless the user specifies otherwise.\n\n8. **Construct the final query structure:**\n   - Use a `WITH` clause if needed for clarity, or directly write the SELECT statement with JOINs and WHERE conditions.\n   - Make sure to include all filtering conditions and join conditions accurately.\n\nBy following these steps, the query will accurately retrieve object identifiers and their most probable classification probabilities for objects first detected in January 2023, with the most likely class being 'SN' according to the stamp classifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of January = 59945.0\n-- mjd date for the end of January = 59975.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifiers and probabilities in the stamp classifier for objects whose most likely class according to the stamp classifier is SN, and that had their first detection in January of 2023''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "3-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves objects classified as YSO (Young Stellar Object) by the lc_classifier with a probability higher than 0.7, and that were last detected in June (specifically between MJD 60096.0 and 60125.0), follow these detailed steps:\n\n1. **Identify the relevant tables:**\n   - Use the `object` table to access the main object information, including detection dates.\n   - Use the `probability` table to filter objects based on their classification probabilities and rankings.\n   \n2. **Filter objects based on classification:**\n   - Select entries from the `probability` table where:\n     - `class_name` is 'YSO'.\n     - `classifier_name` is 'lc_classifier'.\n     - `probability` is greater than 0.7.\n     - `ranking` is 1, to ensure only the most probable classification is considered.\n   \n3. **Join the `probability` table with the `object` table:**\n   - Use the `oid` column as the join key to link classification probabilities with object metadata.\n   \n4. **Apply the date filter for last detection:**\n   - Filter objects where `lastmjd` (from the `object` table) falls within the specified date range for last detections in June (60096.0 to 60125.0).\n   \n5. **Select the desired columns:**\n   - Retrieve all columns from the `object` table for comprehensive information, or specify particular columns if needed.\n   \n6. **Order or group results if necessary:**\n   - Decide if results should be ordered by `lastmjd` or any other relevant metric for clarity.\n   \n7. **Ensure the query adheres to default conditions:**\n   - Confirm that the `probability.ranking=1` and `probability.classifier_name='lc_classifier'` conditions are applied unless explicitly overridden.\n   \n8. **Optimize the query:**\n   - Use appropriate indexes, such as on `probability.oid`, `probability.class_name`, and `object.lastmjd`, to improve performance.\n   \n9. **Test the query:**\n   - Verify that the query correctly filters objects based on classification confidence and detection date, returning accurate and relevant results.\n\nBy following these steps, the resulting query will accurately retrieve all objects classified as YSO with high confidence, last detected in June, ensuring the data is precise and relevant.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- last june in mjd date: [start=60096.0, end=60125.0]\nDomain Knowledge: 0\n # User Request: ''Give me the objects classified as YSO by the lc classifier (prob higher than 0.7) that were last detected last June''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "23-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves objects most likely to be classified as \"SNIa\", \"SNIbc\", \"SNII\", or \"SLSN\" by the lc_classifier with a probability higher than 0.2, and to include all classification probabilities, follow these detailed steps:\n\n1. **Identify the relevant tables:**\n   - Use the `object` table to get the main object information.\n   - Use the `probability` table to access classification probabilities and rankings.\n   \n2. **Filter the classification probabilities:**\n   - Select entries from the `probability` table where:\n     - `classifier_name` equals `'lc_classifier'`.\n     - `ranking` equals `1` to ensure only the most likely classification per object.\n     - `probability` is greater than `0.2`.\n     - `class_name` is one of `'SNIa'`, `'SNIbc'`, `'SNII'`, `'SLSN'`.\n   \n3. **Join the `probability` table with the `object` table:**\n   - Use the `oid` column as the join key to associate classification probabilities with object details.\n   \n4. **Retrieve all classification probabilities for each object:**\n   - For each object that meets the above criteria, fetch all associated probabilities from the `probability` table, regardless of class or ranking.\n   - This involves a subquery or a join that pulls all probabilities for the object, not just the filtered ones.\n   \n5. **Construct the main query:**\n   - Select the object identifiers and relevant object columns (e.g., `oid`, `firstmjd`, `lastmjd`, `meanra`, `meandec`, etc.).\n   - Include a nested subquery or a join to gather all classification probabilities for each object.\n   \n6. **Ensure the query returns all probabilities:**\n   - Use a subquery or a lateral join to fetch all classification probabilities for each object that passes the initial filter.\n   \n7. **Order and limit the results:**\n   - Optionally, order the results by the highest probability or other relevant criteria.\n   - Decide if any limit on the number of objects is needed; otherwise, return all matching objects.\n   \n8. **Include all classification probabilities:**\n   - For each object, include a list or array of all classification probabilities, possibly as a JSON or array aggregation, to provide a comprehensive view of the classification landscape.\n   \n9. **Document the query structure:**\n   - Clearly specify the join conditions, filters, and aggregation methods used to ensure clarity and reproducibility.\n   \n10. **Test the query:**\n    - Verify that it correctly filters objects with the specified classes, probability thresholds, and includes all associated classification probabilities.\n\nBy following these steps, the final query will accurately identify objects most likely to be one of the specified supernova classes, with probabilities above 0.2, and will include all classification probabilities for comprehensive analysis.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- it is important to return all the probabilites (different rankings)\n\nDomain Knowledge: 0\n # User Request: ''I want the objects most likely to be either \"SNIa\", \"SNIbc\", \"SNII\", \"SLSN\" classified by the lc_classifier with a probability higher than 0.2, with all the classification probabilites.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "23-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves objects most likely to be classified as \"SNIa\", \"SNIbc\", \"SNII\", or \"SLSN\" by the lc_classifier with a probability higher than 0.2, and to include all classification probabilities, follow these detailed steps:\n\n1. **Identify the relevant tables:**\n   - Use the 'object' table to get the main object information.\n   - Use the 'probability' table to access classification probabilities and rankings.\n   \n2. **Filter for the most likely classification per object:**\n   - Restrict the 'probability' table to entries where 'ranking' = 1, ensuring only the top-ranked classification per object is considered.\n   - Filter for 'classifier_name' = 'lc_classifier' to focus on classifications from the light curve classifier.\n   \n3. **Select objects with specific classes:**\n   - Filter the 'probability' entries where 'class_name' is one of the target classes: 'SNIa', 'SNIbc', 'SNII', 'SLSN'.\n   - Apply an additional filter where 'probability' > 0.2 to ensure only objects with a high likelihood are included.\n   \n4. **Join the probability data with object data:**\n   - Perform an INNER JOIN between the filtered 'probability' table and the 'object' table on 'oid' to retrieve object details alongside their classification probabilities.\n   \n5. **Retrieve all classification probabilities for each object:**\n   - For each object identified in the previous step, fetch all associated classification probabilities, regardless of ranking or class.\n   - This may involve a subquery or a join to the 'probability' table filtered by 'oid' to get all probabilities for that object.\n   \n6. **Construct the query to include all relevant information:**\n   - Select all columns from the 'object' table.\n   - Include the classification probabilities for the target classes, possibly as a JSON or array structure, or as separate columns.\n   - Ensure the output contains the object identifiers, main object info, and all classification probabilities for transparency.\n   \n7. **Order and limit the results if necessary:**\n   - Optionally, order the results by the highest probability for the target classes or by object identifiers.\n   - Decide if any limit on the number of objects is needed; otherwise, return all matching objects.\n   \n8. **Ensure compliance with default conditions:**\n   - Use 'probability.ranking' = 1 to get the most likely class per object.\n   - Use 'probability.classifier_name' = 'lc_classifier' to focus on the relevant classifier.\n   \n9. **Document the query logic:**\n   - Clearly specify that the query retrieves objects with their most probable classification as one of the specified supernova types, with a probability threshold, and includes all classification probabilities for each object.\n   \nBy following these steps, the resulting query will accurately identify the most likely supernova candidates based on the specified classifier and probability threshold, while providing comprehensive classification probability data for each object.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- it is important to return all the probabilites (different rankings)\n\nDomain Knowledge: 0\n # User Request: ''I want the objects most likely to be either \"SNIa\", \"SNIbc\", \"SNII\", \"SLSN\" classified by the lc_classifier with a probability higher than 0.2, with all the classification probabilites.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "20-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the overall statistics of each astronomical object, including the number of detections (`ndet`).\n   - The `probability` table, which holds the classification probabilities assigned by classifiers, including the light curve classifier (`classifier_name='lc_classifier'`) and class name `'RRL'`.\n   \n2. **Determine the filtering criteria:**\n   - Classification: Objects classified as `'RRL'` by the `lc_classifier`.\n   - Probability threshold: The probability of being `'RRL'` must be greater than 0.55.\n   - Number of detections: The object must have `ndet >= 100`.\n   - Classification ranking: Since the classification probabilities are stored with a ranking, ensure that only the top-ranked (`ranking=1`) probability entries are considered, to get the most confident classification.\n\n3. **Construct the subquery or join for classification data:**\n   - Join the `object` table with the `probability` table on the object identifier (`oid`).\n   - Filter the `probability` table to include only entries where:\n     - `classifier_name='lc_classifier'`\n     - `class_name='RRL'`\n     - `probability > 0.55`\n     - `ranking=1` (to ensure the most probable classification)\n   \n4. **Apply the detection count filter:**\n   - Filter objects where `ndet >= 100` in the `object` table.\n\n5. **Select all relevant columns:**\n   - Since the user requests all information, use `SELECT *` from the combined result, or specify particular columns if needed.\n   \n6. **Order the results:**\n   - Optionally, order the results by probability, detection count, or other relevant metrics for clarity or prioritization.\n\n7. **Ensure the query is optimized:**\n   - Use indexes on `probability.oid`, `probability.class_name`, `probability.classifier_name`, and `object.ndet` to improve performance.\n   - Filter early in the query to reduce the dataset size.\n\n8. **Final step:**\n   - Combine all the above into a single query structure, ensuring all conditions are correctly applied and the joins are properly defined.\n\nThis systematic decomposition ensures the query accurately retrieves objects classified as RRL with high confidence, having sufficient detections, and leverages the database schema efficiently.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query objects classified by the light curve classifier that are most likely to be RRL with a probability larger than 0.55 and that have 100 or more detections. Write in PostgresSQL.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "20-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics of each astronomical object, including the number of detections (`ndet`).\n   - The `probability` table, which holds the classification probabilities for each object, including the class name, classifier name, probability, and ranking.\n\n2. **Determine the filtering criteria based on user request:**\n   - The classification must be performed by the light curve classifier (`classifier_name='lc_classifier'`).\n   - The class of interest is 'RRL' (RR Lyrae), which should be specified exactly as in the database.\n   - The probability of the object being 'RRL' must be greater than 0.55.\n   - The object must have at least 100 detections (`ndet >= 100`).\n\n3. **Apply default conditions for classification probabilities:**\n   - Filter the `probability` table to include only entries where `ranking=1` to ensure the most likely classification.\n   - Filter by `classifier_name='lc_classifier'` to select classifications from the light curve classifier.\n\n4. **Join the relevant tables:**\n   - Perform an `INNER JOIN` between the `object` table and the `probability` table on the `oid` column, ensuring that the classification probabilities are linked to the correct objects.\n   - This join allows filtering objects based on their classification probability and other object properties.\n\n5. **Filter for the class 'RRL':**\n   - In the `probability` table, filter for `class_name='RRL'`.\n   - Ensure the probability exceeds 0.55.\n\n6. **Filter for objects with sufficient detections:**\n   - In the `object` table, filter for `ndet >= 100`.\n\n7. **Select the desired columns:**\n   - Since the user requests all relevant information, use `SELECT *` to retrieve all columns from the joined tables.\n   - Alternatively, specify particular columns if needed, but the default is to select all.\n\n8. **Order the results (optional):**\n   - Decide if the results should be ordered by probability, number of detections, or other criteria.\n   - If not specified, the default can be to order by probability descending to prioritize the most likely RRL objects.\n\n9. **Construct the final query structure:**\n   - Use a `WITH` clause if needed for clarity, but not necessary here.\n   - Ensure the query is optimized by applying filters early and using indexes on `oid`, `class_name`, `classifier_name`, `probability`, and `ndet`.\n\n10. **Test the query:**\n    - Verify that the query correctly filters objects classified as RRL with probability > 0.55 and with at least 100 detections.\n    - Confirm that the join correctly links classification probabilities to object statistics.\n\nThis systematic decomposition ensures the query is accurate, efficient, and adheres to the database schema and default conditions specified.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query objects classified by the light curve classifier that are most likely to be RRL with a probability larger than 0.55 and that have 100 or more detections. Write in PostgresSQL.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics of each source, including `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, and `deltajd`.\n   - The `probability` table, which holds the classification probabilities, including `oid`, `class_name`, `classifier_name`, `ranking`, and `probability`.\n   - The `light curve classifier` specifics are embedded in the `probability` table, filtered by `classifier_name='lc_classifier'`.\n\n2. **Set the filtering criteria based on user specifications:**\n   - Minimum number of detections: `ndet >= 40`.\n   - Minimum time span between first and last detection: `deltajd >= 200`.\n   - Class probability thresholds:\n     - For 'Blazar': `probability > 0.8`.\n     - For 'AGN' and 'QSO': `probability > 0.95`.\n\n3. **Define sub-queries for each class (AGN, QSO, Blazar):**\n   - For each class, create a sub-query that:\n     - Joins the `object` table with the `probability` table on `oid`.\n     - Filters for `classifier_name='lc_classifier'`.\n     - Filters for `class_name` equal to the specific class ('AGN', 'QSO', 'Blazar').\n     - Applies the probability threshold specific to each class.\n     - Applies the detection count and time span filters.\n     - Selects the required columns: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `classifier_name`, `class_name`, `ranking`, and `probability`.\n\n4. **Construct individual SELECT statements for each class:**\n   - Each SELECT should retrieve the columns:\n     - `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `'lc_classifier'` as `classifier_name`, the specific class name, `ranking`, and `probability`.\n   - Ensure the filters for detection count, time span, class, and probability are correctly applied.\n\n5. **Combine the sub-queries using UNION:**\n   - Use `UNION` to merge the results from the three class-specific sub-queries.\n   - This ensures the final result contains sources classified as either AGN, QSO, or Blazar, with the specified probability thresholds.\n\n6. **Order or group the final results if necessary:**\n   - Although not explicitly requested, consider ordering by `probability` descending or by `oid` for clarity.\n   - Ensure the final query returns all columns specified in the user request.\n\n7. **Validate the query:**\n   - Confirm that the joins are correctly implemented on `oid`.\n   - Check that the filters are correctly applied to each sub-query.\n   - Verify that the `classifier_name` filter is consistent across all sub-queries.\n\n8. **Optional: Add comments or documentation within the query:**\n   - To clarify the purpose of each sub-query and the overall union operation.\n   - To specify the filtering criteria explicitly for future reference.\n\nBy following these steps, you will systematically generate a comprehensive PostgreSQL query that retrieves all sources classified as AGN, QSO, or Blazar by the light curve classifier, adhering to the specified detection, time span, and probability thresholds, and combining the results with a UNION statement.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "18-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics of each source, including `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, and `deltajd`.\n   - The `probability` table, which contains the classification probabilities, including `oid`, `class_name`, `classifier_name`, `ranking`, and `probability`.\n   \n2. **Determine the filtering criteria:**\n   - Only include sources classified as `AGN`, `QSO`, or `Blazar` by the `lc_classifier`.\n   - Enforce a minimum number of detections: `ndet >= 40`.\n   - Enforce a minimum time span between first and last detection: `deltajd >= 200`.\n   - Filter out sources with predicted class probability higher than 0.8 for `Blazar`.\n   - Filter out sources with predicted class probability higher than 0.95 for `AGN` and `QSO`.\n   \n3. **Establish the classification filtering:**\n   - Use the `probability` table to filter for `class_name` in (`'AGN'`, `'QSO'`, `'Blazar'`).\n   - Ensure `classifier_name='lc_classifier'`.\n   - Ensure `ranking=1` to get the most probable classification per object.\n   \n4. **Construct sub-queries for each class:**\n   - For each class (`'AGN'`, `'QSO'`, `'Blazar'`), create a sub-query that:\n     - Joins the `object` table with the `probability` table on `oid`.\n     - Applies the class-specific probability threshold (`> 0.95` for `AGN` and `QSO`, `> 0.8` for `Blazar`).\n     - Filters objects based on `ndet` and `deltajd`.\n     - Selects the relevant columns: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `g_r_mean_corr`, `classifier_name`, `class_name`, `ranking`, and `probability`.\n   \n5. **Combine the class-specific sub-queries using UNION:**\n   - Use a `UNION` statement to merge the results from each class-specific sub-query, ensuring no duplicates.\n   \n6. **Order or group the final results if necessary:**\n   - Although not explicitly requested, consider ordering by `probability` or `oid` for clarity.\n   \n7. **Ensure the query returns all specified columns:**\n   - The final query should include the columns: `oid`, `meanra`, `meandec`, `ndet`, `firstmjd`, `deltajd`, `g_r_mean_corr`, `classifier_name`, `class_name`, `ranking`, and `probability`.\n   \n8. **Test the query for correctness and performance:**\n   - Verify that the joins, filters, and union are correctly implemented.\n   - Confirm that the probability thresholds are correctly applied per class.\n   \nBy following these steps, you will systematically generate a comprehensive PostgreSQL query that retrieves all sources classified as `AGN`, `QSO`, or `Blazar` with the specified detection and time span criteria, filtered by the appropriate probability thresholds, and combined into a single result set using UNION.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Write a script in PostgreSQL with a query asking for all the probabilities for all the sources classfied as either AGN, QSO or Blazar by the light curve classifier. Define a minimum number of detections of 40, and a minimum time span between the first and the last detection of 200 days, in order to ensure the detection of a variable signal from the light curves. Also, filter out sources using a predicted class probability higher than 0.8 for the Blazar class and 0.95 for the AGN and QSO classes. Collect similar numbers for each class using a UNION statement between each sub-query defined by each probability. The query must return the columns oid, meanra, meandec, ndet, firstMJD, deltajd, g_r_mean_corr classifier_name, class_name, ranking and probability.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`), detection times (`firstmjd`), and other object-level statistics.\n   - The `probability` table, which provides classification probabilities and rankings for each object, linked via `oid`.\n   - The `detection` table, which contains individual detection records, including detection times (`mjd`), magnitudes (`magpsf`), filter IDs (`fid`), and positional information.\n   - The `feature` table, which stores features like `g-r_max`, `magmax`, and possibly `magmax_fid` (filter ID at maximum magnitude).\n\n2. **Filter objects classified as Type Ia SNe:**\n   - Use the `probability` table to select objects with `class_name='SNIa'`, `classifier_name='lc_classifier'`, and `ranking=1` (most probable classification).\n   - Ensure the probability is above a certain threshold if specified, or simply select the top-ranked classification.\n\n3. **Select objects whose first detection occurred last September:**\n   - Filter the `object` table where `firstmjd` is between 60188.0 and 60217.0.\n   - This ensures the first detection date is within September 2023.\n\n4. **Retrieve the peak magnitude and the filter ID at maximum brightness:**\n   - Use the `detection` table to find, for each object, the detection with the minimum `magpsf` (since magnitude is inversely related to brightness).\n   - Record the `magpsf` value and corresponding `fid` for that detection.\n   - This involves grouping detections by `oid` and selecting the detection with the lowest `magpsf`.\n\n5. **Obtain the maximum g-r color at maximum brightness:**\n   - Use the `feature` table to retrieve the `g-r_max` feature for each object.\n   - Filter for objects where `g-r_max` is below 1.\n\n6. **Apply the magnitude condition:**\n   - Ensure the maximum magnitude (brightest detection) is above 19 (i.e., `magpsf` > 19).\n\n7. **Select and return the required columns:**\n   - Object identifier (`oid`).\n   - The maximum g-r difference (`g-r_max`).\n   - The maximum magnitude (`magmax`).\n   - The filter ID at maximum brightness (`fid`).\n\n8. **Combine all conditions:**\n   - Use `JOIN`s or sub-queries to connect the classification, detection, and feature data.\n   - Use `WHERE` clauses to filter by date, classification, magnitude, and color.\n   - Ensure only objects satisfying all criteria are included.\n\n9. **Order and limit the results if necessary:**\n   - No explicit ordering specified; return all matching objects.\n   - Confirm that the query efficiently filters data using indexes on `mjd`, `oid`, `class_name`, `ranking`, and features.\n\n10. **Ensure the query handles multiple detections:**\n    - Use nested sub-queries or window functions to identify the peak magnitude detection per object.\n    - Cross-reference the detection with the feature data for `g-r_max`.\n\n11. **Test the query for correctness and performance:**\n    - Verify that the date filters correctly capture September 2023.\n    - Confirm that the classification and probability filters are correctly applied.\n    - Check that the maximum magnitude and `g-r_max` are accurately retrieved.\n\nBy following these steps, the final query will accurately extract all Type Ia SNe that meet the specified temporal, brightness, and color criteria, including the relevant object ID, maximum g-r difference, peak magnitude, and filter ID.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "11-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all Type Ia supernovae (SNe Ia) with the specified conditions from the ALeRCE database, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - Use the `object` table to access object identifiers (`oid`), mean right ascension (`meanra`), mean declination (`meandec`), and detection time ranges (`firstmjd`, `lastmjd`).\n   - Use the `probability` table to filter objects classified as Type Ia SNe (`class_name='SNIa'`) with the highest probability (`ranking=1`) from the `lc_classifier`.\n   - Use the `detection` table to find the first detection date (`mjd`) for each object.\n   - Use the `feature` table to obtain the `g-r_max` color and the `magstat` table to find the maximum magnitude (`magmax`) and the filter ID (`fid`).\n\n2. **Filter objects classified as Type Ia SNe with high confidence:**\n   - Select entries from the `probability` table where `class_name='SNIa'`, `classifier_name='lc_classifier'`, `classifier_version` (if needed), and `ranking=1`.\n   - Join this with the `object` table on `oid` to get object details.\n\n3. **Identify objects whose first detection occurred last September:**\n   - Use the `detection` table to find the earliest detection (`MIN(mjd)`) for each object.\n   - Filter objects where this earliest detection date (`first_detection_mjd`) is between 60188.0 and 60217.0 (the MJD range for September).\n\n4. **Determine the peak magnitude and the g-r color at maximum:**\n   - Use the `feature` table to find the `g-r_max` value for each object.\n   - Filter objects where `g-r_max` is below 1.\n\n5. **Find the maximum magnitude (`magmax`) for each object:**\n   - Use the `magstat` table, filtering for the relevant object (`oid`) and the filter ID corresponding to the band where the peak magnitude is observed.\n   - Identify the maximum `magmax` value for each object.\n\n6. **Select the filter ID associated with the maximum magnitude:**\n   - From the `magstat` data, determine which filter (`fid`) corresponds to the maximum magnitude.\n\n7. **Combine all conditions:**\n   - Ensure the object is classified as SNIa with high probability.\n   - The first detection date is in September.\n   - The `g-r_max` color is below 1.\n   - The maximum magnitude exceeds 19 (i.e., `magmax > 19`).\n   - Retrieve the object identifier (`oid`), the `g-r_max` value, the maximum magnitude, and the filter ID (`fid`).\n\n8. **Order and limit the results if necessary:**\n   - Order the results by object identifier or other relevant criteria.\n   - Decide whether to limit the number of results.\n\n9. **Ensure all joins and filters are correctly applied:**\n   - Use inner joins between `object`, `probability`, `detection`, `feature`, and `magstat` tables based on `oid`.\n   - Apply all filters in the `WHERE` clause to meet the specified conditions.\n\n10. **Test the query for correctness and performance:**\n    - Verify that the date filters match the MJD range for September.\n    - Confirm that the classification and probability filters are correctly applied.\n    - Check that the magnitude and color conditions are properly enforced.\n\nThis systematic approach ensures the query accurately retrieves all SNe Ia that meet the user\u2019s criteria, with optimal filtering and correct joins across the relevant tables.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of September = 60188.0\n-- mjd date for the end of September = 60217.0\nDomain Knowledge: 0\n # User Request: ''Obtain all the Type Ia SNe whose first detection happened last September, whose peak magnitude is above 19 and whose g-r color at maximum is below 1. Return the object identifier, the maximum g-r difference, the maximum magnitude, and the filter id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main data sources:**\n   - The primary table is the `object` table, which contains object identifiers (`oid`), detection times (`firstmjd`), celestial coordinates (`meanra`, `meandec`), and other relevant properties.\n   - The `probability` table holds classification probabilities, including the `class_name`, `probability`, `ranking`, and `classifier_name`.\n   - The `stamp_classifier` table (or relevant classification table) contains the classification results, including the class labels and associated probabilities, especially the highest probability per object.\n\n2. **Filter objects based on detection date:**\n   - Convert the specified MJD range for July 2023 (60126.0 to 60156.0) into a condition on the `firstmjd` column.\n   - Select objects where `firstmjd` is greater than or equal to 60126.0 and less than or equal to 60156.0.\n\n3. **Filter objects based on spatial location:**\n   - Use the `meanra` and `meandec` columns from the `object` table.\n   - Apply the `q3c_dist` function to compute the angular distance between each object and the center of Abell 370 (RA=39.97, Dec=-1.5768).\n   - Filter objects where this distance is less than or equal to 16.16667 degrees (which corresponds to 1000 arcmin).\n\n4. **Apply the sgscore1 condition:**\n   - Filter objects where `sgscore1` (assuming it is a column in the `object` table or a related table) is less than 0.3.\n\n5. **Exclude objects with highest probability in stamp classifier for classes 'Asteroid' or 'Bogus':**\n   - Join the `object` table with the `probability` table, filtering for `classifier_name='stamp_classifier'` and `ranking=1` (most probable class).\n   - Retrieve the `class_name` and exclude objects where `class_name` is 'asteroid' or 'bogus' (case-insensitive or as per exact class names).\n\n6. **Identify the highest probability class for each object:**\n   - For each object, select the entry in `probability` with `ranking=1` and `classifier_name='stamp_classifier'`.\n   - Extract the `class_name`, `probability`, and `classifier_version`.\n\n7. **Retrieve the required columns:**\n   - From the `object` table, select `oid`, `meanra`, `meandec`.\n   - From the `probability` table (joined as above), get the `class_name`, `probability`, and `classifier_version`.\n   - For the `value` and `name` columns, determine their source:\n     - If `value` and `name` are from the `stamp_classifier` or related classification table, include them accordingly.\n     - If they are from the `probability` table, clarify their meaning; otherwise, assume they are from the classification result, possibly as `class_name` and `classifier_version`.\n   - Calculate the distance using `q3c_dist` between the object coordinates and the Abell 370 center, alias as `dist`.\n\n8. **Construct the final query:**\n   - Use `SELECT` to specify the columns: `oid`, `value`, `name`, `version`, `meanra`, `meandec`, and the computed `dist`.\n   - Apply all filters in the `WHERE` clause:\n     - Date range filter on `firstmjd`.\n     - Spatial filter using `q3c_dist`.\n     - `sgscore1<0.3`.\n     - Exclusion of objects with highest probability class 'Asteroid' or 'Bogus'.\n   - Ensure the join with the `probability` table is correctly filtered for `ranking=1` and `classifier_name='stamp_classifier'`.\n   - Order or limit results if necessary (not specified).\n\n9. **Verify and optimize:**\n   - Confirm that indexes on `firstmjd`, `meanra`, `meandec`, and `probability` columns are used for efficient filtering.\n   - Use the `q3c_dist` function efficiently by joining with a temporary table or inline values if needed.\n\nThis systematic decomposition ensures the query accurately filters objects based on detection time, spatial proximity, classification probabilities, and specific class exclusions, while retrieving all necessary columns and computed distances.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "9-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - Main object information is stored in the `object` table, including `oid`, `meanra`, `meandec`.\n   - Classification probabilities are stored in the `probability` table, linked via `oid`.\n   - The classification of interest is the `stamp_classifier`.\n   - The `value`, `name`, and `version` columns are likely from the `probability` table, representing the probability value, class name, and classifier version.\n   - The `sgscore1` parameter is not explicitly listed in the provided schema; verify if it exists in the `object` table or if it needs to be derived or filtered differently.\n   - The source identifier (e.g., the object ID or a specific source column) should be clarified; assuming `oid` serves as the source identifier.\n\n2. **Define the spatial filtering criteria:**\n   - Use the `q3c_dist` function to compute the angular distance between each object and the Abell 370 cluster center at RA=39.97, Dec=-1.5768.\n   - Filter objects where this distance is less than or equal to 16.16667 degrees (which corresponds to 1000 arcmin).\n\n3. **Filter objects based on detection date:**\n   - The `firstmjd` column in the `object` table indicates the date of first detection.\n   - Select objects with `firstmjd` between 60126.0 (start of July 2023) and 60156.0 (end of July 2023).\n\n4. **Apply the `sgscore1` condition:**\n   - Filter objects where `sgscore1` < 0.3.\n   - Confirm if `sgscore1` exists as a column in the `object` table; if not, determine its source or derivation.\n\n5. **Filter based on classification probabilities:**\n   - Join the `probability` table with the `object` table on `oid`.\n   - Restrict to `probability.ranking = 1` to get the most probable classification.\n   - Restrict to `probability.classifier_name='stamp_classifier'`.\n   - Exclude objects where the class is 'Asteroid' or 'Bogus' in the `probability` table.\n   - Ensure the class with the highest probability is not 'Asteroid' or 'Bogus'.\n\n6. **Identify the highest probability class for each object:**\n   - For each object, select the class with the maximum `probability.value`.\n   - Confirm that this class is neither 'Asteroid' nor 'Bogus'.\n\n7. **Retrieve the requested columns:**\n   - `oid` from the `object` table.\n   - `value`, `name`, `version` from the `probability` table.\n   - `meanra`, `meandec` from the `object` table.\n   - The source identifier, which is likely `oid`.\n   - The distance `dist` calculated using `q3c_dist` between the object and the cluster center.\n\n8. **Construct the spatial query:**\n   - Use `q3c_dist` to compute the distance between each object\u2019s (`meanra`, `meandec`) and the cluster center.\n   - Filter objects where this distance is less than or equal to 16.16667 degrees.\n\n9. **Combine all filters into a coherent query:**\n   - Use `JOIN` between `object` and `probability` on `oid`.\n   - Apply all `WHERE` conditions for date, spatial proximity, `sgscore1`, and classification.\n   - Use a subquery or window function to identify the maximum probability class per object.\n   - Exclude objects with maximum class 'Asteroid' or 'Bogus'.\n\n10. **Order and limit the results if necessary:**\n    - Order by `oid` or `dist` as needed.\n    - Limit the number of results if specified or for performance considerations.\n\n11. **Document the query:**\n    - Clearly comment each filtering step.\n    - Ensure the query is optimized with appropriate indexes, especially on `oid`, `firstmjd`, `meanra`, `meandec`, and `probability` columns.\n\nBy following these steps, you will systematically generate a precise and efficient PostgreSQL query that retrieves the desired object identifiers and associated information based on the specified criteria.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for the start of July = 60126.0\n-- mjd date for the end of July = 60156.0\nDomain Knowledge: -- 1000 arcmin = 16.16667 degrees\n\n # User Request: ''Get the object identifiers that had their first detection in July 2023, are within a search radius of 1000 arcmin from the center of the Abell 370 galaxy cluster (centered at RA=39.97, Dec=-1.5768), have sgscore1<0.3 and their highest probability in the stamp classifier is not obtained for class Asteroid nor class Bogus. Get the columns 'oid', 'value', 'name', 'version', 'meanra', 'meandec', the source identifier, and the distance obtained from the q3c_dist function as 'dist'.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers (`oid`) and classification information.\n   - The `probability` table, which holds classification probabilities and rankings.\n   - The `feature` table, which contains feature names, values, and the associated `fid` (bandpass identifier).\n   - The `detection` table, which records individual detections, including candidate identifiers (`candid`), detection times (`mjd`), magnitudes (`magpsf`), magnitude errors (`sigmapsf`), and band identifiers (`fid`).\n\n2. **Filter objects classified as 'SN II' with probability > 0.6:**\n   - Create a sub-query on the `probability` table filtering for `class_name='SNIi'`, `classifier_name='lc_classifier'`, and `ranking=1` (most likely class).\n   - Add the condition `probability > 0.6`.\n   - Join this sub-query with the `object` table on `oid` to select the relevant objects.\n\n3. **Ensure the objects have more than 50 detections:**\n   - Use the `detection` table to count the number of detections per object (`oid`).\n   - Filter for objects where the count of detections exceeds 50.\n\n4. **Calculate the magnitude range in the ZTF g-band:**\n   - Filter detections to only include those with `fid=1` (assuming `fid=1` corresponds to g-band).\n   - For each object, find the minimum and maximum `magpsf` in the g-band.\n   - Compute the difference between these two values.\n   - Filter objects where this difference exceeds 2 magnitudes.\n\n5. **Retrieve detection details:**\n   - For the objects passing all filters, extract the detection information:\n     - `candid` (candidate identifier)\n     - `mjd` (detection time)\n     - `magpsf` (psf magnitude)\n     - `sigmapsf` (magnitude error)\n     - `fid` (band identifier, renamed as `feature_fid`)\n   \n6. **Retrieve features associated with these objects:**\n   - Filter the `feature` table for entries with `oid` in the filtered object set.\n   - Select the feature `name` and `value`.\n   - Rename the `fid` column as `feature_fid` in the output.\n\n7. **Order the final results:**\n   - Order the combined results by `oid` as specified.\n\n8. **Combine all steps:**\n   - Use nested sub-queries and JOINs to connect the filtered objects with their detections and features.\n   - Ensure that only objects satisfying all conditions are included.\n   - Use appropriate filtering, grouping, and ordering to optimize the query.\n\n9. **Additional considerations:**\n   - Use `DISTINCT` if necessary to avoid duplicate rows.\n   - Maintain the exact column names and table references.\n   - Use inner joins to connect the filtered object set with detections and features, ensuring only relevant data is retrieved.\n\nThis systematic decomposition ensures the final query will accurately retrieve the object identifiers, detection candidate IDs, feature names and values, psf magnitudes, magnitude errors, and band identifiers, all filtered by the specified classification, detection count, and magnitude variation criteria, ordered by object ID.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "5-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The primary table for object information is the `object` table, which contains object identifiers (`oid`) and classification probabilities.\n   - The `probability` table holds classification probabilities, including the class name, classifier name, and ranking.\n   - The `detection` table contains detection-specific information such as candidate identifiers (`candid`), detection times (`mjd`), band identifiers (`fid`), and magnitudes.\n   - The `feature` table contains features associated with objects, including feature names and values.\n\n2. **Filter objects classified as SN II with probability > 0.6:**\n   - Use the `probability` table to select entries where:\n     - `class_name` = 'SNII'\n     - `classifier_name` = 'lc_classifier'\n     - `probability` > 0.6\n     - `ranking` = 1 (most likely classification)\n   - Join this filtered probability data with the `object` table on `oid` to get object identifiers.\n\n3. **Ensure the objects meet the detection count criterion:**\n   - Join the `object` table with the `detection` table on `oid`.\n   - Count the number of detections (`ndet`) for each object.\n   - Filter objects where the total number of detections exceeds 50.\n\n4. **Calculate the magnitude range in the ZTF g-band:**\n   - Filter detections to only include those with `fid` corresponding to the g-band (assumed to be `fid=1`).\n   - For each object, find the minimum and maximum `magpsf` (psf magnitude) in the g-band.\n   - Compute the difference between these two values.\n   - Filter objects where this magnitude difference exceeds 2 mag.\n\n5. **Retrieve detection details:**\n   - For each object that passes the above filters, select detection information:\n     - Candidate identifier (`candid`)\n     - Detection time (`mjd`)\n     - Band identifier (`fid`)\n     - PSF magnitude (`magpsf`)\n     - Magnitude error (`sigmapsf`)\n   - Rename the `fid` column as `'feature_fid'` in the output.\n\n6. **Retrieve features associated with the objects:**\n   - Join the `feature` table with the filtered objects on `oid`.\n   - Select features where the `name` matches the features of interest (if specific features are specified; otherwise, select all).\n   - For each feature, get the `name` and `value`.\n\n7. **Order the final results:**\n   - Order the combined results by `oid`.\n\n8. **Construct the query structure:**\n   - Use subqueries or Common Table Expressions (CTEs) to organize filtering steps:\n     - One CTE for objects classified as SN II with probability > 0.6.\n     - One CTE for objects with detection counts > 50.\n     - One CTE for objects with magnitude range > 2 in g-band.\n   - Join these CTEs with detection and feature tables to assemble the final dataset.\n\n9. **Ensure all selected columns are included:**\n   - Object identifier (`oid`)\n   - Candidate identifier (`candid`)\n   - Detection time (`mjd`)\n   - Feature name and value\n   - PSF magnitude (`magpsf`)\n   - Magnitude error (`sigmapsf`)\n   - Feature band identifier (`fid` renamed as `'feature_fid'`)\n\n10. **Finalize the query:**\n    - Apply the `ORDER BY oid` clause.\n    - Confirm that all joins and filters are correctly applied to produce an accurate and efficient query.\n\nThis systematic decomposition ensures that the query will accurately retrieve the requested information, filtered by the specified classification, detection count, and magnitude variation criteria, with proper ordering and renaming of columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier of the detections, name and value of the feature, psf magnitudes, magnitude errors, and band identifiers renaming the feature fid column as 'feature_fid', as a function of time of the objects classified as SN II with probability larger than 0.6, number of detections greater than 50 and difference between minimum and maximum magnitudes in ZTF g-band greater than 2 mag. Order the results by oid.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object identifiers and general properties.\n   - The `probability` table, which holds classification probabilities, including the likelihood of being a YSO.\n   - The `feature` table, which stores various features, including those related to periodicity, amplitude, and other light curve characteristics.\n\n2. **Filter objects based on YSO probability:**\n   - Select objects where the `probability` table's `class_name` is `'YSO'`.\n   - Ensure the `probability` value exceeds 0.7.\n   - Restrict to the most recent or relevant probability entries by filtering on `classifier_name='lc_classifier'` and `ranking=1` (most likely classification).\n\n3. **Join the `object` and `probability` tables:**\n   - Use the object identifier (`oid`) as the join key.\n   - Filter the joined data to include only objects with the YSO probability > 0.7.\n\n4. **Identify features related to periodicity and amplitude:**\n   - From the `feature` table, select features where the `name` corresponds to known periodicity and amplitude features:\n     - Periodicity features: `Multiband_period`, `Period_band`.\n     - Amplitude features: `Amplitude`.\n   - Filter features to those with `fid` (filter id) indicating the relevant photometric band (e.g., `fid=1` for g-band, or include all if not specified).\n   - Filter features to the specific feature `version` as needed, or include all versions if not specified.\n\n5. **Apply the specific feature value constraints:**\n   - For the period feature, select objects where the `value` is between 3 and 10 days.\n   - For the amplitude feature, select objects where the `value` exceeds 0.5 mag.\n\n6. **Select the required output columns:**\n   - Object identifier (`oid`).\n   - The probability value for YSO (`probability`).\n   - The feature `value`.\n   - The feature `name`.\n   - The feature `fid` (filter id).\n   - The feature `version`.\n\n7. **Sort the results:**\n   - Order the final list by the probability value in descending order.\n\n8. **Ensure the query returns all relevant features for each object:**\n   - For each object, include the features that meet the criteria, possibly using subqueries or joins to fetch multiple features per object.\n\n9. **Optional:**\n   - If multiple features are associated with a single object, decide whether to return multiple rows per object or aggregate features into a JSON or array structure (depending on the desired output format).\n\n10. **Final step:**\n    - Compose the query with all joins, filters, and sorting, ensuring it adheres to the exact table and column names, and includes all specified conditions.\n\nThis systematic decomposition ensures the query will accurately retrieve objects classified as likely YSOs with periodicity and amplitude constraints, sorted by their likelihood, and including detailed feature information.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "0-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics and identifiers of objects.\n   - The `probability` table, which holds the classification probabilities and rankings.\n   - The `feature` table, which stores various features and their values, names, filter IDs, and versions.\n\n2. **Filter objects based on YSO classification probability:**\n   - Select objects where the classification probability for YSOs ('YSO') exceeds 0.7.\n   - Ensure that the probability is the most likely (ranking = 1) and from the `lc_classifier` classifier.\n\n3. **Join the `object` and `probability` tables:**\n   - Use the object identifier (`oid`) as the join key.\n   - Filter the `probability` table to include only entries with `class_name='YSO'`, `classifier_name='lc_classifier'`, `classifier_version` (any version, unless specified), `ranking=1`, and `probability > 0.7`.\n\n4. **Identify objects with periodicity features:**\n   - From the `feature` table, select features related to periodicity.\n   - Filter features where the `name` indicates a period, such as 'Multiband_period' or other period-related features.\n   - Filter features where the `value` (period) is between 3 and 10 days.\n\n5. **Filter objects based on amplitude of variation:**\n   - From the `feature` table, select features related to amplitude, such as 'Amplitude'.\n   - Filter for features where the `name` is 'Amplitude' and the `value` exceeds 0.5 mag.\n\n6. **Join the `object` table with the `feature` table:**\n   - Use the object identifier (`oid`) to connect objects with their features.\n   - Ensure that the features meet the period and amplitude criteria.\n\n7. **Select the required output columns:**\n   - Object identifier (`oid`).\n   - The probability value for YSO classification.\n   - The feature value (`value`).\n   - The feature name (`name`).\n   - The filter ID (`fid`).\n   - The feature version (`version`).\n\n8. **Sort the results:**\n   - Order the final list by the probability value in descending order.\n\n9. **Ensure the query retrieves only objects that meet all criteria:**\n   - Confirm that the object has a high YSO probability (>0.7).\n   - Confirm that the object has at least one periodicity feature with period between 3 and 10 days.\n   - Confirm that the object has an amplitude feature greater than 0.5 mag.\n\n10. **Optional:**\n    - If multiple features related to period or amplitude exist, decide whether to return all or just the most relevant one.\n    - If multiple period features are present, consider whether to filter for the primary period or include all that meet the criteria.\n\nThis systematic decomposition ensures the query will accurately retrieve objects classified as likely YSOs, exhibiting periodicity within the specified period range, and with significant variation amplitude, sorted by their likelihood.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get objects that are likely to be YSOs (possibility great than 0.7) and with some periodicities. The photometric period is between 3 to 10 days and variation amplitude is great than 0.5 mag. Please sort the list by the possibility in descending order, and return the object identifier, the possibility, value and name of the feature, the filter id, and the feature version.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "38-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and their relationships:**\n   - The primary tables involved are `object`, `probability`, and potentially `detection`.\n   - The `probability` table links objects (`oid`) with classification probabilities, including class names, classifier names, and probabilities.\n   - The `object` table contains object-specific information, including detection counts (`ndet`).\n   - The `detection` table contains individual detection records, which can be used to filter objects based on the number of detections.\n\n2. **Filter the probability table for the specific classifier and class conditions:**\n   - Restrict the `probability` table to entries where `classifier_name='lc_classifier'`.\n   - Filter for class names corresponding to 'AGN' and 'QSO' respectively.\n   - Apply the probability thresholds: greater than 0.6 for AGN candidates and greater than 0.5 for QSO candidates.\n   - Ensure that only the top-ranked probability (`ranking=1`) is considered, as per the default conditions.\n\n3. **Retrieve objects classified as AGN and QSO with the specified probability thresholds:**\n   - For AGN candidates, select objects with `class_name='AGN'` and `probability > 0.6`.\n   - For QSO candidates, select objects with `class_name='QSO'` and `probability > 0.5`.\n   - Use inner joins between `probability` and `object` tables on `oid` to get full object details.\n\n4. **Order the results by probability in descending order:**\n   - For each class (AGN and QSO), order the objects by their probability value, highest first.\n\n5. **Limit the results to the top 1000 objects for each class:**\n   - Use `LIMIT 1000` for both AGN and QSO candidate lists.\n\n6. **Combine the two candidate lists into a single set:**\n   - Use a `UNION ALL` to combine AGN and QSO candidates, maintaining their classification labels.\n\n7. **Filter objects based on the number of detections (`ndet`):**\n   - For each object in the combined list, verify that the number of detections (`ndet`) from the `object` table is between 30 and 200.\n   - This can be done by joining the object list with the `object` table and applying a `WHERE` clause on `ndet`.\n\n8. **Ensure the objects meet the detection count criteria:**\n   - Filter the combined list to include only objects with `ndet >= 30` and `ndet <= 200`.\n\n9. **Order the final list:**\n   - Order the resulting objects by their probability in descending order, or by any other relevant criterion if specified.\n\n10. **Select the desired columns:**\n    - Retrieve all columns from the `object` table for the final output, or specify particular columns if needed.\n    - Optionally, include the classification label ('AGN' or 'QSO') for clarity.\n\n11. **Optimize the query:**\n    - Use appropriate indexes on `oid`, `class_name`, `classifier_name`, `probability`, and `ndet` to ensure efficient filtering and joining.\n    - Confirm that the joins and filters are applied correctly to minimize computational load.\n\n12. **Test the query:**\n    - Verify that the query correctly retrieves the top 1000 AGN and QSO candidates with the specified probability thresholds.\n    - Confirm that all objects in the final result have between 30 and 200 detections.\n\nBy following these steps, you will systematically generate a precise, efficient PostgreSQL query that fulfills the user\u2019s request, ensuring correct filtering, ordering, and selection based on the classification probabilities and detection counts.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query the top 1000 active galactic nuclei and top 1000 quasi\u2013stellar objects candidates ordered by probability in descending order, that have a probability > 0.6 and 0.5 respectively according to the light curve classifier. From those objects obtain the ones that have between 30 and 200 detections both.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "38-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and their relationships:**\n   - The primary tables involved are `object`, `probability`, and potentially `detection`.\n   - The `probability` table links objects (`oid`) with classification probabilities, including class names, classifier names, and probabilities.\n   - The `object` table contains object-specific information, including detection counts (`ndet`).\n   - The `detection` table contains individual detection records, which can be used to filter objects based on the number of detections.\n\n2. **Filter objects based on classification probabilities:**\n   - Focus on the `probability` table where:\n     - `classifier_name` is `'lc_classifier'`.\n     - `ranking` is 1 (to ensure the most probable classification per object).\n     - `probability` exceeds 0.6 for AGN candidates.\n     - `probability` exceeds 0.5 for QSO candidates.\n   - Filter objects that meet these probability thresholds for each class separately.\n\n3. **Identify objects classified as active galactic nuclei (AGN):**\n   - Select objects with `class_name` equal to `'AGN'`.\n   - Ensure their `probability` is greater than 0.6.\n   - Confirm that their `probability` ranking is 1.\n   - Join with the `object` table to retrieve object details.\n\n4. **Identify objects classified as quasi-stellar objects (QSO):**\n   - Select objects with `class_name` equal to `'QSO'`.\n   - Ensure their `probability` is greater than 0.5.\n   - Confirm that their `probability` ranking is 1.\n   - Join with the `object` table to retrieve object details.\n\n5. **Order the AGN and QSO objects by their probability in descending order:**\n   - For each class, order the filtered objects by `probability` descending.\n   - Limit the results to the top 1000 objects per class.\n\n6. **Combine the two sets of objects:**\n   - Use a `UNION ALL` to combine the top 1000 AGN and top 1000 QSO candidates into a single result set.\n\n7. **Filter objects based on the number of detections:**\n   - For each object in the combined set, check the `ndet` value from the `object` table.\n   - Select only objects with `ndet` between 30 and 200 inclusive.\n\n8. **Ensure the objects meet the detection count criteria:**\n   - Use a `WHERE` clause to filter objects based on `ndet` values.\n   - This filtering can be applied after the union, or integrated into the subqueries for efficiency.\n\n9. **Construct the final query:**\n   - Select all columns from the filtered objects, or specific columns as needed.\n   - Include relevant joins to connect `probability` and `object` tables.\n   - Apply the filtering conditions for class, probability thresholds, ranking, and detection counts.\n   - Order the final results as needed, possibly by probability or object ID.\n\n10. **Optional: Optimize the query:**\n    - Use indexes on `probability.oid`, `probability.class_name`, `probability.classifier_name`, `probability.ranking`, and `object.ndet` to improve performance.\n    - Consider using Common Table Expressions (CTEs) for clarity and modularity, especially for the separate class filters.\n\nBy following these steps, you will systematically generate a comprehensive query that retrieves the top 1000 AGN and QSO candidates with the specified probability thresholds, ordered by probability, and filtered by the number of detections.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Query the top 1000 active galactic nuclei and top 1000 quasi\u2013stellar objects candidates ordered by probability in descending order, that have a probability > 0.6 and 0.5 respectively according to the light curve classifier. From those objects obtain the ones that have between 30 and 200 detections both.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "24-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the input sources and their coordinates:**\n   - Define two inline temporary tables (using WITH clause) for the sources:\n     - Source 1: name 'source_1', RA 160.18301441363647, Dec 33.0164673528409\n     - Source 2: name 'source_2', RA 174.21524897555543, Dec 44.83789535222221\n\n2. **Set the spatial filtering criteria:**\n   - Use the Q3C function `q3c_join` to find objects within 10 degrees of each source's coordinates.\n   - For each source, perform a spatial join with the 'object' table, filtering objects that are within 10 degrees of the source's RA and Dec.\n\n3. **Set the temporal filtering criteria:**\n   - The first detection of the objects should be within the first 7 days of February.\n   - Convert the date range to Julian days:\n     - Start date: February 1, 2023 (mjd 59976.0)\n     - End date: February 7, 2023 (mjd 59982.0)\n   - Filter the 'detection' table for objects whose 'mjd' (Modified Julian Date) falls within 59976.0 and 59982.0.\n\n4. **Link the 'object' and 'detection' tables:**\n   - Join 'object' and 'detection' tables on 'oid' to access detection times for each object.\n   - For each object, find the earliest detection ('firstmjd') and ensure it falls within the specified date range.\n\n5. **Combine spatial and temporal filters:**\n   - For each source, select objects that satisfy:\n     - Spatial proximity within 10 degrees (using `q3c_join`)\n     - The object's 'firstmjd' is within the first 7 days of February (between 59976.0 and 59982.0).\n\n6. **Retrieve relevant object information:**\n   - Select all columns from the 'object' table for the filtered objects.\n   - Optionally, include the source name for clarity.\n\n7. **Order and limit the results:**\n   - Order the results by 'firstmjd' ascending to show earliest detections first.\n   - No explicit limit specified, so return all matching objects.\n\n8. **Ensure the query adheres to the default conditions:**\n   - Use only the most probable classification (ranking=1) from the 'probability' table if classification info is needed.\n   - Filter by 'classifier_name'='lc_classifier' if classification details are required.\n   - If classification info is not needed, skip this step.\n\n9. **Optional: Include classification probabilities or types:**\n   - If classification info is desired, join 'probability' with 'object' on 'oid' and filter for 'ranking=1' and 'classifier_name'='lc_classifier'.\n\n10. **Final assembly:**\n    - Combine all the above steps into a coherent query structure, ensuring proper joins, filters, and ordering.\n\nThis systematic decomposition ensures the query will accurately retrieve objects within 10 degrees of the specified sources, detected within the first 7 days of February, with all necessary filters and joins properly applied.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Return a query from ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221) for object within 10 degress of the given positions, and with their first detection the first 7 days of February''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "24-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves objects from the ALeRCE database based on the user's specifications, the following systematic steps should be taken:\n\n1. **Define the set of input sources with their coordinates:**\n   - Create an inline temporary table (using a WITH clause) that includes the source identifiers ('source_1', 'source_2') along with their respective right ascension (RA) and declination (Dec) values.\n   - Assign the provided RA and Dec values to each source within this temporary table for easy reference in subsequent spatial queries.\n\n2. **Set the spatial filtering criteria:**\n   - Use the Q3C extension functions to identify objects within a 10-degree radius of each source's coordinates.\n   - For each source, perform a spatial query that checks whether objects in the 'object' table are within 10 degrees of the source's RA and Dec.\n   - Combine these spatial filters with logical OR to include objects within 10 degrees of either source.\n\n3. **Define the temporal filtering criteria:**\n   - Focus on objects whose first detection (represented by 'firstmjd' in the 'object' table) occurred within the first 7 days of February.\n   - Convert the date range into Julian days (MJDs): \n     - February 1 corresponds to MJD 59976.0\n     - February 7 corresponds to MJD 59982.0\n   - Use a WHERE clause to filter objects with 'firstmjd' >= 59976.0 and 'firstmjd' <= 59982.0.\n\n4. **Combine spatial and temporal filters:**\n   - Use logical AND to ensure that only objects satisfying both the spatial proximity (within 10 degrees of either source) and the temporal window (first detection within the first 7 days of February) are selected.\n\n5. **Select relevant columns:**\n   - Retrieve all columns from the 'object' table to provide comprehensive information about each object.\n   - Optionally, include the source identifier from the temporary table to indicate which source's region the object is associated with.\n\n6. **Order and limit the results:**\n   - Decide whether to order the results by 'firstmjd' or other relevant columns.\n   - Determine if any limit on the number of returned objects is necessary; if not specified, return all matching objects.\n\n7. **Ensure query efficiency:**\n   - Use the appropriate spatial index (via Q3C functions) to optimize the spatial query.\n   - Use indexes on 'firstmjd' for efficient temporal filtering.\n   - Confirm that the query structure leverages these indexes for optimal performance.\n\n8. **Document the query logic:**\n   - Clearly comment on each part of the query to explain the purpose of the spatial and temporal filters.\n   - Note assumptions, such as the use of the Q3C extension and the date conversions.\n\nBy following these steps, the final query will accurately retrieve objects within 10 degrees of the specified sources and with their first detection in the first 7 days of February, ensuring both spatial and temporal constraints are properly applied.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 01 = 59976.0\n-- mjd date for February 07 = 59982.0\nDomain Knowledge: 0\n # User Request: ''Return a query from ('source_1', 160.18301441363647, 33.0164673528409),\n('source_2', 174.21524897555543, 44.83789535222221) for object within 10 degress of the given positions, and with their first detection the first 7 days of February''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the object identifiers (`oid`), mean galactic coordinates (`gal_b`, `gal_l`), and detection date information (`firstmjd`).\n   - The `feature` table, which holds various features associated with each object, linked via `oid`.\n   - The `probability` table, which contains classification probabilities and rankings, linked via `oid`.\n   - The `classification` information is obtained from the `probability` table, filtered by `classifier_name='lc_classifier'` and `ranking=1` to get the most probable class.\n\n2. **Determine the date filtering criteria:**\n   - Convert the date range from user request into MJD:\n     - February 1, 2023 = 59976.0\n     - February 2, 2023 = 59977.0\n   - Filter objects where `firstmjd` is between 59976.0 and 59977.0 inclusive.\n\n3. **Filter objects based on detection date:**\n   - Use the `firstmjd` column in the `object` table to select objects first detected within the specified date range.\n\n4. **Retrieve galactic coordinates:**\n   - Select `gal_b` and `gal_l` columns from the `object` table for the filtered objects.\n\n5. **Retrieve feature columns:**\n   - Identify relevant feature columns needed (the user specifies \"feature columns\" generally, so select all features or specific ones if specified).\n   - Use the `feature` table, filtering by `oid` matching the selected objects.\n\n6. **Retrieve classification information:**\n   - Join with the `probability` table, filtering for:\n     - `classifier_name='lc_classifier'`\n     - `ranking=1` (most probable class)\n   - Select the `class_name` from the `probability` table.\n\n7. **Select object identifiers:**\n   - Include the `oid` from the `object` table as the object identifier.\n\n8. **Combine all data:**\n   - Use appropriate `JOIN` operations:\n     - Join `object` with `probability` on `oid`.\n     - Join `object` with `feature` on `oid`.\n   - Ensure filtering conditions are applied correctly to each join.\n\n9. **Order and structure the output:**\n   - Decide on the output columns:\n     - `gal_b`, `gal_l` (galactic coordinates)\n     - All feature columns (or specific ones if specified)\n     - `class_name` from `probability`\n     - `oid` as object identifier\n   - No specific ordering is requested, but can be ordered by `firstmjd` or `oid` if needed.\n\n10. **Ensure query efficiency:**\n    - Use indexes on `firstmjd`, `oid`, and relevant columns in `probability` and `feature` tables.\n    - Filter early in the query to reduce data volume.\n\n11. **Final validation:**\n    - Confirm that the date filtering matches the specified date range.\n    - Confirm that only objects classified by the light curve classifier (`classifier_name='lc_classifier'`) with the top ranking (`ranking=1`) are included.\n    - Verify that the selected features are relevant and correctly joined.\n\nThis systematic decomposition ensures the query will accurately retrieve the galactic coordinates, features, class name, and object identifiers for objects first detected between February 1 and 2, 2023, classified by the light curve classifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "31-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the object identifiers (`oid`), mean galactic coordinates (`gal_b`, `gal_l`), and detection date information (`firstmjd`).\n   - The `feature` table, which contains various feature columns associated with each object, linked via `oid`.\n   - The `probability` table, which contains classification results, including `class_name`, `oid`, and `classifier_name`.\n   \n2. **Determine the filtering criteria based on detection dates:**\n   - Convert the user-specified date range (February 1-2, 2023) into Julian dates:\n     - February 1, 2023 = 59976.0\n     - February 2, 2023 = 59977.0\n   - Filter objects where `firstmjd` is between 59976.0 and 59977.0 inclusive.\n\n3. **Filter objects classified by the light curve classifier:**\n   - Use the `probability` table to select only entries where:\n     - `classifier_name` = 'lc_classifier'\n     - `ranking` = 1 (most probable classification)\n   - Join `probability` with `object` on `oid` to associate classification with object data.\n   - Filter for `class_name` (e.g., any class, or specific classes if specified; since not specified, include all classes).\n\n4. **Filter for objects classified as most likely by the light curve classifier:**\n   - Ensure the `probability` table's `ranking` is 1, indicating the top classification.\n\n5. **Select the required columns:**\n   - From the `object` table:\n     - `gal_b` (galactic latitude)\n     - `gal_l` (galactic longitude)\n     - `firstmjd` (to confirm detection date)\n   - From the `feature` table:\n     - All feature columns (since the user requests \"feature columns,\" select all features associated with the objects).\n   - From the `probability` table:\n     - `class_name`\n     - `oid` (object identifier)\n\n6. **Construct the join conditions:**\n   - Join `object` with `probability` on `oid`.\n   - Join `feature` with `object` on `oid`.\n\n7. **Apply all filters:**\n   - Date filter on `firstmjd`.\n   - Classifier filter on `classifier_name='lc_classifier'`.\n   - Top rank filter on `ranking=1`.\n\n8. **Order or group the results if necessary:**\n   - No specific ordering requested; can be ordered by `firstmjd` or `oid` if desired.\n\n9. **Ensure the query retrieves all feature columns:**\n   - Use a wildcard or explicitly list all feature columns if known; otherwise, select all from `feature`.\n\n10. **Final step:**\n    - Prepare the query to return the combined data with columns:\n      - `gal_b`, `gal_l`, `firstmjd`, all feature columns, `class_name`, and `oid`.\n\nThis systematic breakdown ensures the query will accurately retrieve the galactic coordinates, features, classification, and object identifiers for objects first detected between February 1 and 2, 2023, classified by the light curve classifier as the most probable class.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for February 1 2023 = 59976.0\n-- mjd date for February 3 2023 = 59978.0\nDomain Knowledge: \n-- The galactic coordinate system locates objects within the Milky Way galaxy by 'latitude' and 'longitude'\n # User Request: ''Write a query in SQL that returns the galactic coordinates, feature columns, class name, and the identifiers of the objects classified by the light curve classifier that were first detected between February 1 and 2 of 2023.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The primary table for object information is the `object` table, which contains object identifiers (`oid`) and their properties.\n   - The `detection` table holds the time-series data, including magnitudes, errors, band identifiers (`fid`), and detection times (`mjd`).\n   - The `probability` table contains classification probabilities, with relevant columns such as `oid`, `class_name`, `classifier_name`, `probability`, and `ranking`.\n\n2. **Filter objects classified as 'SN II' with high probability:**\n   - Use the `probability` table to select entries where:\n     - `class_name` = 'SNII' (matching the classification for Type II supernovae).\n     - `classifier_name` = 'lc_classifier' (to ensure the classification is from the specified classifier).\n     - `probability` > 0.6 (user-defined confidence threshold).\n     - `ranking` = 1 (to select the most probable classification per object).\n   - Join this filtered probability subset with the `object` table on `oid` to retrieve object identifiers.\n\n3. **Restrict objects to the specified date range (2019-2022):**\n   - Use the `mjd` column in the `detection` table.\n   - Filter detections where `mjd` >= 58484.0 and `mjd` <= 59944.0.\n   - Ensure that the objects are within this date range based on their detections.\n\n4. **Identify objects with initial rise rate > 0.5 mag/day in g and r bands:**\n   - For each object, extract detections in bands `fid` = 1 (g-band) and `fid` = 2 (r-band).\n   - Calculate the initial rise rate:\n     - Find the earliest detection time (`mjd`) in each band.\n     - Find the magnitude difference (`magpsf`) between the earliest detection and subsequent detections.\n     - Compute the rate as (magnitude difference) / (time difference in days).\n   - Filter objects where the initial rise rate exceeds 0.5 mag/day in both g and r bands.\n\n5. **Ensure objects have at least 100 days of observations in r-band:**\n   - For each object, identify all detections in `fid` = 2 (r-band).\n   - Calculate the time span as the difference between the maximum and minimum `mjd` in r-band detections.\n   - Filter objects where this span is >= 100 days.\n\n6. **Verify the number of detections in r-band exceeds 30:**\n   - Count the number of detections (`nid`) in `fid` = 2 for each object.\n   - Filter objects with `ndet` > 30 in r-band.\n\n7. **Select relevant detection data:**\n   - For the filtered objects, retrieve:\n     - Object identifier (`oid`).\n     - Candidate identifier (`candid`) from the `detection` table.\n     - Magnitudes (`magpsf`) and magnitude errors (`sigmapsf`).\n     - Band identifier (`fid`), renamed as `f_id`.\n     - Detection time (`mjd`).\n\n8. **Order the results as a function of time:**\n   - Sort the final output by `mjd` in ascending order to reflect the temporal evolution.\n\n9. **Construct nested subqueries and joins:**\n   - Use subqueries to filter objects based on classification probability, rise rate, observation span, and detection count.\n   - Join these subqueries with the `detection` table to retrieve time-series data.\n   - Use inner joins to ensure only objects meeting all criteria are included.\n\n10. **Ensure all conditions are explicitly applied:**\n    - Confirm that the probability filtering, date range, rise rate calculations, observation span, and detection count filters are correctly implemented.\n    - Use appropriate aggregation functions (`MIN`, `MAX`, `COUNT`) for calculating rise rates, observation span, and detection counts.\n\n11. **Final query structure:**\n    - The outermost query should select the object ID, candidate ID, magnitude, magnitude error, band ID (`f_id`), and detection time.\n    - The `WHERE` clause should incorporate all the filters described.\n    - The `ORDER BY` clause should order results by `mjd`.\n\nBy following these steps, the resulting query will accurately retrieve the time-series data of objects classified as SN II in the specified period, with the specified probability and rise rate conditions, along with the required detection details, properly renamed and ordered.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "6-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains object-level information such as object identifiers (`oid`), mean RA/Dec, and other statistics.\n   - The `probability` table, which contains classification probabilities, linked to objects via `oid`.\n   - The `detection` table, which records individual detections with time (`mjd`), magnitudes, errors, band identifiers (`fid`), and detection identifiers (`candid`).\n\n2. **Filter objects classified as 'SN II' with high probability:**\n   - Use the `probability` table to select entries where:\n     - `class_name` = 'SNII' (matching the classification for Type II supernovae).\n     - `classifier_name` = 'lc_classifier' (as per default conditions).\n     - `ranking` = 1 (to select the most probable classification).\n     - `probability` > 0.6 (user-specified confidence threshold).\n   - Join this filtered `probability` subset with the `object` table on `oid` to retrieve object identifiers.\n\n3. **Restrict objects to the specified date range (2019-2022):**\n   - Use the `mjd` date range filter:\n     - `mjd` >= 58484.0 (start of 2019).\n     - `mjd` <= 59944.0 (end of 2022).\n   - This filter will be applied to the `detection` table to select detections within the specified period.\n\n4. **Identify objects with initial rise rate > 0.5 mag/day in g and r bands:**\n   - For each object, analyze the light curve in the g and r bands separately.\n   - Calculate the initial rise rate:\n     - Find the earliest detection(s) in each band.\n     - Compute the difference in magnitude over the difference in time (mjd) between the first detection and subsequent detections.\n     - Ensure the initial rise rate (change in magnitude per day) exceeds 0.5 mag/day.\n   - This step involves:\n     - Sub-querying detections per object and band.\n     - Sorting detections by `mjd`.\n     - Calculating the slope of the initial rise segment.\n   - Filter objects where the initial rise rate exceeds 0.5 mag/day in both g and r bands.\n\n5. **Select objects with at least 100 days of observations in r-band:**\n   - For each object, count the number of detections in the r-band (`fid` corresponding to r-band, e.g., 2).\n   - Filter objects where this count is >= 100.\n\n6. **Select objects with more than 30 detections overall:**\n   - Count total detections per object across all bands.\n   - Filter objects where total detections > 30.\n\n7. **Retrieve detection details for the selected objects:**\n   - For each object passing all filters, extract:\n     - `candid` (candidate/detection identifier).\n     - `mjd` (observation time).\n     - `magpsf` (magnitude).\n     - `sigmapsf` (magnitude error).\n     - `fid` (band identifier, renamed as `f_id`).\n   - Order the detections chronologically (`mjd`) for each object.\n\n8. **Construct the final output:**\n   - For each detection, include:\n     - Object identifier (`oid`).\n     - Detection identifier (`candid`).\n     - Magnitude (`magpsf`).\n     - Magnitude error (`sigmapsf`).\n     - Band identifier (`f_id`).\n     - Observation time (`mjd`).\n   - Present the data as a function of time (`mjd`) for each object.\n\n9. **Additional considerations:**\n   - Use nested sub-queries to handle the calculation of initial rise rates per object and band.\n   - Use `JOIN`s to combine the probability-filtered objects with their detections.\n   - Apply `WHERE` clauses for date range, probability, and rise rate conditions.\n   - Use `GROUP BY` and aggregate functions where necessary to count detections and compute rise rates.\n   - Ensure the `fid` column from `detection` is renamed as `f_id` in the output.\n\n10. **Ensure all default conditions are respected:**\n    - Only consider the most probable classification (`ranking=1`).\n    - Classifier name is `'lc_classifier'`.\n    - Probability threshold is > 0.6.\n    - Use the `object` and `detection` tables efficiently with appropriate indexes.\n\nThis systematic decomposition ensures that the final SQL query will accurately retrieve the requested data, respecting all user-specified constraints and default conditions, and will be optimized for performance by leveraging joins, sub-queries, and filters appropriately.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: \n-- mjd date for the start of the year 2019 = 58484.0\n-- mjd date for the end of the year 2022 = 59944.0\nDomain Knowledge: 0\n # User Request: ''Get the object identifier, candidate identifier, magnitudes, magnitude errors, and band identifiers as a function of time of the objects classified as SN II in the year 2019-2022, with probability larger than 0.6, initial rise rate greater than 0.5 mag/day in ZTF g and r-band, with at least 100 days of observations in r-band and number of detections greater than 30. Rename the fid column from the detection table as f_id.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "21-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query for the ALeRCE database, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics and identifiers for each source.\n   - The `probability` table, which holds the classification probabilities and rankings for each object.\n   - The `feature` table, if needed, to filter or verify features, but in this case, primary filtering is based on classification probabilities and counts.\n\n2. **Determine the filtering criteria based on user request:**\n   - Classification labels: `'AGN'`, `'QSO'`, `'Blazar'` in the `probability` table.\n   - Minimum number of detections: `ndet >= 30` in the `object` table.\n   - Minimum time span between first and last detection: `(lastmjd - firstmjd) >= 200` days in the `object` table.\n   - Predicted class probability higher than 0.5: `probability.probability > 0.5` in the `probability` table.\n   - The classification should be from the `lc_classifier` classifier with the highest ranking (`ranking = 1`).\n\n3. **Establish the join conditions:**\n   - Join the `object` table with the `probability` table on the `oid` field, ensuring the probability corresponds to the object.\n   - Filter the `probability` table to include only entries where `classifier_name='lc_classifier'` and `ranking=1`.\n   - Filter the `probability` table to include only class names `'AGN'`, `'QSO'`, `'Blazar'`.\n   - Filter the `probability` table to include only entries with `probability > 0.5`.\n\n4. **Apply the object-level filters:**\n   - Filter objects with `ndet >= 30`.\n   - Filter objects with `(lastmjd - firstmjd) >= 200`.\n\n5. **Combine all filters:**\n   - Use `WHERE` clauses to enforce the above conditions.\n   - Ensure the join is correctly established to link objects with their classification probabilities.\n\n6. **Select the desired output:**\n   - Retrieve all columns from the `object` table for the sources that meet the criteria.\n   - Optionally, include classification probability and class name from the `probability` table for context.\n\n7. **Order and limit the results:**\n   - Decide if results should be ordered by probability, date, or other criteria.\n   - Limit the number of results if necessary, but this is optional based on user request.\n\n8. **Document the query structure:**\n   - Use clear comments to explain the purpose of each join and filter.\n   - Ensure the query is optimized by using indexes on `oid`, `classifier_name`, `ranking`, and `class_name`.\n\nBy following these steps, the resulting query will accurately retrieve sources classified as `'AGN'`, `'QSO'`, or `'Blazar'` with the specified detection and time span criteria, filtered by a high confidence probability.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Can you do a query to get sources classfied as AGN, QSO or Blazar by the ALeRCE light curve classifier, with a minimum number of detections of 30, and a minimum time span between the first and the last detection of 200 days, and also filtering out sources by a predicted class probability higher than 0.5?''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "21-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics and identifiers for each source.\n   - The `probability` table, which holds the classification probabilities and rankings for each object.\n   - The `feature` table, if needed, to filter sources based on specific features, but in this case, the focus is on classification and detection metrics.\n\n2. **Determine the filtering criteria based on the user request:**\n   - Classification labels: Select sources classified as `'AGN'`, `'QSO'`, or `'Blazar'` according to the `probability` table.\n   - Minimum number of detections: Filter objects with `ndet >= 30`.\n   - Minimum time span between first and last detection: Filter objects with `(lastmjd - firstmjd) >= 200`.\n   - Predicted class probability: Filter objects with `probability > 0.5` for the relevant class.\n\n3. **Set the default conditions for the probability filtering:**\n   - Use only the top-ranked probability (`ranking = 1`) to ensure the most confident classification.\n   - Filter by classifier name: `'lc_classifier'`.\n   - Filter by `class_name` to include only `'AGN'`, `'QSO'`, or `'Blazar'`.\n\n4. **Construct the subquery or join to link objects with their classification probabilities:**\n   - Join the `object` table with the `probability` table on `oid`.\n   - Filter the `probability` table for `classifier_name='lc_classifier'`, `ranking=1`, and `class_name` in the specified set.\n   - Filter the `probability` table for `probability > 0.5`.\n\n5. **Apply the detection and time span filters:**\n   - Filter the `object` table for `ndet >= 30`.\n   - Filter the `object` table for `(lastmjd - firstmjd) >= 200`.\n\n6. **Select the relevant columns:**\n   - Typically, include object identifiers (`oid`), classification label (`class_name`), probability, number of detections (`ndet`), first and last detection times (`firstmjd`, `lastmjd`), and any other relevant statistics.\n\n7. **Order or group the results if necessary:**\n   - Order by probability descending to prioritize the most confident sources.\n   - Or group by object if aggregations are needed, but in this case, a straightforward selection suffices.\n\n8. **Ensure the query is optimized:**\n   - Use indexes on `oid`, `class_name`, `ranking`, and `probability` columns.\n   - Limit the result set if needed for performance.\n\n9. **Document the query logic:**\n   - Clearly specify that the query retrieves sources classified as AGN, QSO, or Blazar with high confidence, sufficient detections, and a significant time span, based on the most probable classification.\n\nThis step-by-step plan ensures the query will accurately and efficiently retrieve the sources matching the user's criteria, respecting the database schema and filtering conditions.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Can you do a query to get sources classfied as AGN, QSO or Blazar by the ALeRCE light curve classifier, with a minimum number of detections of 30, and a minimum time span between the first and the last detection of 200 days, and also filtering out sources by a predicted class probability higher than 0.5?''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "26-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The main table for object information is the `object` table, which contains object-level data such as `oid`, `firstmjd`, `lastmjd`, `ndet`, and other properties.\n   - The classification data is stored in the `probability` table, which links to `object` via `oid` and contains `class_name`, `probability`, and `ranking`.\n   - The detection details are stored in the `detection` table, which includes individual detection records with `oid`, `mjd`, and other detection-specific columns.\n\n2. **Define the date range filter:**\n   - Convert the user-specified date range into Julian date (MJD) range:\n     - August 25, 2022 = 59816.0\n     - September 10, 2022 = 59832.0\n   - Filter objects that appeared (i.e., had detections) within this date range:\n     - Use the `detection` table to find objects with `mjd` between 59816.0 and 59832.0.\n     - Alternatively, if the object\u2019s `firstmjd` or `lastmjd` falls within this range, consider whether to include objects that started or ended within this period.\n\n3. **Filter objects based on detection date:**\n   - Select objects where `firstmjd` is less than or equal to 59832.0 and `lastmjd` is greater than or equal to 59816.0, ensuring the object was active during the date window.\n   - Or, more precisely, find objects with at least one detection (`mjd`) within the date range.\n\n4. **Identify objects classified as supernovae:**\n   - Use the `probability` table to find objects with `class_name='SNIa'` (or other supernova classes if specified) and `classifier_name='lc_classifier'`.\n   - Filter for `probability > 0.5`.\n   - Ensure that only the most probable classification is considered by filtering for `ranking=1`.\n\n5. **Identify objects with more than one detection:**\n   - Use the `object` table\u2019s `ndet` column.\n   - Filter for `ndet > 1`.\n\n6. **Combine the classification and detection filters:**\n   - Use logical operators to select objects that meet either of the following:\n     - Classified as supernova with probability > 0.5.\n     - Or have more than one detection.\n\n7. **Construct the main query:**\n   - Select all columns (`*`) from the `object` table for objects satisfying the above conditions.\n   - Join with the `probability` table to filter by classification and probability criteria.\n   - Optionally, join with the `detection` table if filtering by detection date is more precise than using `firstmjd` and `lastmjd`.\n\n8. **Apply the date filter to detections:**\n   - If filtering based on actual detection dates, join `object` with `detection` on `oid`.\n   - Filter `detection.mjd` between 59816.0 and 59832.0.\n   - Ensure that the object was active during this period.\n\n9. **Order and limit the results:**\n   - Decide whether to order by `firstmjd`, `ndet`, or other relevant columns.\n   - No explicit limit specified, so return all matching objects.\n\n10. **Ensure the query adheres to the default conditions:**\n    - Use `probability.ranking=1`.\n    - Use `probability.classifier_name='lc_classifier'`.\n    - Select all columns unless specified otherwise.\n\n11. **Finalize the query structure:**\n    - Use subqueries or CTEs if needed for clarity, such as defining a temporary set of objects that meet the detection date criteria before filtering by classification or detection count.\n\nBy following these steps, you will systematically generate a comprehensive and accurate PostgreSQL query that retrieves objects appearing within the specified date range, classified as supernovae with high confidence, or with multiple detections, according to the database schema and conditions.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for August 25 2022 = 59816.0\n-- mjd date for September 10 2022 = 59832.0\nDomain Knowledge: 0\n # User Request: ''Query objects which appeared between august 25 and september 10 of 2022, which are classified as supernova by the stamp classifier with a probability greater than 0.5 or which have more than one detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "26-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and their relationships:**\n   - The main table containing object-level information is the `object` table.\n   - The classification information, specifically the stamp classifier's output, is stored in the `probability` table, linked via the `oid` column.\n   - Detection data, including the detection times, are stored in the `detection` table, also linked via the `oid` column.\n   \n2. **Define the temporal filtering criteria:**\n   - Convert the date range from calendar dates to Modified Julian Dates (MJDs):\n     - August 25, 2022 corresponds to MJD 59816.0.\n     - September 10, 2022 corresponds to MJD 59832.0.\n   - Filter objects that have at least one detection with `mjd` between 59816.0 and 59832.0.\n   - To do this efficiently, plan to join the `detection` table with the `object` table on `oid`, applying the date filter on `detection.mjd`.\n\n3. **Filter objects based on their appearance within the date range:**\n   - Use the `detection` table to identify objects with at least one detection within the specified MJDs.\n   - Alternatively, if the `object` table has a `firstmjd` and `lastmjd`, check if these overlap with the date range, but since the user specifies appearance \"between\" these dates, it's more precise to filter detections directly.\n\n4. **Apply classification filter for supernovae:**\n   - The `probability` table contains classification probabilities.\n   - Filter for entries where:\n     - `classifier_name` = 'stamp_classifier'\n     - `class_name` = 'SN' (assuming 'SN' is the class name for supernovae in the database; if not, verify the exact class name in the schema)\n     - `probability` > 0.5\n     - `ranking` = 1 (to ensure the most probable classification)\n   - Join this filtered `probability` data with the `object` table via `oid`.\n\n5. **Filter objects with more than one detection:**\n   - Use the `ndet` column in the `object` table.\n   - Select objects where `ndet` > 1.\n\n6. **Combine the filters:**\n   - Use logical operators to combine:\n     - Objects that have at least one detection within the date range.\n     - Objects classified as supernovae with probability > 0.5.\n     - Or objects with more than one detection, regardless of classification.\n\n7. **Construct the final query:**\n   - Select all columns from the `object` table (or specific columns if needed).\n   - Join with the `probability` table filtered for supernova classification.\n   - Join with the `detection` table to filter by detection date.\n   - Use `WHERE` clauses to enforce all conditions.\n   - Ensure that the classification filter applies only to the most probable classification (`ranking`=1).\n\n8. **Optimize the query:**\n   - Use indexes on `object.oid`, `probability.oid`, and `detection.oid` for efficient joins.\n   - Use subqueries or CTEs if necessary to improve readability and performance.\n\n9. **Final considerations:**\n   - Confirm the exact class name for supernovae in the `probability` table (`'SN'` or other).\n   - Ensure that the date filtering on `detection.mjd` is correctly applied.\n   - Verify that the `probability` table's `ranking` filter is used to select the most probable classification.\n\nThis step-by-step decomposition ensures that the query will accurately retrieve objects that appeared within the specified date range, are classified as supernovae with high confidence, or have multiple detections, fulfilling the user\u2019s request comprehensively.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: -- mjd date for August 25 2022 = 59816.0\n-- mjd date for September 10 2022 = 59832.0\nDomain Knowledge: 0\n # User Request: ''Query objects which appeared between august 25 and september 10 of 2022, which are classified as supernova by the stamp classifier with a probability greater than 0.5 or which have more than one detection''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the ZTF object identifiers (`oid`), number of detections (`ndet`), and detection date information (`lastmjd`, `firstmjd`).\n   - The `feature` table, which stores features like `LinearTrend` associated with each object, including the feature value and filter identifier (`fid`).\n   - The `probability` table, which contains the classification results, including classifier name, version, class, probability, and ranking.\n\n2. **Apply initial filters based on object properties:**\n   - Filter objects where the difference between `lastmjd` and `firstmjd` is greater than 1 day.\n   - This involves calculating `lastmjd - firstmjd` and applying a `WHERE` condition to select only those objects.\n\n3. **Join the `object` table with the `feature` table:**\n   - Use the `oid` as the key to join these tables.\n   - Filter the `feature` table to include only entries where `name` is `'LinearTrend'`.\n   - Also, filter for features where the `value` exceeds 5.\n   - Include the `fid` (filter identifier) in the selection.\n\n4. **Join with the `probability` table to get classification info:**\n   - Join on `oid` to associate each object with its classification results.\n   - Filter the `probability` table to include only entries where `classifier_name` is `'lc_classifier'` and `ranking` is 1 (most probable class).\n   - Retrieve the `classifier_version`, `class_name`, and `probability`.\n\n5. **Limit the number of results:**\n   - Use a `LIMIT` clause to restrict the output to at most 10 cases.\n\n6. **Select the required columns:**\n   - From the `object` table: the ZTF identifier (`oid`) and number of detections (`ndet`).\n   - From the classification data: `classifier_version`, `class_name`, and `probability`.\n   - From the `feature` table: `value` (for `LinearTrend`) and `fid` (filter identifier).\n\n7. **Order the results (optional but recommended):**\n   - To ensure consistent output, order by `LinearTrend` value descending or by `probability` descending, depending on preference.\n\n8. **Document the query structure:**\n   - Use subqueries or joins as appropriate to combine the data efficiently.\n   - Ensure all filters are correctly applied to meet the user criteria.\n\nThis systematic breakdown ensures the query will accurately retrieve up to 10 objects with `LinearTrend` > 5, a detection span > 1 day, along with their classification and feature details, following the database schema and conditions provided.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "109-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the ZTF object identifiers (`oid`), number of detections (`ndet`), and detection date information (`lastmjd`, `firstmjd`).\n   - The `feature` table, which stores features like `LinearTrend` associated with each object, including the feature value and filter identifier (`fid`).\n   - The `probability` table, which contains the classification results, including classifier name, version, class, probability, and ranking.\n\n2. **Apply initial filters based on object properties:**\n   - Filter objects where the difference between `lastmjd` and `firstmjd` exceeds 1 day. This involves calculating `lastmjd - firstmjd` and applying a condition to select only those objects.\n   - Limit the number of results to at most 10, which can be achieved by applying a `LIMIT 10` clause after sorting.\n\n3. **Join the relevant tables:**\n   - Join the `object` table with the `feature` table on the common `oid` to access the `LinearTrend` feature for each object.\n   - Join the resulting set with the `probability` table on `oid` to retrieve the classification data.\n   - Filter the `probability` table to include only entries where `ranking = 1` and `classifier_name='lc_classifier'` to get the most probable classification per object.\n\n4. **Filter objects based on the feature 'LinearTrend':**\n   - In the `feature` table, filter for entries where `name='LinearTrend'`.\n   - Further filter for feature values where `value > 5`.\n\n5. **Select the required columns:**\n   - From the `object` table: the ZTF identifier (`oid`) and the number of detections (`ndet`).\n   - From the `probability` table: the classifier version (`classifier_version`), class (`class_name`), and probability (`probability`).\n   - From the `feature` table: the feature value (`value`) and filter identifier (`fid`).\n\n6. **Order and limit the results:**\n   - Order the results by the feature value (`LinearTrend`) in descending order to prioritize the largest values.\n   - Limit the output to at most 10 entries.\n\n7. **Ensure the query adheres to the default conditions:**\n   - Use only the most probable classification (`ranking=1`).\n   - Use the classifier `'lc_classifier'` unless specified otherwise.\n\n8. **Optional: Add comments or documentation within the query for clarity.**\n\nBy following these steps, the query will efficiently retrieve up to 10 objects with `LinearTrend > 5`, a detection span greater than 1 day, along with their classification and feature details, fulfilling the user request accurately.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 10 cases where the feature called 'LinearTrend' is larger than 5 and their ZTF objects have a difference between last and first detection date larger than 1 day. Return the following columns. For the ZTF objects: ZTF identifier and number of detections; for their light curve classifier data at ranking 1: classifier version, class and probability; for the 'LinearTrend' feature: value and filter identifier''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "49-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all rows from the 'feature' table for specific objects with features in the g band, follow these detailed steps:\n\n1. **Identify the target objects:**\n   - Specify the list of ZTF identifiers provided by the user: 'ZTF20abywohm' and 'ZTF20abxgxjd'.\n   - These identifiers will be used to filter the 'object' table, which contains the object identifiers ('oid').\n\n2. **Determine the relationship between tables:**\n   - Recognize that the 'feature' table references the 'object' table via the 'oid' column.\n   - The 'object' table (not explicitly described but implied) contains the 'oid' and the ZTF identifier, likely in a column such as 'oid' or a similar identifier.\n\n3. **Locate the column with ZTF identifiers:**\n   - Confirm the exact column name in the 'object' table that stores the ZTF identifier (e.g., 'oid' or another name). Assume it is 'oid' for this context.\n   - Use this column to filter objects matching the specified ZTF IDs.\n\n4. **Filter for features in the g band:**\n   - The 'feature' table has a 'fid' column indicating the bandpass.\n   - Identify the value of 'fid' that corresponds to the g band. Based on the provided feature descriptions, 'fid' = 1 corresponds to the g band.\n\n5. **Construct the filtering condition:**\n   - Filter the 'feature' table to include only rows where:\n     - The 'oid' matches objects with the specified ZTF identifiers.\n     - The 'fid' equals 1 (g band).\n\n6. **Combine the filters:**\n   - Use a sub-query or a join to select the 'oid's of objects with the specified ZTF IDs.\n   - Filter the 'feature' table to include only rows with those 'oid's and 'fid' = 1.\n\n7. **Select all relevant data:**\n   - Retrieve all columns from the 'feature' table for the filtered objects, as the user requests all feature rows in the g band for these objects.\n\n8. **Ensure query efficiency and correctness:**\n   - Use an `IN` clause or an `INNER JOIN` to filter the objects efficiently.\n   - Confirm that the filtering is precise and only includes the specified objects and features in the g band.\n\n9. **Document the filtering logic:**\n   - Clearly specify that the filtering is based on the object identifiers matching the provided ZTF IDs.\n   - Confirm that only features with 'fid' = 1 are included, corresponding to the g band.\n\nBy following these steps, the resulting query will accurately retrieve all feature rows in the g band for the objects with the specified ZTF identifiers.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abywohm' and 'ZTF20abxgxjd', get all rows from the 'feature' table that provide a feature in the g band''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "93-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all columns from the 'probability' and 'magstat' tables for ZTF objects meeting the specified conditions, follow these detailed steps:\n\n1. **Identify the Relevant Tables and Relationships:**\n   - Recognize that the 'probability' table contains classification probabilities for objects, linked via the 'oid' column.\n   - The 'magstat' table contains statistical light curve data, also linked via the 'oid' column.\n   - The 'object' table (not explicitly described but implied) likely contains object identifiers and coordinates, which may be useful if spatial filtering is needed, but in this case, focus on classification and light curve conditions.\n\n2. **Apply the Classification Conditions:**\n   - Filter the 'probability' table to include only entries where:\n     - The 'class_name' is 'asteroid'.\n     - The 'ranking' is 1, indicating the 'asteroid' class is the top-ranked classification for that object.\n     - The 'classifier_name' is 'stamp_classifier', to ensure the classification is from the stamp-based classifier.\n   - This involves adding a WHERE clause with these conditions.\n\n3. **Filter for Corrected Light Curves:**\n   - In the 'magstat' table, filter for objects where:\n     - The 'corrected' column is TRUE, indicating the light curve has been corrected.\n   - This involves adding a WHERE clause for 'corrected = TRUE'.\n\n4. **Join the 'probability' and 'magstat' Tables:**\n   - Use an INNER JOIN on the 'oid' column to combine the classification probabilities with the light curve statistics for each object.\n   - This ensures that only objects satisfying both the classification and light curve conditions are included.\n\n5. **Select All Columns:**\n   - Retrieve all columns from both tables, which can be achieved by selecting all columns from each table explicitly or using a wildcard if supported.\n   - Ensure that the resulting dataset includes all relevant information from both tables.\n\n6. **Limit the Number of Results:**\n   - Use a LIMIT clause to restrict the output to at most 10 rows.\n   - This helps in managing the result size and focusing on a sample.\n\n7. **Order the Results:**\n   - Order the final results by the 'oid' column from the 'probability' table.\n   - This provides a consistent and meaningful ordering based on object identifiers.\n\n8. **Construct the Final Query Structure:**\n   - The query should be a SELECT statement with the specified columns, FROM clause with the join, WHERE conditions, ORDER BY clause, and LIMIT clause.\n   - Ensure all conditions are correctly specified and the syntax is valid.\n\n9. **Verify the Query Logic:**\n   - Confirm that the filters correctly reflect the user's request.\n   - Check that the join is appropriate and that no necessary conditions are omitted.\n   - Ensure the ordering and limit are correctly applied.\n\nBy following these steps, you will systematically build a query that accurately retrieves the desired data, respecting the classification hierarchy, light curve correction status, and result constraints.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all columns from the 'probability' and 'magstat' tables for ZTF objects that satisfy the following conditions: the 'asteroid' class is first ranked in the stamp classifier, and have a computed corrected light curve. Give at most 10 rows in the resulting table. Order the results by the object identifier from the probability table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "93-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all columns from the 'probability' and 'magstat' tables for ZTF objects meeting the specified conditions, follow these detailed steps:\n\n1. **Identify the Relevant Tables and Relationships:**\n   - Recognize that the 'probability' table contains classification probabilities for objects, linked via the 'oid' column.\n   - The 'magstat' table contains statistical light curve data, also linked via the 'oid' column.\n   - The 'object' table (not explicitly described but implied) likely contains object identifiers and coordinates, which may be useful if spatial filtering is needed, but in this case, focus on classification and light curve conditions.\n\n2. **Apply the Classification Conditions:**\n   - Filter the 'probability' table to include only entries where:\n     - 'class_name' is 'asteroid'.\n     - 'ranking' is 1, indicating the first-ranked (most probable) classification.\n     - 'classifier_name' is 'stamp_classifier', to ensure the classification is from the stamp-based classifier.\n   - This involves adding a WHERE clause with these conditions.\n\n3. **Ensure the Object Has a Corrected Light Curve:**\n   - In the 'magstat' table, filter for objects where:\n     - 'corrected' is TRUE, indicating the light curve has been corrected.\n   - This involves adding a WHERE clause for 'corrected' = TRUE.\n\n4. **Join the 'probability' and 'magstat' Tables:**\n   - Use an INNER JOIN on the 'oid' column to combine data from both tables for objects that satisfy both conditions.\n   - This ensures only objects with both classification and light curve data are included.\n\n5. **Select All Columns:**\n   - Retrieve all columns from both tables, which can be achieved by selecting all columns from each table explicitly or using a wildcard if supported.\n   - Since the user requests all columns from both tables, specify the columns accordingly.\n\n6. **Limit the Number of Results:**\n   - Use a LIMIT clause to restrict the output to at most 10 rows.\n   - This helps in managing the result size and aligns with the user request.\n\n7. **Order the Results:**\n   - Order the final result set by the 'oid' column from the 'probability' table.\n   - This ensures the results are sorted based on object identifiers.\n\n8. **Construct the Final Query Structure:**\n   - The query should be a SELECT statement with the specified columns, FROM clause with a JOIN, WHERE conditions, ORDER BY, and LIMIT.\n   - Ensure the syntax is correct and all conditions are properly combined.\n\n9. **Optional: Verify the Existence of Data:**\n   - Confirm that the 'probability' table contains entries with 'class_name'='asteroid', 'ranking'=1, and 'classifier_name'='stamp_classifier'.\n   - Confirm that the 'magstat' table has entries with 'corrected'=TRUE for the same 'oid's.\n\n10. **Test the Query:**\n    - Run the query on a sample dataset or in a test environment to ensure it returns the expected results and performs efficiently.\n\nBy following these steps, you will systematically construct a precise and efficient query that retrieves all relevant data for ZTF objects classified as 'asteroid' with the highest probability, which also have corrected light curves, limited to 10 results, ordered by object identifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get all columns from the 'probability' and 'magstat' tables for ZTF objects that satisfy the following conditions: the 'asteroid' class is first ranked in the stamp classifier, and have a computed corrected light curve. Give at most 10 rows in the resulting table. Order the results by the object identifier from the probability table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate the PostgreSQL query that fulfills the user request, follow these detailed steps:\n\n1. **Identify the target ZTF objects:**\n   - Specify the two ZTF object identifiers ('ZTF19aazhdoy' and 'ZTF17aaaqqtd') as a temporary inline table or CTE (Common Table Expression) with columns for object identifiers and their associated RA and Dec coordinates if available.\n   - Since the user request does not specify coordinates, focus on the object identifiers for filtering.\n\n2. **Retrieve the 'xmatch' entries for these objects:**\n   - Filter the 'xmatch' table to include only rows where the 'oid' matches either of the two specified ZTF object identifiers.\n   - This will give all catalog matches related to these objects, including the catalog object identifiers, distances, and class information.\n\n3. **Identify the relevant features ('W1-W2', 'g-W2', 'r-W2') with specific version:**\n   - Filter the 'feature' table to select rows where:\n     - 'name' is one of ('W1-W2', 'g-W2', 'r-W2').\n     - 'version' equals 'lc_classifier_1.2.1-P'.\n     - 'oid' matches the ZTF objects of interest.\n   - This ensures only the specified features and version are retrieved for these objects.\n\n4. **Join the features with the ZTF objects:**\n   - Join the filtered 'feature' table with the inline table of ZTF object identifiers to associate each feature with the corresponding object.\n   - This allows pairing each feature with its respective object.\n\n5. **Join the features with the 'xmatch' table:**\n   - Join the features' data with the 'xmatch' table on the 'oid' field to include match information such as catalog object identifier, distance, and class.\n   - This will produce a combined dataset with object identifiers, match details, feature names, and feature values.\n\n6. **Select and organize the output columns:**\n   - Include in the final output:\n     - The ZTF object identifier ('oid').\n     - The catalog object identifier ('catid' or 'oid_catalog' from 'xmatch').\n     - The distance between counterparts ('dist').\n     - The feature name ('name').\n     - The feature value ('value').\n\n7. **Sort the results:**\n   - Order the final result set by:\n     - The catalog object identifier ('catid' or 'oid_catalog').\n     - The feature name ('name').\n\n8. **Ensure the query returns all relevant data:**\n   - Use 'SELECT *' or specify all necessary columns explicitly.\n   - Confirm that the join conditions are correct and that the filtering criteria are applied properly.\n\n9. **Test the query:**\n   - Verify that the query correctly filters for the specified objects, features, and version.\n   - Check that the join produces the expected combined dataset with all required columns.\n\nBy following these steps, you will systematically construct a query that retrieves all matches and specified features for the given ZTF objects, joined with match details, and sorted as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "95-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate the PostgreSQL query that retrieves the requested information, follow these detailed steps:\n\n1. **Identify the target ZTF objects:**\n   - Specify the two ZTF object identifiers ('ZTF19aazhdoy' and 'ZTF17aaaqqtd') as a temporary inline table or CTE (Common Table Expression) with columns for object identifiers and their associated coordinates if needed.\n   - Since the user request does not specify coordinates, focus on the object identifiers for filtering.\n\n2. **Retrieve the 'xmatch' entries for these objects:**\n   - Filter the 'xmatch' table to include only rows where the 'oid' matches either 'ZTF19aazhdoy' or 'ZTF17aaaqqtd'.\n   - This will give all catalog matches associated with these specific ZTF objects.\n   - Extract relevant columns: 'oid' (ZTF object ID), 'catid' (catalog object ID), 'dist' (distance to the catalog object), and any other relevant match information.\n\n3. **Identify the features 'W1-W2', 'g-W2', and 'r-W2' for these objects:**\n   - Filter the 'feature' table to include only rows where:\n     - 'oid' matches either of the two ZTF object identifiers.\n     - 'name' is one of the specified features: 'W1-W2', 'g-W2', 'r-W2'.\n     - 'version' is exactly 'lc_classifier_1.2.1-P'.\n   - This will give the feature values for each object and feature name.\n\n4. **Join the match data with the feature data:**\n   - Perform an inner join between the filtered 'xmatch' results and the filtered 'feature' results on the 'oid' (ZTF object ID).\n   - This will combine the match information with the feature values for each object.\n\n5. **Select and organize the output columns:**\n   - Include in the final output:\n     - The ZTF object identifier ('oid').\n     - The catalog object identifier ('catid').\n     - The distance between counterparts ('dist').\n     - The feature name ('name').\n     - The feature value ('value').\n\n6. **Sort the final results:**\n   - Order the results by the catalog object identifier ('catid') and then by the feature name ('name').\n\n7. **Ensure the query is comprehensive:**\n   - Use 'SELECT *' or explicitly specify all necessary columns.\n   - Confirm that only the features with the specified version are included.\n   - Make sure to filter the 'xmatch' table for the two specific ZTF objects.\n\n8. **Optional:**\n   - If needed, include the ZTF object identifiers explicitly in the output for clarity.\n   - Confirm that the join keys are correctly aligned and that the filtering conditions are precise.\n\nBy following these steps, the resulting query will efficiently retrieve and join the match and feature data for the specified objects, sorted as requested, and include all relevant columns.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF19aazhdoy' and 'ZTF17aaaqqtd', find 1) all matches in the 'xmatch' table, and 2) features 'W1-W2', 'g-W2' and 'r-W2' in their 'lc_classifier_1.2.1-P' version. Return these results as a joined table that includes the following columns, sort by catalog object identifier and feature name: identifier in ZTF and in the catalog, distance between counterparts, and feature name and value''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all detections for the ZTF object 'ZTF20actqnhg' with the specified columns, and sorts the results by detection date, follow these detailed steps:\n\n1. **Identify the main object of interest:**\n   - Use the 'object' table to locate the object with the specific identifier 'ZTF20actqnhg'.\n   - Filter the 'object' table to find the row where the 'oid' column matches this object ID.\n\n2. **Retrieve associated detections:**\n   - Use the 'detection' table, which contains individual detection records linked to objects via the 'oid' column.\n   - Filter the 'detection' table to include only records where 'oid' matches the object identified in step 1.\n\n3. **Select the required detection columns:**\n   - From the 'detection' table, select:\n     - 'mjd' as detection date.\n     - 'isdiffpos' flag indicating whether the difference image detection is positive.\n     - 'magpsf' as the difference magnitude.\n     - 'sigmapsf' as the uncertainty of the difference magnitude.\n\n4. **Join detection data with data quality information:**\n   - Use the 'candid' column in 'detection' to join with the 'candid' primary key in the 'dataquality' table.\n   - This join will allow retrieval of all columns from 'dataquality' for each detection epoch.\n\n5. **Retrieve all columns from 'dataquality':**\n   - Select all columns from the 'dataquality' table for each matching detection epoch.\n\n6. **Order the results:**\n   - Sort the combined results by the detection date ('mjd') in ascending order.\n\n7. **Ensure the query is efficient and accurate:**\n   - Use appropriate filtering conditions.\n   - Use exact table and column names.\n   - Maintain the join integrity to match each detection with its data quality record.\n\n8. **Optional:**\n   - If needed, explicitly specify the columns from 'dataquality' instead of selecting all, to improve clarity or performance.\n   - Confirm that the join is on the correct key ('candid') and that the 'candid' in 'detection' corresponds to the 'candid' in 'dataquality'.\n\nBy following these steps, the resulting query will accurately retrieve all detections for the specified object, including the requested detection details and all associated data quality metrics, sorted by detection date.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "85-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all detections for the ZTF object 'ZTF20actqnhg' with specific columns and sorts by detection date, follow these detailed steps:\n\n1. **Identify the main object of interest:**\n   - Use the 'object' table to locate the row corresponding to the object with the identifier 'ZTF20actqnhg'.\n   - Filter the 'object' table by the 'oid' column to select this specific object.\n\n2. **Retrieve detection records for the object:**\n   - Use the 'detection' table, which contains individual detection records linked to objects via the 'oid' column.\n   - Filter the 'detection' table where 'oid' matches the object identified in step 1.\n\n3. **Select the required detection columns:**\n   - From the 'detection' table, select:\n     - 'mjd' as the detection date.\n     - 'isdiffpos' flag indicating whether the difference image detection is positive.\n     - 'magpsf' as the difference magnitude.\n     - 'sigmapsf' as the uncertainty of the difference magnitude.\n\n4. **Join detection records with the object table:**\n   - Perform an INNER JOIN between 'detection' and 'object' on the 'oid' column to ensure all detection data is correctly associated with the object.\n\n5. **Retrieve all columns from the 'dataquality' table for each detection epoch:**\n   - Use the 'candid' column from 'detection' to join with 'dataquality' on the 'candid' column.\n   - Filter 'dataquality' records where 'candid' matches the detection's 'candid'.\n   - Select all columns from 'dataquality' for each matching detection.\n\n6. **Order the results:**\n   - Sort the combined results by 'mjd' (detection date) in ascending order to meet the requirement of sorting by detection date.\n\n7. **Ensure the query is efficient and accurate:**\n   - Use precise JOIN conditions.\n   - Select only necessary columns to optimize performance.\n   - Confirm that the filtering by 'oid' is correctly applied to limit the dataset to the specified object.\n\n8. **Optional:**\n   - If needed, include the 'oid' in the SELECT statement for clarity.\n   - Verify that the 'candid' values are correctly matched between 'detection' and 'dataquality'.\n\nBy following these steps, the resulting query will accurately retrieve all detections for 'ZTF20actqnhg', including the specified columns, with associated data quality information, sorted by detection date.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all detections for the ZTF object 'ZTF20actqnhg'. Return the following columns sort by detection date: detection date, isdiffpos flag, difference magnitude and its uncertainty, and all columns from the 'dataquality' table for the corresponding epochs for this object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves up to 200 distinct ZTF objects with a high probability (>0.7) of being a QSO according to the light curve classifier, and to return all columns from the 'xmatch' and 'allwise' tables for these objects, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The 'probability' table contains classification probabilities, linked to objects via 'oid'.\n   - The 'object' table contains object identifiers ('oid') and other object properties.\n   - The 'xmatch' table links objects ('oid') to external catalog matches, including cross-matched catalog IDs and positional data.\n   - The 'allwise' table provides infrared data for objects, linked via 'oid_catalog' which corresponds to 'oid' in 'xmatch'.\n\n2. **Filter the 'probability' table:**\n   - Select entries where 'classifier_name' is 'lc_classifier' to ensure probabilities are from the light curve classifier.\n   - Filter for 'ranking' equal to 1 to get the most probable classification per object.\n   - Filter for 'probability' greater than 0.7 to meet the probability threshold.\n   - Filter for 'class_name' equal to 'QSO' to select quasars.\n   \n3. **Join 'probability' with 'object' table:**\n   - Use 'oid' to connect 'probability' entries with their corresponding objects in the 'object' table.\n   - This allows access to object details if needed, although the user requests only data from 'xmatch' and 'allwise'.\n\n4. **Select distinct objects:**\n   - Ensure the query returns at most 200 unique objects by applying a 'LIMIT 200' clause.\n   - Use 'DISTINCT' on 'oid' to avoid duplicates if multiple probability entries exist per object.\n\n5. **Retrieve associated 'xmatch' and 'allwise' data:**\n   - For each selected object ('oid'), join with 'xmatch' on 'oid' to get cross-matching information.\n   - Join with 'allwise' on 'oid_catalog' matching 'oid' to get infrared data.\n   - Since 'xmatch' and 'allwise' may have multiple entries per object, decide whether to:\n     - Retrieve all matching entries (if multiple exist), or\n     - Limit to the most relevant match (e.g., closest match). The user does not specify, so retrieve all.\n\n6. **Construct the query structure:**\n   - Use subqueries or Common Table Expressions (CTEs) to organize the filtering and joins.\n   - First, filter the 'probability' table for the desired objects.\n   - Then, join with 'xmatch' and 'allwise' to get the full data for these objects.\n   - Limit the total number of objects to 200.\n\n7. **Order the results:**\n   - Optionally, order by the probability in descending order to prioritize the most confident QSO classifications.\n\n8. **Ensure all columns from 'xmatch' and 'allwise' are included:**\n   - Use 'SELECT *' for 'xmatch' and 'allwise' tables to return all their columns for each object.\n\n9. **Final considerations:**\n   - Confirm that the join keys are correctly used: 'oid' in 'xmatch' and 'object', 'oid_catalog' in 'allwise' and 'xmatch'.\n   - Be aware of potential multiple entries per object in 'xmatch' and 'allwise'; the query will return all such entries unless further filtering is applied.\n\nBy following these steps, the resulting query will efficiently identify up to 200 ZTF objects with high QSO probability, and retrieve all relevant cross-matching and infrared data for each.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "98-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves up to 200 distinct ZTF objects with a high probability (>0.7) of being a QSO according to the light curve classifier, and to return all columns from the 'xmatch' and 'allwise' tables for these objects, follow these detailed steps:\n\n1. **Identify the relevant classification data:**\n   - Use the 'probability' table to find objects classified as 'QSO' by the 'lc_classifier'.\n   - Filter the 'probability' table to include only entries where:\n     - 'classifier_name' equals 'lc_classifier'.\n     - 'probability' exceeds 0.7.\n     - 'ranking' equals 1 (to ensure the most probable classification per object).\n   - Select only the 'oid' (object identifier) for these entries.\n\n2. **Ensure distinct objects:**\n   - Since multiple entries might exist for the same object, use `DISTINCT` on 'oid' to get unique object identifiers.\n   - Limit the number of objects to 200 using `LIMIT 200`.\n\n3. **Retrieve object identifiers for filtering:**\n   - Store the list of selected 'oid's in a subquery or a Common Table Expression (CTE) for clarity and reusability.\n\n4. **Join with 'xmatch' table:**\n   - Use the list of 'oid's to filter the 'xmatch' table.\n   - Retrieve all columns from 'xmatch' for these objects.\n\n5. **Join with 'allwise' table:**\n   - Similarly, filter the 'allwise' table using the same list of 'oid's.\n   - Retrieve all columns from 'allwise' for these objects.\n\n6. **Combine the results:**\n   - Since the user requests all columns from both 'xmatch' and 'allwise' tables for these objects, consider whether to:\n     - Return separate result sets for each table, or\n     - Combine the data into a single result set with appropriate joins or unions if relevant.\n   - Given the request, it is most straightforward to produce two separate result sets or a combined query that joins 'xmatch' and 'allwise' on 'oid' if appropriate.\n\n7. **Order the results:**\n   - No specific ordering is specified, but for consistency, order by 'oid' or any relevant column if needed.\n\n8. **Limit the total number of objects:**\n   - Ensure the initial selection of 'oid's is limited to 200, so the subsequent joins only include these objects.\n\n9. **Ensure all columns are selected:**\n   - Use `SELECT *` for 'xmatch' and 'allwise' tables to return all columns.\n\n10. **Final query structure:**\n    - Use a CTE or subquery to select the top 200 'oid's based on the probability criteria.\n    - Join this set with 'xmatch' and 'allwise' tables to retrieve all relevant data.\n\nBy following these steps, the query will efficiently identify the objects with high QSO probability, limit the number to 200, and retrieve all associated data from the specified tables.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 200 distinct ZTF objects that have a probability larger than 0.7 of being a QSO in the light curve classifier. Return all columns from the 'xmatch' and 'allwise' tables for such objects''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The main tables involved are `probability` and `gaia_ztf`.\n   - The `probability` table contains classification probabilities, with columns: `oid`, `class_name`, `classifier_name`, `classifier_version`, `probability`, and others.\n   - The `gaia_ztf` table contains information about Gaia sources related to the objects, with columns: `oid`, `candid`, `neargaia`, `neargaiabright`, `maggaia`, `maggaiabright`, `unique1`, and others.\n\n2. **Determine the filtering criteria based on user request:**\n   - The probability of the object being either a Long Period Variable (LPV) or an Eclipsing Binary (E) should be greater than 0.7.\n   - The classification must be from the `lc_classifier` with `classifier_version='hierarchical_rf_1.1.0'`.\n   - The class names of interest are `'LPV'` and `'E'`.\n   - The Gaia object associated with each object must have `unique1` set to `TRUE`, indicating it has not changed since the first alert.\n\n3. **Apply default conditions for the probability table:**\n   - Filter `probability` entries where `ranking=1` to get the most probable classification.\n   - Filter `probability` entries where `classifier_name='lc_classifier'`.\n   - Filter `probability` entries where `classifier_version='hierarchical_rf_1.1.0'`.\n\n4. **Construct the filtering logic for class probabilities:**\n   - Select objects where the probability of being `'LPV'` or `'E'` exceeds 0.7.\n   - This involves creating a condition that checks if `class_name='LPV'` or `class_name='E'` and `probability > 0.7`.\n\n5. **Join the `probability` and `gaia_ztf` tables:**\n   - Use the `oid` column as the key to join these tables, ensuring each object\u2019s Gaia information is associated with its classification probability.\n\n6. **Add the condition for Gaia objects:**\n   - Filter for `gaia_ztf.unique1=TRUE` to ensure the Gaia source has not changed since the first alert.\n\n7. **Limit the number of results:**\n   - Restrict the output to at most 50 rows using a `LIMIT` clause.\n\n8. **Select all columns from both tables:**\n   - Use `SELECT *` to retrieve all columns from `probability` and `gaia_ztf` for the filtered objects.\n\n9. **Order the results (optional but recommended):**\n   - To ensure consistent results, order by `probability` descending or any relevant column, if desired.\n\n10. **Summarize the query structure:**\n    - The query will involve a `JOIN` between `probability` and `gaia_ztf` on `oid`.\n    - The `WHERE` clause will include:\n      - `probability.ranking=1`\n      - `probability.classifier_name='lc_classifier'`\n      - `probability.classifier_version='hierarchical_rf_1.1.0'`\n      - `probability.class_name IN ('LPV', 'E')`\n      - `probability.probability > 0.7`\n      - `gaia_ztf.unique1=TRUE`\n    - The result will be limited to 50 rows.\n\nThis systematic breakdown ensures the query will accurately retrieve the desired objects with the specified conditions, using the correct tables, columns, and filtering logic.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "87-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into steps for generating the PostgreSQL query, follow this detailed plan:\n\n1. **Identify the relevant tables and columns:**\n   - The 'probability' table contains classification probabilities, with columns: 'oid', 'class_name', 'classifier_name', 'classifier_version', 'probability', 'ranking'.\n   - The 'gaia_ztf' table contains Gaia association data, with columns: 'oid', 'candid', 'neargaia', 'neargaiabright', 'maggaia', 'maggaiabright', 'unique1'.\n   - The 'object' table is referenced via 'oid' but is not directly needed unless for additional filtering or context.\n\n2. **Filter the 'probability' table for the specified classifier and class conditions:**\n   - Select entries where 'classifier_name' equals 'lc_classifier' and 'classifier_version' equals 'hierarchical_rf_1.1.0'.\n   - Filter for 'ranking' equal to 1 to ensure only the most probable classification per object.\n   - Filter for 'probability' greater than 0.7.\n   - Filter for 'class_name' being either 'LPV' (long period variable) or 'E' (eclipsing binary).\n\n3. **Join the filtered 'probability' data with the 'gaia_ztf' table:**\n   - Use the 'oid' as the key to join both tables, ensuring that Gaia data corresponds to the same object.\n\n4. **Apply the condition on Gaia association stability:**\n   - Filter for 'gaia_ztf.unique1' being true, indicating the Gaia association has not changed since the first alert.\n\n5. **Select the required columns:**\n   - Retrieve all columns from both 'probability' and 'gaia_ztf' tables for the objects satisfying the above conditions.\n\n6. **Limit the result:**\n   - Restrict the output to at most 50 rows to match the user request.\n\n7. **Order the results (optional but recommended):**\n   - To ensure consistent output, order by 'probability' descending or any other relevant column.\n\n8. **Construct the query with the above filters and joins:**\n   - Use an inner join between the filtered 'probability' subquery and 'gaia_ztf' on 'oid'.\n   - Apply the 'LIMIT 50' clause at the end.\n\nThis step-by-step plan ensures the query is precise, efficient, and adheres to the user's specifications, including the classification probabilities, Gaia association stability, and result limit.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being either long period variable or eclipsing binary in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest Gaia objects have not changed compared to their first alerts. Return all columns from the 'probability' and 'gaia_ztf' tables, and give at most 50 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "108-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the object identifiers, number of detections (`ndet`), and Galactic latitude (`gal_b`).\n   - The `probability` table, which contains classification probabilities, object identifiers (`oid`), class names, classifier names, and probabilities.\n   - The `stamp_classifier` table (or equivalent), which stores classifier information, including the classifier name and version.\n\n2. **Determine the filtering criteria:**\n   - Select objects with more than 20 detections (`ndet > 20`) from the `object` table.\n   - Join with the `probability` table to filter objects with a probability greater than 0.9 of being a bogus object.\n   - Ensure the probability corresponds to the `stamp_classifier` with name `'stamp_classifier'` and version `'stamp_classifier_1.0.4'`.\n   - Filter the probability to only consider the class `'bogus'`.\n\n3. **Establish the join conditions:**\n   - Join the `object` table with the `probability` table on the object identifier (`oid` in `probability` matches `oid` in `object`).\n   - Filter the `probability` table to only include entries where:\n     - `classifier_name` = `'stamp_classifier'`\n     - `classifier_version` = `'stamp_classifier_1.0.4'`\n     - `class_name` = `'bogus'`\n     - `probability` > 0.9\n\n4. **Select the required columns:**\n   - From the `object` table, select the object identifier (likely `oid` or a specific identifier column).\n   - The number of detections (`ndet`).\n   - The probability value from the `probability` table.\n   - The Galactic latitude (`gal_b`) from the `object` table.\n\n5. **Limit the number of results:**\n   - Restrict the output to at most 15 objects using a `LIMIT` clause.\n\n6. **Order the results:**\n   - Order the final results by the object identifier, which is in the `object` table, in ascending order.\n\n7. **Ensure the query is efficient and accurate:**\n   - Use appropriate indexes on `oid`, `classifier_name`, `classifier_version`, and `class_name` to optimize joins and filtering.\n   - Use `JOIN` clauses to combine tables based on `oid`.\n   - Use `WHERE` clauses to apply all filtering conditions.\n\n8. **Document the query structure:**\n   - Clearly specify the join conditions, filters, selected columns, and ordering.\n   - Confirm that the class name `'bogus'` and classifier details match the database schema.\n\nBy following these steps, the resulting query will accurately retrieve up to 15 ZTF objects with more than 20 detections, a high probability (>0.9) of being bogus according to the specified classifier version, and will include the requested columns ordered by object identifier.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 15 ZTF objects that have more than 20 detections and a probability larger than 0.9 of being a bogus in the stamp classifier version 'stamp_classifier_1.0.4'. Return the following columns: ZTF identifier, number of detections, probability and Galactic latitude as 'gal_b'. Order the results by the object identifier from the object table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "108-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics of each astronomical object, including its identifier, number of detections (`ndet`), and Galactic latitude (`gal_b`).\n   - The `probability` table, which stores the classification probabilities for each object, including the class name, classifier name, version, probability value, and object identifier (`oid`).\n   - The `stamp_classifier` table (or equivalent), which contains the classification results, including the classifier name, version, and object identifier, and indicates whether an object is classified as bogus.\n\n2. **Determine the filtering criteria:**\n   - The object must have more than 20 detections (`ndet > 20`).\n   - The probability of being a bogus object must be greater than 0.9, specifically from the `stamp_classifier` with version `'stamp_classifier_1.0.4'`.\n   - The classification must be for the class `'bogus'` in the `stamp_classifier` table.\n   - The classifier name should be `'stamp_classifier'` (or the exact name used in the database for the classifier that produces these results).\n   - The probability must be the highest ranking (`ranking = 1`) for the `'stamp_classifier'` classifier.\n\n3. **Establish the join conditions:**\n   - Join the `object` table with the `probability` table on the object identifier (`oid`).\n   - Join the `probability` table with the classification results table (`stamp_classifier`) on `oid`.\n   - Filter the `probability` table to include only entries where `classifier_name='stamp_classifier'`, `classifier_version='stamp_classifier_1.0.4'`, `class_name='bogus'`, and `ranking=1`.\n   - Filter the classification results to include only objects classified as `'bogus'`.\n\n4. **Apply the filters:**\n   - Filter objects with `ndet > 20`.\n   - Filter probability entries with `probability > 0.9`.\n   - Ensure the classification is `'bogus'` in the classification table.\n\n5. **Select the required columns:**\n   - The object identifier (likely `oid` or a specific ZTF identifier column).\n   - The number of detections (`ndet`).\n   - The probability value (`probability`).\n   - The Galactic latitude (`gal_b`).\n\n6. **Limit the number of results:**\n   - Restrict the output to at most 15 objects.\n\n7. **Order the results:**\n   - Order the final results by the object identifier, as specified.\n\n8. **Construct the query logic:**\n   - Use a `JOIN` or sub-query to combine the `object`, `probability`, and classification result tables.\n   - Apply all filters in the `WHERE` clause.\n   - Use `LIMIT 15` to restrict the output.\n   - Use `ORDER BY` on the object identifier.\n\n9. **Ensure the query adheres to the default conditions:**\n   - Use the `probability.ranking=1` condition.\n   - Use the `classifier_name='stamp_classifier'`.\n   - Use the `classifier_version='stamp_classifier_1.0.4'`.\n   - Select all columns needed, or specify only the required ones.\n\n10. **Verify the output columns:**\n    - Confirm that the columns returned are the ZTF identifier, number of detections, probability, and `gal_b`.\n\nBy following these steps, you will systematically generate an accurate and efficient PostgreSQL query that retrieves the desired objects based on the specified criteria, ensuring the results are limited to 15 and ordered appropriately.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 15 ZTF objects that have more than 20 detections and a probability larger than 0.9 of being a bogus in the stamp classifier version 'stamp_classifier_1.0.4'. Return the following columns: ZTF identifier, number of detections, probability and Galactic latitude as 'gal_b'. Order the results by the object identifier from the object table.''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "101-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and their roles:**\n   - The `probability` table contains classification probabilities for objects, including the probability of being a long period variable (LPV) in the light curve classifier.\n   - The `xmatch` table links objects to external catalogs; it may be used if cross-matching information is needed, but in this case, the user does not specify any filtering based on `xmatch`.\n   - The `allwise` table contains WISE W1 magnitudes, which are used to filter objects with W1 magnitudes between 7 and 8.\n\n2. **Determine the filtering criteria:**\n   - For the `probability` table:\n     - Filter for `classifier_name='lc_classifier'` to select probabilities from the light curve classifier.\n     - Filter for `class_name='LPV'` to focus on long period variables.\n     - Filter for `probability > 0.5` to select objects with a high likelihood of being LPV.\n     - Filter for `ranking=1` to ensure selecting the most probable classification per object.\n   - For the `allwise` table:\n     - Filter for `w1mpro BETWEEN 7 AND 8` to select objects with W1 magnitudes in the specified range.\n   - For the `xmatch` table:\n     - No specific filtering is requested; include all objects that meet the above criteria.\n\n3. **Establish the join conditions:**\n   - The `probability` table is linked to objects via the `oid` column.\n   - The `allwise` table is linked via `oid_catalog` which should match the object identifiers; verify if `oid` in `probability` corresponds to `oid_catalog` in `allwise`.\n   - The `xmatch` table also uses `oid` to link objects; ensure that the `oid` in `xmatch` matches the `oid` in `probability`.\n   - Use inner joins to combine these tables based on the object identifiers.\n\n4. **Construct the join sequence:**\n   - Start with the `probability` table filtered for LPV class and probability > 0.5, ranking=1, classifier='lc_classifier'.\n   - Join with `allwise` on the object identifier to filter by W1 magnitude.\n   - Join with `xmatch` on the object identifier to include cross-matching data if needed.\n   - Since the user requests all columns from these tables, select all columns from each table in the final output.\n\n5. **Apply the limit:**\n   - Limit the total number of returned rows to 100 to match the user\u2019s request.\n\n6. **Order the results:**\n   - Optionally, order the results by probability or any other relevant column to make the output more meaningful, but this is not explicitly required.\n\n7. **Ensure the query is efficient:**\n   - Use the existing indexes on `probability.oid`, `allwise.oid_catalog`, and `xmatch.oid` to optimize joins.\n   - Filter early in subqueries or CTEs if needed to improve performance.\n\n8. **Final step:**\n   - Compose the query with the above filters, joins, and limit, ensuring all selected columns are included from the three tables.\n\nThis systematic plan ensures the query accurately retrieves the desired objects with the specified classification probability, WISE magnitude range, and includes all relevant data from the specified tables, with a maximum of 100 results.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have a probability larger than 0.5 of being a long period variable in the light curve classifier, as well as a WISE W1 magnitude between 7 and 8. Return all columns from the 'probability', 'xmatch' and 'allwise' tables for such objects. Give at most 100 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "88-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the main statistics of each ZTF object, including its identifier (`oid`), mean RA (`meanra`), mean Dec (`meandec`), and total number of detections (`ndet`).\n   - The `probability` table, which holds classification probabilities and rankings for each object, including `oid`, `class_name`, `classifier_name`, `classifier_version`, `probability`, and `ranking`.\n   - The `stamp_classifier` classification is stored in the `probability` table with `classifier_name='stamp_classifier'` and `class_name='bogus'`.\n\n2. **Filter for the classification criteria:**\n   - Select entries from the `probability` table where:\n     - `classifier_name='stamp_classifier'`\n     - `class_name='bogus'`\n     - `ranking=1` (to ensure the highest probability classification is 'bogus')\n   \n3. **Join the classification data with object data:**\n   - Use an `INNER JOIN` between the filtered `probability` table and the `object` table on the `oid` column to retrieve object details.\n\n4. **Apply the detection count condition:**\n   - Filter objects where `ndet >= 20` in the `object` table.\n\n5. **Select the required columns:**\n   - ZTF identifier: `object.oid`\n   - Number of detections: `object.ndet`\n   - Mean RA and Dec: `object.meanra`, `object.meandec`\n   - Classifier version: `probability.classifier_version`\n   - Probability: `probability.probability`\n\n6. **Limit the number of results:**\n   - Use a `LIMIT 50` clause to restrict the output to at most 50 rows.\n\n7. **Order the results (optional but recommended):**\n   - To make the output more meaningful, order by the probability in descending order, so the most confident classifications appear first.\n\n8. **Ensure the query adheres to default conditions:**\n   - Since the user request involves the `probability` table, always include the condition `probability.ranking=1`.\n   - Confirm that `probability.classifier_name='lc_classifier'` is not necessary here, as the classification is from `stamp_classifier`.\n\n9. **Document the query structure:**\n   - The query will be a join between the filtered `probability` table and the `object` table, with appropriate `WHERE` conditions and a `LIMIT`.\n\nBy following these steps, the resulting query will accurately retrieve ZTF objects classified as 'bogus' with the highest confidence, having at least 20 detections, along with the specified columns, and limited to 50 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have the 'bogus' class as ranking 1 in the stamp classifier, as well as a minimum of 20 detections. Return the following columns: ZTF identifier, number of detections, mean RA Dec coordinates, classifier version and probability. Give at most 50 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "88-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the primary information about each ZTF object, including its identifier (`oid`), mean RA (`meanra`), mean Dec (`meandec`), and total number of detections (`ndet`).\n   - The `probability` table, which holds the classification probabilities and rankings for each object, including `oid`, `class_name`, `classifier_name`, `classifier_version`, `probability`, and `ranking`.\n   - The `detection` table, which records individual detection events, including `oid` and `candid`. The total number of detections per object can be derived from counting entries in this table, or directly from the `ndet` column in the `object` table.\n\n2. **Determine the filtering criteria:**\n   - The object must have a classification in the `probability` table with:\n     - `class_name` equal to `'bogus'`.\n     - `classifier_name` equal to `'stamp_classifier'`.\n     - `ranking` equal to `1` (most probable classification).\n   - The object must have at least 20 detections, which can be checked via:\n     - The `ndet` column in the `object` table, or\n     - Counting the number of entries in the `detection` table for each object (`oid`).\n\n3. **Construct the subquery or join for classification:**\n   - Filter the `probability` table to include only entries where `class_name='bogus'`, `classifier_name='stamp_classifier'`, and `ranking=1`.\n   - Select the `oid`, `classifier_version`, and `probability` for these entries.\n\n4. **Join the classification data with the object data:**\n   - Use the `oid` as the key to join the filtered `probability` entries with the `object` table.\n   - Retrieve the `oid`, `ndet`, `meanra`, and `meandec` from the `object` table.\n\n5. **Apply the detection count filter:**\n   - Ensure that only objects with `ndet >= 20` are included.\n   - Alternatively, if `ndet` is not reliable or not available, perform a count of detections from the `detection` table grouped by `oid` and filter for counts >= 20.\n\n6. **Select the required columns:**\n   - ZTF identifier: `oid`.\n   - Number of detections: `ndet`.\n   - Mean RA and Dec: `meanra`, `meandec`.\n   - Classifier version: from the `probability` table.\n   - Probability: from the `probability` table.\n\n7. **Limit the number of results:**\n   - Use a `LIMIT 50` clause to restrict the output to at most 50 rows.\n\n8. **Order the results:**\n   - Optionally, order by probability descending or by `ndet` descending to prioritize the most confident or most detected objects.\n\n9. **Ensure the query adheres to default conditions:**\n   - Use only the most probable (`ranking=1`) classification.\n   - Filter by `classifier_name='stamp_classifier'`.\n   - Use the exact column and table names as specified.\n   - Use `SELECT *` or specific columns as needed.\n\n10. **Test and validate the query:**\n    - Verify that the joins and filters correctly implement the criteria.\n    - Confirm that the number of detections filter is correctly applied.\n    - Check that the output columns match the requested information.\n\nBy following these steps, you will systematically generate an accurate and efficient PostgreSQL query that retrieves ZTF objects classified as 'bogus' with ranking 1, having at least 20 detections, along with the specified columns, limited to 50 rows.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that have the 'bogus' class as ranking 1 in the stamp classifier, as well as a minimum of 20 detections. Return the following columns: ZTF identifier, number of detections, mean RA Dec coordinates, classifier version and probability. Give at most 50 rows in the resulting table''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier'\n### IF THE 'feature' TABLE is used with 2 or more features, you need to take the following steps, because it is a transposed table (each feature is in a different row).\nI. Create a sub-query using the 'probability' TABLE filtering the desired objects.\nII. For each feature, you have to make a sub-query retrieving the specific feature adding the condition of its value, taking only the oids in the 'probability' sub-query with an INNER JOIN inside each 'feature' sub-query to retrieve only the features associated with the desired spatial objects.\nIII. Make an UNION between the sub-queries of each feature from step II\nIV. Make an INTERSECT between the sub-queries of each feature from step II\nV. Filter the 'UNION' query from step III selecting only the 'oids' that are in the 'INTERSECT' query from step IV\nVI. Add the remaining conditions to the final result of step V, using the 'probability' sub-query from step I.\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n\n# If you need to use 2 or 3 tables, try using a sub-query or INNER JOIN over 'probability' TABLE or 'object' TABLE, or an INNER JOIN between 'probabbility' and 'object', or over an INNER JOIN between 'probability', 'object' and 'magstat', if it is necessary (priority in this order).\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Finally, join all the steps in a final query, with the following format: \n```sql [FINAL QUERY HERE] ```\nDON'T include anything else inside and after your FINAL answer.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The primary table for ZTF objects is the `object` table, which contains the object identifiers (`oid`) and other static properties.\n   - The `probability` table links object IDs (`oid`) with classification probabilities, including the class name, classifier name, and probability value.\n   - The `xmatch` table contains information about the nearest PS1 sources, including the `dist` (distance in arcsec), `oid` (ZTF object ID), and `catid` (catalog identifier).\n   - The `ps1_ztf` table provides PS1 star/galaxy scores (`sgscore1`, `sgscore2`, `sgscore3`) and the nearest PS1 source identifiers.\n   - The `light_curve` or similar table (not explicitly provided but implied by the request) should contain epoch-specific data: candidate ID, filter ID, reduced chi-square, star/galaxy score from SExtractor, and possibly the epoch timestamp.\n\n2. **Filter objects based on probability of being an AGN:**\n   - Use the `probability` table to select objects with `class_name='AGN'`, `classifier_name='lc_classifier'`, `classifier_version='hierarchical_rf_1.1.0'`, and `probability > 0.7`.\n   - Ensure to select only the entries with `ranking=1` to get the most probable classification per object.\n\n3. **Join the probability-filtered objects with the `object` table:**\n   - Retrieve the ZTF object identifier (`oid`) and the associated probability value for each object satisfying the probability condition.\n\n4. **Apply spatial proximity condition with PS1 sources:**\n   - Join the filtered objects with the `xmatch` table on `oid`.\n   - Filter for `dist < 2` arcsec to select objects with a nearest PS1 source within 2 arcsec.\n\n5. **Calculate the difference in star/galaxy scores:**\n   - Join with the `ps1_ztf` table on `oid` to access PS1 star/galaxy scores (`sgscore1`, `sgscore2`, `sgscore3`) and the nearest PS1 source identifier.\n   - Retrieve the star/galaxy score from SExtractor (assumed to be in the epoch data table, which should be joined accordingly).\n   - Compute the absolute difference between the PS1 star/galaxy score (`sgscore1`) of the nearest source and the SExtractor star/galaxy score.\n   - Filter for objects where this difference is less than 0.5.\n\n6. **Retrieve epoch-specific data:**\n   - Join with the epoch data table (e.g., `light_curve` or similar) to get:\n     - Candidate ID\n     - Filter ID\n     - Reduced chi-square\n     - SExtractor star/galaxy score\n   - Ensure to select only up to 50 objects, ordered by probability or other relevant criteria.\n\n7. **Select the output columns:**\n   - For each object: ZTF identifier (`oid`) and probability.\n   - For each epoch: candidate ID, filter ID, reduced chi-square, SExtractor star/galaxy score.\n   - For the nearest PS1 source: identifier (`objectidps1`), PS1 star/galaxy score (`sgscore1`), and distance (`distpsnr1`).\n\n8. **Limit the results:**\n   - Use a `LIMIT 50` clause to restrict the output to at most 50 objects satisfying all conditions.\n\n9. **Order the results:**\n   - Optionally, order by probability descending or other relevant metric to prioritize the most confident candidates.\n\n10. **Ensure all conditions are combined correctly:**\n    - Use `INNER JOIN`s to enforce the conditions on probability, spatial proximity, and score differences.\n    - Use `WHERE` clauses to filter by probability, distance, and score difference.\n    - Use subqueries or CTEs if necessary to organize complex filtering steps, especially for the probability and spatial conditions.\n\n11. **Test and validate the query:**\n    - Verify that the joins correctly link the tables.\n    - Confirm that the filters are applied as intended.\n    - Check that the number of returned objects does not exceed 50.\n\nThis systematic decomposition ensures that the final SQL query will accurately retrieve the requested data, respecting all specified conditions, and will be optimized by proper joins, filters, and limiting clauses.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "105-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves up to 50 ZTF objects meeting the specified conditions, the following systematic steps should be taken:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the ZTF object identifiers and basic statistics.\n   - The `probability` table, which holds classification probabilities, including the probability of being an AGN.\n   - The `ps1_ztf` table, which provides information about the nearest PS1 sources, including star/galaxy scores and distances.\n   - The `feature` table, which contains epoch-specific features such as candidate, filter identifier, reduced chi-square, and star/galaxy score from SExtractor.\n\n2. **Filter objects based on probability:**\n   - Select entries from the `probability` table where:\n     - `class_name` is `'AGN'`.\n     - `classifier_name` is `'lc_classifier'`.\n     - `classifier_version` is `'hierarchical_rf_1.1.0'`.\n     - `probability` exceeds 0.7.\n     - `ranking` is 1 (to ensure the most probable classification).\n   - Join this filtered probability data with the `object` table on `oid` to get the object identifiers and other statistics.\n\n3. **Apply spatial proximity condition:**\n   - From the `ps1_ztf` table, select objects where:\n     - `distpsnr1` (distance to nearest PS1 source) is less than 2 arcsec.\n   - Join this with the previous result on `oid` to filter objects that satisfy this spatial condition.\n\n4. **Apply star/galaxy score difference condition:**\n   - For each object, compute the absolute difference between:\n     - `sgscore1` (PS1 star/galaxy score).\n     - `sgscore1` from SExtractor (which should be stored in the `feature` table with a specific `name`, e.g., `'sgscore1'`).\n   - Filter objects where this difference is less than 0.5.\n\n5. **Retrieve epoch-specific features:**\n   - For each object, select from the `feature` table the rows corresponding to epoch data, which include:\n     - Candidate identifier.\n     - Filter identifier.\n     - Reduced chi-square.\n     - Star/galaxy score from SExtractor.\n   - Ensure to filter features by relevant `name` values and possibly by `fid` if needed.\n\n6. **Select the required columns:**\n   - From the object table: ZTF identifier (`oid`) and probability.\n   - From the features table: candidate, filter identifier, reduced chi-square, star/galaxy score from SExtractor.\n   - From the `ps1_ztf` table: PS1 source identifier, star/galaxy score, and distance.\n\n7. **Limit the result to 50 objects:**\n   - Use a `LIMIT 50` clause to restrict the output to the top 50 objects satisfying all conditions.\n\n8. **Order the results:**\n   - Optionally, order by probability descending or by object identifier for consistency.\n\n9. **Ensure all joins and filters are correctly applied:**\n   - Use inner joins where necessary to enforce the conditions.\n   - Use appropriate `WHERE` clauses for probability, spatial distance, and score difference conditions.\n\n10. **Test the query:**\n    - Verify that the query correctly filters objects based on all criteria.\n    - Check that the selected columns are correctly retrieved.\n    - Confirm that the limit is respected.\n\nThis systematic approach ensures the query is accurate, efficient, and retrieves the requested data within the specified constraints.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.7 of being an AGN in the light curve classifier version 'hierarchical_rf_1.1.0', a distance to the nearest PS1 source lower than 2 arcsec, and a difference between the star/galaxy score from PS1 and the star/galaxy score from SExtractor lower than 0.5. Return the following columns. For the ZTF object: ZTF identifier and probability; for each epoch: candidate and filter identifier, reduced chi-square, star/galaxy score from SExtractor, and also the identifier, PS1 star/galaxy score and distance of the nearest PS1 source''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow this detailed plan:\n\n1. **Identify the relevant tables and columns:**\n   - The primary tables involved are:\n     - `probability` for classification probabilities.\n     - `ps1_ztf` for information about the closest PS1 sources.\n   - The key columns are:\n     - In `probability`: `oid`, `class_name`, `classifier_name`, `probability`.\n     - In `ps1_ztf`: all columns, especially `oid`, `sgmag1`, `srmag1`, `simag1`, `szmag1`, `sgscore1`, `distpsnr1`, etc.\n\n2. **Apply filtering conditions on the `probability` table:**\n   - Filter for `classifier_name='lc_classifier'`.\n   - Filter for `classifier_version='hierarchical_rf_1.1.0'`.\n   - Filter for `probability > 0.6`.\n   - Filter for `class_name` being one of the three classes: `'Cepheid'`, `'DSCT'`, `'RRL'`.\n   - Filter for `ranking=1` to ensure only the most probable classification per object.\n\n3. **Join the `probability` table with the `object` table (if needed):**\n   - Since the `probability` table references objects via `oid`, and the user wants all columns from `probability` and `ps1_ztf`, the join will be based on `oid`.\n   - The join ensures that only objects with the specified classification probabilities are selected.\n\n4. **Apply filtering conditions on the `ps1_ztf` table:**\n   - Filter for `sgscore1 > 0.8` to select objects with high star/galaxy score.\n   - The `ps1_ztf` table is linked via `oid`, so join on `oid`.\n\n5. **Construct the combined query:**\n   - Use an `INNER JOIN` between `probability` and `ps1_ztf` on `oid`.\n   - Apply all the above filters in the `WHERE` clause.\n\n6. **Limit the number of results:**\n   - Use `LIMIT 100` to restrict the output to at most 100 rows.\n\n7. **Select all columns from both tables:**\n   - Use `SELECT *` from `probability` and `ps1_ztf` to include all relevant information.\n\n8. **Order the results (optional):**\n   - Optionally, order by `probability` descending to prioritize the most confident classifications, or leave unordered if not specified.\n\n9. **Ensure the query adheres to the default conditions:**\n   - Confirm that only the most probable (`ranking=1`) entries are included.\n   - Confirm that the classifier name and version match the specified values.\n\n10. **Finalize the query structure:**\n    - The query will be a join of `probability` and `ps1_ztf` with the specified filters, limited to 100 rows.\n\nThis systematic decomposition ensures the query will accurately retrieve ZTF objects with the specified classification probabilities and PS1 star/galaxy scores, respecting all user constraints and database schema details.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "86-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The 'probability' table contains classification probabilities, with columns: 'oid', 'class_name', 'classifier_name', 'classifier_version', 'probability', 'ranking'.\n   - The 'ps1_ztf' table contains information about the closest PS1 sources, with columns: 'oid', 'sgscore1', 'distpsnr1', etc.\n   - The 'object' table is not explicitly required here, but ensure the 'oid' keys are consistent across tables.\n\n2. **Set the filtering conditions based on user specifications:**\n   - Probabilities for classes 'Cepheid', 'DSCT' (Delta Scuti), and 'RRL' (RR Lyrae) must be greater than 0.6.\n   - The 'probability' table should be filtered to include only entries with 'classifier_name' equal to 'lc_classifier', 'classifier_version' equal to 'hierarchical_rf_1.1.0', and 'ranking' equal to 1 (most likely class).\n   - The class names should be filtered to include only the three specified classes.\n\n3. **Construct the probability filter:**\n   - Use a condition that selects rows where 'class_name' is in ('CEP', 'DSCT', 'RRL') and 'probability' > 0.6.\n   - Ensure the 'classifier_name' and 'classifier_version' match the specified classifier.\n\n4. **Join the 'probability' table with the 'ps1_ztf' table:**\n   - Use the 'oid' column as the key to join these tables, ensuring that the objects are matched correctly.\n   - This join will allow retrieval of all columns from both tables for objects satisfying the conditions.\n\n5. **Apply the condition on the PS1 star/galaxy score:**\n   - Filter the joined results to include only entries where 'sgscore1' > 0.8, indicating a high likelihood of the closest PS1 source being a star.\n\n6. **Limit the number of results:**\n   - Use a limit clause to restrict the output to at most 100 rows, as specified.\n\n7. **Select all columns from the 'probability' and 'ps1_ztf' tables:**\n   - Use a SELECT statement that retrieves all columns from both tables, ensuring clarity and completeness.\n\n8. **Order the results (optional but recommended):**\n   - Optionally, order by 'probability' descending or another relevant column to prioritize the most confident classifications.\n\n9. **Ensure the query is efficient:**\n   - Use appropriate indexes on 'oid', 'class_name', 'classifier_name', 'classifier_version', and 'sgscore1' to optimize performance.\n\n10. **Document the query logic:**\n    - Clearly specify that the query filters for high-probability classifications of Cepheid, Delta Scuti, or RR Lyrae, with high-confidence PS1 star/galaxy scores, and limits the output to 100 entries.\n\nThis systematic decomposition ensures the final query will accurately retrieve the desired objects with all relevant information, respecting the specified conditions and constraints.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being either Cepheid or delta Scuti or RR Lyra in the light curve classifier version 'hierarchical_rf_1.1.0', and their closest PS1 objects have a star/galaxy score larger than 0.8. Return all columns from the 'probability' and 'ps1_ztf' tables, and give at most 100 rows in the result''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "41-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the input objects and their coordinates:**\n   - Define the first object with identifier 'id_1' and coordinates RA=132.961, Dec=41.397.\n   - Define the second object with identifier 'id_2' and coordinates RA=139.01, Dec=41.5653.\n\n2. **Set the search radii in degrees:**\n   - Convert the search radius for 'id_1' from 5 arcseconds to degrees (5/3600).\n   - Convert the search radius for 'id_2' from 10 arcseconds to degrees (10/3600).\n\n3. **Create a temporary inline table (using a WITH clause) to hold the input objects:**\n   - Define a temporary table with columns: 'id', 'ra', 'dec', and 'r_deg'.\n   - Insert two rows into this table: one for 'id_1' with its coordinates and radius, and one for 'id_2' with its coordinates and radius.\n\n4. **Use spatial functions to find ALLWISE objects within the specified search radii:**\n   - For each input object, perform a spatial query on the 'allwise' table.\n   - Use the Q3C function `q3c_radial_query` to check if the ALLWISE object coordinates (ra, dec) are within 'r_deg' degrees of the input object coordinates.\n   - Combine the results for both input objects using a logical OR, so that ALLWISE objects within either radius are included.\n\n5. **Select the relevant columns from the 'allwise' table:**\n   - Retrieve the ALLWISE catalog identifier ('oid_catalog').\n   - Retrieve the RA and Dec coordinates ('ra', 'dec').\n   - Retrieve the W1 magnitude ('w1mpro') and its uncertainty ('w1sigmpro').\n\n6. **Construct the output columns:**\n   - Include a column 'identifier' with the value 'ALLWISE' for all returned rows.\n   - Include the input object identifier ('id') for each ALLWISE object, indicating which input object it is associated with.\n   - Include the input object coordinates ('obj_ra', 'obj_dec') for reference.\n   - Include the search radius used ('r_deg') in degrees for each input object.\n\n7. **Order or group the results as needed:**\n   - Optionally, order the results by the input object identifier or by proximity.\n\n8. **Ensure the query handles multiple matches:**\n   - The query should return all ALLWISE objects that satisfy the spatial condition for either input object.\n\n9. **Test the query to verify correctness:**\n   - Confirm that the spatial filtering correctly identifies objects within the specified radii.\n   - Check that the output includes all required columns with correct data.\n\nThis systematic decomposition ensures the query will accurately find all ALLWISE objects within the specified angular distances from the two input objects, and will include all the requested information in the output table.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all ALLWISE objects that lie within 5 arcsec of an object called id_1, that has coordinates (RA, Dec) = (132.961, 41.397) deg, or within 10 arcsec of  an object called id_2, having coordinates (RA, Dec) = (139.01, 41.5653). Return a table that includes the following columns. For the input objects: identifier as 'id', coordinates as 'obj_ra' and 'obj_dec', and search radius used for each object in degrees as r_deg; and for the output ALLWISE objects: identifier in the ALLWISE catalog, RA Dec coordinates, and magnitude (and its uncertainty) in the WISE W1 filter''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "41-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the input objects and their coordinates:**\n   - Define the first object with identifier 'id_1' and coordinates RA=132.961\u00b0, Dec=41.397\u00b0.\n   - Define the second object with identifier 'id_2' and coordinates RA=139.01\u00b0, Dec=41.5653\u00b0.\n\n2. **Determine the search radii in degrees:**\n   - Convert the given arcsecond search radii to degrees:\n     - 5 arcsec = 5 / 3600 \u2248 0.0013889 degrees.\n     - 10 arcsec = 10 / 3600 \u2248 0.0027778 degrees.\n   - Assign these as variables or constants in the query for clarity:\n     - For 'id_1': radius = 0.0013889 degrees.\n     - For 'id_2': radius = 0.0027778 degrees.\n\n3. **Create inline tables for the input objects:**\n   - Use a WITH clause to define a temporary table (e.g., 'input_objects') containing:\n     - 'id' as the identifier ('id_1' or 'id_2'),\n     - 'ra' and 'dec' as their respective coordinates,\n     - 'r_deg' as the search radius in degrees.\n\n4. **Perform spatial filtering using Q3C functions:**\n   - For each input object, perform a spatial query on the 'allwise' table:\n     - Use the 'q3c_join' function to find ALLWISE objects within the specified radius.\n     - The function parameters are (ra, dec, ra_center, dec_center, radius).\n   - Combine the results for both input objects, ensuring no duplicates if an ALLWISE object is within both search regions.\n\n5. **Construct the SELECT statement:**\n   - Retrieve from the 'allwise' table:\n     - The 'oid_catalog' as the identifier.\n     - RA and Dec coordinates ('ra', 'dec').\n     - WISE W1 magnitude ('w1mpro') and its uncertainty ('w1sigmpro').\n   - Include in the output the input object identifier ('id'), the input coordinates ('obj_ra', 'obj_dec'), and the search radius ('r_deg') used for each query.\n\n6. **Format the output table:**\n   - For each matched ALLWISE object, include:\n     - 'id' (either 'id_1' or 'id_2'),\n     - 'obj_ra' and 'obj_dec' (the input object coordinates),\n     - 'r_deg' (the search radius in degrees),\n     - 'oid_catalog' (ALLWISE object identifier),\n     - 'ra', 'dec' (coordinates of the ALLWISE object),\n     - 'w1mpro' (W1 magnitude),\n     - 'w1sigmpro' (uncertainty in W1 magnitude).\n\n7. **Ensure the query handles both input objects:**\n   - Use a UNION or OR condition to combine the spatial queries for both objects.\n   - Maintain clarity by tagging each result with the corresponding input object identifier and search radius.\n\n8. **Test and validate the query:**\n   - Verify that the spatial filtering correctly uses the Q3C functions.\n   - Confirm that the output includes all required columns and correctly labels the input object info.\n\nThis systematic decomposition ensures the query will accurately find all ALLWISE objects within the specified angular distances from each input object, and will return a comprehensive table with all requested information.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Find all ALLWISE objects that lie within 5 arcsec of an object called id_1, that has coordinates (RA, Dec) = (132.961, 41.397) deg, or within 10 arcsec of  an object called id_2, having coordinates (RA, Dec) = (139.01, 41.5653). Return a table that includes the following columns. For the input objects: identifier as 'id', coordinates as 'obj_ra' and 'obj_dec', and search radius used for each object in degrees as r_deg; and for the output ALLWISE objects: identifier in the ALLWISE catalog, RA Dec coordinates, and magnitude (and its uncertainty) in the WISE W1 filter''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "74-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the specified information from the ALeRCE database based on the user's request, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The main table containing ZTF object information is likely to be the 'ss_ztf' table, which includes the 'oid' (object identifier), 'candid' (candidate ID), and possibly other columns.\n   - The MPC (Minor Planet Center) object data, including the MPC magnitude and identifiers, are not explicitly specified in the provided schema. Determine if there is a dedicated table for MPC objects or if the MPC data is stored within 'ss_ztf' or related tables.\n   - Since the user requests columns from 'ss_ztf' and mentions MPC objects, assume that the 'ss_ztf' table contains or links to MPC object identifiers and magnitudes.\n\n2. **Map the user-specified ZTF object identifiers to database entries:**\n   - Filter the 'ss_ztf' table to include only the rows where the 'oid' matches any of the three specified ZTF object IDs: 'ZTF20abmaqeh', 'ZTF18abwxduj', and 'ZTF19aactlln'.\n   - Use an `IN` clause or equivalent filtering condition for these object IDs.\n\n3. **Retrieve MPC object information:**\n   - For each of these ZTF objects, find associated MPC objects with brightness (magnitude) brighter than 19.2.\n   - This may involve joining the 'ss_ztf' table with an MPC objects table if it exists, or filtering within the same table if MPC data is stored there.\n   - Ensure that the filter for MPC magnitude is 'less than' 19.2, since in astronomy, smaller magnitudes mean brighter objects.\n\n4. **Select the required columns:**\n   - From the relevant table(s), select:\n     - The identifier in both ZTF and MPC (likely the 'oid' for ZTF and some MPC identifier, possibly 'ssnamenr' or another column).\n     - The MPC magnitude (probably stored in a column such as 'ssmagnr' or similar).\n   - The user requests these columns to be sorted by MPC magnitude in descending order, so include an `ORDER BY` clause on the MPC magnitude column, specifying descending order.\n\n5. **Sort the results:**\n   - Order the final output by the MPC magnitude in descending order, so the brightest MPC objects (smallest magnitude) appear last, and the faintest (largest magnitude) appear first.\n\n6. **Ensure the query includes all necessary conditions:**\n   - Filter for the specific ZTF objects.\n   - Filter for MPC objects brighter than 19.2 mag.\n   - Sort accordingly.\n\n7. **Verify the output columns:**\n   - Confirm that the output includes:\n     - ZTF object identifier (from 'oid' or equivalent).\n     - MPC object identifier (from 'ssnamenr' or equivalent).\n     - MPC magnitude (from 'ssmagnr' or equivalent).\n\n8. **Test the query:**\n   - Run the query to ensure it returns the expected data, with correct filtering and sorting.\n\nBy following these steps, you will systematically construct a query that accurately retrieves all MPC objects brighter than 19.2 mag associated with the specified ZTF objects, sorted by MPC magnitude in descending order, including the requested identifiers and magnitudes.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: Note that 'fainter' means 'larger' for magnitudes\nDomain Knowledge: 0\n # User Request: ''For ZTF objects 'ZTF20abmaqeh', 'ZTF18abwxduj' and 'ZTF19aactlln', find all MPC objects brighter than 19.2 mag in the MPC archive. Get the following columns from the 'ss_ztf' table, sort by MPC magnitude in descending order: identifier in both ZTF and MPC, and MPC magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "74-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves the specified information from the ALeRCE database based on the user's request, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - The primary table for ZTF object information is `ss_ztf`.\n   - The columns of interest in `ss_ztf` are:\n     - `oid` (which references the object identifier, likely the ZTF object name)\n     - `candid` (candidate ID)\n     - `ssmagnr` (nearest solar system object magnitude, which in this context is used as the MPC magnitude)\n     - `ssnamenr` (name of the nearest solar system object, which may correspond to the MPC object identifier)\n\n2. **Determine the filtering criteria:**\n   - The ZTF objects of interest are `'ZTF20abmaqeh'`, `'ZTF18abwxduj'`, and `'ZTF19aactlln'`.\n   - The MPC objects should be brighter than 19.2 mag, which means their `ssmagnr` should be less than 19.2 (since smaller magnitudes are brighter).\n\n3. **Construct the filtering condition for the specific ZTF objects:**\n   - Use an `IN` clause to filter `oid` for the three specified ZTF object identifiers.\n\n4. **Apply the brightness filter:**\n   - Use a `WHERE` clause to select rows where `ssmagnr` < 19.2.\n\n5. **Select the required columns:**\n   - From `ss_ztf`, retrieve:\n     - The ZTF object identifier (`oid`)\n     - The MPC object identifier (`ssnamenr`)\n     - The MPC magnitude (`ssmagnr`)\n\n6. **Sort the results:**\n   - Order the results by the MPC magnitude (`ssmagnr`) in descending order, so the brightest MPC objects (smallest `ssmagnr`) appear first.\n\n7. **Ensure the query handles multiple matches:**\n   - The query should return all matching rows for the specified ZTF objects that meet the brightness criterion.\n\n8. **Optional:**\n   - If needed, include comments or structure the query for clarity, but as per instructions, only describe the steps.\n\nBy following these steps, the resulting query will efficiently retrieve all relevant MPC objects associated with the specified ZTF objects that are brighter than 19.2 mag, sorted by their MPC magnitude in descending order, and will include the ZTF and MPC identifiers along with the MPC magnitude.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: Note that 'fainter' means 'larger' for magnitudes\nDomain Knowledge: 0\n # User Request: ''For ZTF objects 'ZTF20abmaqeh', 'ZTF18abwxduj' and 'ZTF19aactlln', find all MPC objects brighter than 19.2 mag in the MPC archive. Get the following columns from the 'ss_ztf' table, sort by MPC magnitude in descending order: identifier in both ZTF and MPC, and MPC magnitude''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the primary identifiers and basic statistics of each ZTF object.\n   - The `probability` table, which stores the classification probabilities, linked to objects via the `oid` column.\n   \n2. **Determine the relevant classification criteria:**\n   - For the stamp classifier:\n     - Filter for `classifier_name='stamp_classifier'` and `classifier_version='stamp_classifier_1.0.4'`.\n     - Filter for `class_name='SN'` (or the relevant class for AGN if specified; but based on context, likely 'AGN' in the stamp classifier).\n     - Filter for `probability > 0.6`.\n     - Filter for `ranking=1` to get the most probable classification.\n   - For the light curve classifier:\n     - Filter for `classifier_name='lc_classifier'`.\n     - Filter for `class_name='LPV'`.\n     - Filter for `probability > 0.7`.\n     - Filter for `ranking=1`.\n   \n3. **Construct subqueries or join conditions:**\n   - Use the `probability` table to filter objects based on the above probability and classification conditions.\n   - Join the filtered `probability` entries with the `object` table on `oid`.\n   \n4. **Select the required columns:**\n   - From the `object` table, select the ZTF identifier, which is `oid`.\n   - From the `probability` table, select the `probability` value for the AGN classification (label it as `prob_stamp_agn`).\n   - From the `probability` table, select the `probability` value for the LPV classification (label it as `prob_lc_lpv`).\n   \n5. **Apply the filtering conditions:**\n   - Ensure that the object has:\n     - A probability > 0.6 for AGN in the stamp classifier version 'stamp_classifier_1.0.4'.\n     - A probability > 0.7 for LPV in the light curve classifier.\n   - Both conditions must be satisfied simultaneously, so join the probability entries for each classifier and class for the same object.\n   \n6. **Limit the number of results:**\n   - Use `LIMIT 50` to restrict the output to at most 50 objects.\n   \n7. **Order the results (optional but recommended):**\n   - To ensure consistent results, order by one of the probabilities or by `oid`.\n   \n8. **Ensure the query is efficient:**\n   - Use appropriate indexes on `probability.oid`, `probability.classifier_name`, `probability.class_name`, and `probability.ranking`.\n   - Use inner joins to filter only objects meeting all criteria.\n   \n9. **Document the final structure:**\n   - The final query should return three columns:\n     - `oid` (ZTF identifier)\n     - `prob_stamp_agn` (probability of being an AGN in the stamp classifier)\n     - `prob_lc_lpv` (probability of being an LPV in the light curve classifier)\n   \n10. **Summary of the steps:**\n    - Filter `probability` for AGN with the specified classifier version and probability threshold.\n    - Filter `probability` for LPV with the specified classifier and probability threshold.\n    - Join these filtered probabilities on `oid`.\n    - Join with `object` table to retrieve the object identifier.\n    - Limit the results to 50 entries.\n    - Return the specified columns with appropriate aliases.\n\nThis systematic approach ensures the query will accurately retrieve the desired objects satisfying all specified probability and classification conditions, with clear and efficient filtering.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "97-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic plan for generating the PostgreSQL query, follow these detailed steps:\n\n1. **Identify the main tables involved:**\n   - The `object` table, which contains the primary identifiers and basic statistics of each ZTF object.\n   - The `probability` table, which stores the classification probabilities, linked to objects via the `oid` column.\n   \n2. **Determine the relevant classification criteria:**\n   - For the stamp classifier:\n     - Filter for `classifier_name='stamp_classifier'` and `classifier_version='stamp_classifier_1.0.4'`.\n     - Filter for `class_name='SN'` (or the relevant class for AGN if specified; but based on context, likely 'AGN' in the stamp classifier).\n     - Filter for `probability > 0.6`.\n   - For the light curve classifier:\n     - Filter for `classifier_name='lc_classifier'`.\n     - Filter for `class_name='LPV'`.\n     - Filter for `probability > 0.7`.\n   \n3. **Apply default conditions for classification ranking:**\n   - Ensure that only the top-ranked classification (`ranking=1`) is considered for both classifiers, as per the provided conditions.\n   \n4. **Construct subqueries or joins:**\n   - Use inner joins between the `object` table and the `probability` table twice:\n     - Once for the AGN probability from the stamp classifier.\n     - Once for the LPV probability from the light curve classifier.\n   - Each join should filter on the respective classifier name, version, class name, probability threshold, and ranking.\n   \n5. **Select the required columns:**\n   - From the `object` table, select the ZTF identifier (`oid`).\n   - From the `probability` table joins, select the probabilities:\n     - For AGN from the stamp classifier, alias as `prob_stamp_agn`.\n     - For LPV from the light curve classifier, alias as `prob_lc_lpv`.\n   \n6. **Limit the number of results:**\n   - Use a `LIMIT 50` clause to restrict the output to at most 50 objects satisfying all conditions.\n   \n7. **Order the results:**\n   - Optionally, order by one of the probabilities or by object identifier for consistency, although not explicitly specified.\n   \n8. **Ensure all conditions are explicitly included:**\n   - Confirm that the probability thresholds, classifier names, versions, class names, and ranking conditions are correctly applied in the WHERE clauses.\n   \n9. **Final query structure:**\n   - The main query will select from the `object` table.\n   - Join with the `probability` table twice, each time with specific filters for the respective classifier and class.\n   - Apply the probability thresholds and ranking filters.\n   - Limit the output to 50 objects.\n   \n10. **Test and validate:**\n    - Verify that the query correctly filters objects based on the specified probabilities and classifiers.\n    - Confirm that the selected columns match the requested output.\n\nThis systematic decomposition ensures the query is accurate, efficient, and adheres to the specified conditions, retrieving at most 50 ZTF objects with the desired classification probabilities and details.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''Get at most 50 ZTF objects that satisfy the following conditions: have a probability larger than 0.6 of being an AGN in the stamp classifier version 'stamp_classifier_1.0.4', and a probability larger than 0.7 of being an LPV in the light curve classifier. Return the following columns: ZTF identifier, probability in the stamp classifier (name this column 'prob_stamp_agn'), and probability in the light curve classifier (name this column 'prob_lc_lpv')''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "76-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo generate a PostgreSQL query that retrieves all ZTF objects within 1.5 arcseconds of the Solar System object with MPC archive identifier '115185', and returns the ZTF identifier, the MPC archive magnitude, and the distance between each ZTF object detection and the MPC object, follow these detailed steps:\n\n1. **Identify the MPC object coordinates:**\n   - Query the MPC archive or relevant table to obtain the celestial coordinates (Right Ascension and Declination) of the object with identifier '115185'.\n   - If the coordinates are stored in a specific table (not explicitly provided), formulate a subquery or a temporary inline table to hold this information.\n   - Ensure the coordinates are in degrees, as required by the Q3C spatial functions.\n\n2. **Define the MPC object as a temporary inline table:**\n   - Use a WITH clause to create a temporary table named, for example, 'mpc_object' with columns for object ID, RA, and Dec.\n   - Populate this table with the retrieved coordinates of the '115185' object.\n\n3. **Perform a spatial query to find ZTF objects within 1.5 arcseconds:**\n   - Use the Q3C function `q3c_join` or `q3c_dist` to identify ZTF objects that are within 1.5 arcseconds of the MPC object.\n   - Since Q3C functions operate in degrees, convert 1.5 arcseconds to degrees (1 arcsecond = 1/3600 degrees), so 1.5 arcseconds = 1.5/3600 degrees.\n   - Filter the 'object' table (or the relevant ZTF objects table) by applying the spatial function with the MPC object coordinates and the radius in degrees.\n\n4. **Retrieve the required columns:**\n   - For each matching ZTF object, select:\n     - The ZTF object identifier (likely from the 'object' table, e.g., 'oid').\n     - The MPC archive magnitude, which may be stored in the 'object' table or a related table; if not directly available, identify the appropriate column.\n     - The distance between the ZTF object detection and the MPC object, calculated using `q3c_dist` with the RA and Dec of both objects.\n\n5. **Order the results:**\n   - Sort the output by the computed distance in ascending order to list the closest objects first.\n\n6. **Ensure the query is optimized:**\n   - Use spatial indexing on the 'object' table if available.\n   - Limit the search to the relevant sky region by applying the spatial filter first, then selecting the columns.\n\n7. **Finalize the query structure:**\n   - Wrap the spatial filtering and selection in a single query, possibly with a CTE (WITH clause) for clarity.\n   - Confirm that all table and column names match the database schema exactly.\n\nBy following these steps, the resulting query will efficiently identify all ZTF objects within 1.5 arcseconds of the specified MPC object, returning the requested information sorted by proximity.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For the Solar System object called '115185' in the MPC archive, find all ZTF objects that lie within 1.5 arcsec from it. Return the following columns, sort by distance: ZTF identifier, MPC archive magnitude, and distance between ZTF object detection and MPC object''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "44-0", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - Recognize that the main table involved is `dataquality`, which contains columns such as `oid` (object identifier), `candid` (candidate ID), and various quality metrics including `chipsf` (reduced chi-square) and `scorr` (peak-pixel S/N).\n   - Confirm that `oid` in `dataquality` corresponds to the ZTF object identifiers, which are stored as strings matching the format `'ZTF...'`.\n\n2. **Determine the filtering criteria:**\n   - The objects of interest are specified by their ZTF identifiers: `'ZTF20abfcszi'` and `'ZTF21aaqwjlz'`.\n   - The epochs to be retrieved are those where the `chipsf` (reduced chi-square) value is less than 3.\n   \n3. **Construct the filtering conditions:**\n   - Use a `WHERE` clause to select rows where `oid` matches either `'ZTF20abfcszi'` or `'ZTF21aaqwjlz'`.\n   - Add an additional condition to filter rows where `chipsf` < 3.\n\n4. **Determine the columns to retrieve:**\n   - Since the user requests \"all columns from the 'dataquality' table,\" specify selecting all columns using `*`.\n\n5. **Define the sorting order:**\n   - First, sort the results by the ZTF identifier (`oid`) in ascending order.\n   - Then, sort by the peak-pixel S/N (`scorr`) in descending order within each object.\n\n6. **Implement the sorting in the query:**\n   - Use an `ORDER BY` clause with `oid ASC` and `scorr DESC`.\n\n7. **Optional considerations:**\n   - Ensure that the filtering on `oid` is case-sensitive and matches the exact string.\n   - Confirm that the `scorr` column is numeric and suitable for descending order sorting.\n\n8. **Final step:**\n   - Combine all the above into a coherent query structure, ensuring proper syntax and logical flow.\n\nBy following these steps, the query will accurately retrieve all epochs for the specified objects where the reduced chi-square is below 3, sorted as requested, and include all relevant data columns from the `dataquality` table.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abfcszi' and 'ZTF21aaqwjlz', get all epochs that have a reduced chi-square value lower than 3. Return all columns from the 'dataquality' table, sorting them by ZTF identifier in ascending order and peak-pixel S/N in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
{"custom_id": "44-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4.1-nano-2025-04-14", "messages": [{"role": "system", "content": "\n\n# As a SQL expert with a willingness to assist users, you are tasked with crafting a PostgreSQL query for the Automatic Learning for the Rapid Classification of Events (ALeRCE) Database in 2023. This database serves as a repository for information about individual spatial objects, encompassing various statistics, properties, detections, and features observed by survey telescopes.\nThe tables within the database are categorized into three types: time and band independent (e.g., object, probability), time-independent (e.g., magstats), and time and band-dependent (e.g., detection). Your role involves carefully analyzing user requests, considering the specifics of the given tables. It is crucial to pay attention to explicit conditions outlined by the user and always maintain awareness of the broader context.\nALeRCE processes data from the alert stream of the Zwicky Transient Facility (ZTF), so unless a specific catalog is mentioned, the data is from ZTF, including the object, candidate and filter identifiers, and other relevant information.  \nBe thorough in understanding and addressing the user's request, taking into account both explicit conditions and the overall context for effective communication and assistance.\n\n\n# The Database has the following tables that can be used to generate the SQL query:\n\nCREATE TABLE object ( /* this is the most important table. It contains the main statistics of an object, independent of time and band */\n    oid VARCHAR PRIMARY KEY,  /* object identifier, from the ZTF */\n    deltajd DOUBLE PRECISION, /* time difference between last and first detection */\n    firstmjd DOUBLE PRECISION, /* time of first detection */\n    lastmjd DOUBLE PRECISION, /* time of last detection */\n    ndethist INTEGER,  /* number of posible detections above 3 sigma */\n    ncovhist INTEGER,  /* number of visits */\n    mjdstarthist DOUBLE PRECISION,  /* time of first observation even if not detected, Earliest Julian date of epoch corresponding to ndethist [days]*/\n    mjdendhist DOUBLE PRECISION, /* time of last observation even if not detected, Latest Julian date of epoch corresponding to ndethist [days] */\n    corrected BOOLEAN, /* whether the object was corrected */\n    stellar BOOLEAN, /* whether the object is likely psf shaped */\n    ndet INTEGER, /* total number of detections for the object */\n    g_r_max DOUBLE PRECISION, /* g-r difference color at maximum */\n    g_r_max_corr DOUBLE PRECISION, /* g-r color at maximum*/\n    g_r_mean DOUBLE PRECISION, /* mean g-r difference color */\n    g_r_mean_corr DOUBLE PRECISION, /* mean g-r color */\n    meanra DOUBLE PRECISION,  /* mean right ascension */\n    meandec DOUBLE PRECISION,  /* mean declination */\n    sigmara DOUBLE PRECISION, /* right ascension dispersion */\n    sigmadec DOUBLE PRECISION, /* declination dispersion */\n    step_id_corr VARCHAR, /* correction step pipeline version */\n    diffpos BOOLEAN, /* whether the first detection was positive or negative */\n    reference_change BOOLEAN /* whether the reference image changes */\n);\nCREATE INDEX ix_object_ndet ON object USING btree (ndet);\nCREATE INDEX ix_object_firstmjd ON object USING btree (firstmjd);\nCREATE INDEX ix_object_g_r_max ON object USING btree (g_r_max);\nCREATE INDEX ix_object_g_r_mean_corr ON object USING btree (g_r_mean_corr);\nCREATE INDEX ix_object_meanra ON object USING btree (meanra);\nCREATE INDEX ix_object_meandec ON object USING btree (meandec);\n\n\nCREATE TABLE dataquality (\n    candid BIGINT PRIMARY KEY, /* unique identifier for the subtraction candidate */\n    oid VARCHAR NOT NULL, /* unique identifier for this object */\n    fid INTEGER NOT NULL, /* Filter ID (1=g; 2=r; 3=i) */\n    xpos DOUBLE PRECISION, /* x-image position of candidate [pixels] */\n    ypos DOUBLE PRECISION, /* y-image position of candidate [pixels] */\n    chipsf DOUBLE PRECISION, /* Reduced chi-square for PSF-fit */\n    sky DOUBLE PRECISION, /* Local sky background estimate [DN] */\n    fwhm DOUBLE PRECISION, /* Full Width Half Max assuming a Gaussian core, from SExtractor [pixels] */\n    classtar DOUBLE PRECISION, /* Star/Galaxy classification score from SExtractor */\n    mindtoedge DOUBLE PRECISION, /* Distance to nearest edge in image [pixels] */\n    seeratio DOUBLE PRECISION, /* Ratio: difffwhm / fwhm */\n    aimage DOUBLE PRECISION, /* Windowed profile RMS afloat major axis from SExtractor [pixels] */\n    bimage DOUBLE PRECISION, /* Windowed profile RMS afloat minor axis from SExtractor [pixels] */\n    aimagerat DOUBLE PRECISION, /* Ratio: aimage / fwhm */\n    bimagerat DOUBLE PRECISION, /* Ratio: bimage / fwhm */\n    nneg INTEGER, /* number of negative pixels in a 5 x 5 pixel stamp */\n    nbad INTEGER, /* number of prior-tagged bad pixels in a 5 x 5 pixel stamp */\n    sumrat DOUBLE PRECISION, /* Ratio: sum(pixels) / sum(abs(pixels)) in a 5 x 5 pixel stamp where stamp is first median-filtered to mitigate outliers */\n    scorr DOUBLE PRECISION, /* Peak-pixel signal-to-noise ratio in point source matched-filtered detection image */\n    dsnrms DOUBLE PRECISION, /* Ratio: D/stddev(D) on event position where D = difference image */\n    ssnrms DOUBLE PRECISION, /* Ratio: S/stddev(S) on event position where S = image of convolution: D (x) PSF(D) */\n    magzpsci DOUBLE PRECISION, /* Magnitude zero point for photometry estimates [mag] */\n    magzpsciunc DOUBLE PRECISION, /* Magnitude zero point uncertainty (in magzpsci) [mag] */\n    magzpscirms DOUBLE PRECISION, /* RMS (deviation from average) in all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    nmatches INTEGER, /* Number of PS1 photometric calibrators used to calibrate science image from science image processing */\n    clrcoeff DOUBLE PRECISION, /* Color coefficient from linear fit from photometric calibration of science image */\n    clrcounc DOUBLE PRECISION, /* Color coefficient uncertainty from linear fit (corresponding to clrcoeff) */\n    zpclrcov DOUBLE PRECISION, /* Covariance in magzpsci and clrcoeff from science image processing [mag^2] */\n    zpmed DOUBLE PRECISION, /* Magnitude zero point from median of all differences between instrumental photometry and matched photometric calibrators from science image processing [mag] */\n    clrmed DOUBLE PRECISION, /* Median color of all PS1 photometric calibrators used from science image processing [mag]: for filter (fid) = 1, 2, 3, PS1 color used = g-r, g-r, r-i respectively */\n    clrrms DOUBLE PRECISION, /* RMS color (deviation from average) of all PS1 photometric calibrators used from science image processing [mag] */\n    exptime DOUBLE PRECISION /* Integration time of camera exposure [sec] */\n    FOREIGN KEY (candid, oid) REFERENCES detection(candid, oid)\n);\n\n\n\n\n## DEFAULT CONDITIONS YOU NEED TO SET\n### IF THE 'probability' TABLE is used, use always the next conditions, unless the user explicitly specifies different probability conditions.\n- 'probability.ranking' = 1 ; this only return the most likely probabilities, if the user request all ranking probabilities, don't use it.\n- 'probability.classifier_name='lc_classifier' ; this will return the classifications by the light curve classifier\n### GENERAL\n### Important points to consider\n- If the user doesn't specify explicit columns or information that is not in a column, choose all the columns, for example by using the \u201cSELECT *\u201d SQL statement, from ALL the tables used, including the ones from the sub-queries.\n- Mantain the EXACT COLUMN names as they are in the database, unless the user explicitly asks you to do so in the request, giving you the new name to use. This is crucial for the query to work correctly.\n- Mantain the exact class names as they are in the database, marked with single quotes, for example, 'SNIa'.\n\n# If you need to use 2 tables, try using a INNER JOIN statement, or a sub-query over 'probability' or 'object', if the query requires it. It is important to be really careful with the use of sub-queries or JOINs, as they can slow down the query.\n# Answer ONLY with the SQL query, do not include any additional or explanatory text. If you want to add something, add COMMENTS IN PostgreSQL format so that the user can understand.\n# Answer ONLY with the final SQL query, with the following format: \n  ```sql SQL_QUERY_HERE ```\nDON'T include anything else in your answer. If you want to add comments, use the SQL comment format inside the query.\n\n# Use the next decomposed planification to write the query:\nTo decompose the user request into a systematic series of steps for generating the appropriate PostgreSQL query, follow these detailed steps:\n\n1. **Identify the relevant tables and columns:**\n   - Recognize that the main table involved is `dataquality`, which contains columns such as `oid` (object identifier), `candid` (candidate ID), and various quality metrics including `chipsf` (reduced chi-square) and `scorr` (peak-pixel S/N).\n   - Confirm that `oid` in `dataquality` corresponds to the ZTF object identifiers, which are stored as strings matching the format `'ZTF...'`.\n\n2. **Determine the filtering criteria:**\n   - The objects of interest are specified by their ZTF identifiers: `'ZTF20abfcszi'` and `'ZTF21aaqwjlz'`.\n   - The epochs to be retrieved are those where the `chipsf` (reduced chi-square) value is less than 3.\n   \n3. **Construct the filtering conditions:**\n   - Use a `WHERE` clause to select rows where `oid` matches either `'ZTF20abfcszi'` or `'ZTF21aaqwjlz'`.\n   - Add an additional condition to filter rows where `chipsf` < 3.\n\n4. **Determine the columns to retrieve:**\n   - Since the user requests \"all columns from the 'dataquality' table,\" specify selecting all columns using `*`.\n\n5. **Define the sorting order:**\n   - First, sort the results by the ZTF identifier (`oid`) in ascending order.\n   - Then, sort by the peak-pixel S/N (`scorr`) in descending order within each object.\n\n6. **Implement the sorting in the query:**\n   - Use an `ORDER BY` clause with `oid ASC` and `scorr DESC`.\n\n7. **Optional considerations:**\n   - Ensure that the filtering on `oid` is case-sensitive and matches the exact string format.\n   - Confirm that the `scorr` column is numeric and suitable for descending order sorting.\n\n8. **Final step:**\n   - Combine all the above into a coherent query structure, ensuring proper syntax and logical flow, with the filtering conditions first, followed by the selection of all columns, and then the sorting.\n\nBy following these steps, the resulting query will accurately retrieve all epochs for the specified objects where the reduced chi-square is below 3, sorted as requested.\n# If there is SQL code, use it only as reference, changing the conditions you consider necessary.\n# You can join some of the steps if you consider it better for the query. For example, if 2 or more use the same table and are not requested to be different sub-queries, then you can join them.\n"}, {"role": "user", "content": "# Important Information for the query\nExternal Knowledge: 0\nDomain Knowledge: 0\n # User Request: ''For objects with ZTF identifiers 'ZTF20abfcszi' and 'ZTF21aaqwjlz', get all epochs that have a reduced chi-square value lower than 3. Return all columns from the 'dataquality' table, sorting them by ZTF identifier in ascending order and peak-pixel S/N in descending order''"}], "max_tokens": 4000, "temperature": 0.0, "top_p": 1.0, "n": 1}}
